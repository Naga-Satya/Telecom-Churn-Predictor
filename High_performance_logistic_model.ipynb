{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>tot_monthly_recharge_6</th>\n",
       "      <th>tot_monthly_recharge_7</th>\n",
       "      <th>average_recharge_6_7</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1069.180</td>\n",
       "      <td>1349.850</td>\n",
       "      <td>1519.213488</td>\n",
       "      <td>57.84</td>\n",
       "      <td>54.68</td>\n",
       "      <td>52.29</td>\n",
       "      <td>453.43</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>57.74</td>\n",
       "      <td>19.38</td>\n",
       "      <td>18.74</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.721</td>\n",
       "      <td>492.223</td>\n",
       "      <td>137.362000</td>\n",
       "      <td>413.69</td>\n",
       "      <td>351.03</td>\n",
       "      <td>35.08</td>\n",
       "      <td>94.66</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>21.03</td>\n",
       "      <td>910.65</td>\n",
       "      <td>122.16</td>\n",
       "      <td>437.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>492.846</td>\n",
       "      <td>205.671</td>\n",
       "      <td>593.260000</td>\n",
       "      <td>501.76</td>\n",
       "      <td>108.39</td>\n",
       "      <td>534.24</td>\n",
       "      <td>413.31</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>507.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>430.975</td>\n",
       "      <td>299.869</td>\n",
       "      <td>187.894000</td>\n",
       "      <td>50.51</td>\n",
       "      <td>74.01</td>\n",
       "      <td>70.61</td>\n",
       "      <td>296.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>21.89</td>\n",
       "      <td>570.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>690.008</td>\n",
       "      <td>18.980</td>\n",
       "      <td>25.499000</td>\n",
       "      <td>1185.91</td>\n",
       "      <td>9.28</td>\n",
       "      <td>7.79</td>\n",
       "      <td>61.64</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>816.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou    arpu_6    arpu_7  \\\n",
       "0             0.0             0.0             0.0  1069.180  1349.850   \n",
       "1             0.0             0.0             0.0   378.721   492.223   \n",
       "2             0.0             0.0             0.0   492.846   205.671   \n",
       "3             0.0             0.0             0.0   430.975   299.869   \n",
       "4             0.0             0.0             0.0   690.008    18.980   \n",
       "\n",
       "        arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  ...  \\\n",
       "0  1519.213488        57.84        54.68        52.29        453.43  ...   \n",
       "1   137.362000       413.69       351.03        35.08         94.66  ...   \n",
       "2   593.260000       501.76       108.39       534.24        413.31  ...   \n",
       "3   187.894000        50.51        74.01        70.61        296.29  ...   \n",
       "4    25.499000      1185.91         9.28         7.79         61.64  ...   \n",
       "\n",
       "   fb_user_7  fb_user_8     aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0       -1.0       -1.0   802.0       57.74       19.38       18.74   \n",
       "1        1.0        1.0   315.0       21.03      910.65      122.16   \n",
       "2       -1.0        1.0  2607.0        0.00        0.00        0.00   \n",
       "3       -1.0       -1.0   511.0        0.00        2.45       21.89   \n",
       "4       -1.0       -1.0   667.0        0.00        0.00        0.00   \n",
       "\n",
       "   tot_monthly_recharge_6  tot_monthly_recharge_7  average_recharge_6_7  churn  \n",
       "0                  1580.0                   790.0                1185.0      1  \n",
       "1                   437.0                   603.0                 520.0      0  \n",
       "2                   507.0                   253.0                 380.0      0  \n",
       "3                   570.0                   348.0                 459.0      0  \n",
       "4                   816.0                     0.0                 408.0      0  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log = pd.read_csv(\"data_for_logistic_high_performance_model.csv\")\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30019 entries, 0 to 30018\n",
      "Data columns (total 158 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   loc_og_t2o_mou          float64\n",
      " 1   std_og_t2o_mou          float64\n",
      " 2   loc_ic_t2o_mou          float64\n",
      " 3   arpu_6                  float64\n",
      " 4   arpu_7                  float64\n",
      " 5   arpu_8                  float64\n",
      " 6   onnet_mou_6             float64\n",
      " 7   onnet_mou_7             float64\n",
      " 8   onnet_mou_8             float64\n",
      " 9   offnet_mou_6            float64\n",
      " 10  offnet_mou_7            float64\n",
      " 11  offnet_mou_8            float64\n",
      " 12  roam_ic_mou_6           float64\n",
      " 13  roam_ic_mou_7           float64\n",
      " 14  roam_ic_mou_8           float64\n",
      " 15  roam_og_mou_6           float64\n",
      " 16  roam_og_mou_7           float64\n",
      " 17  roam_og_mou_8           float64\n",
      " 18  loc_og_t2t_mou_6        float64\n",
      " 19  loc_og_t2t_mou_7        float64\n",
      " 20  loc_og_t2t_mou_8        float64\n",
      " 21  loc_og_t2m_mou_6        float64\n",
      " 22  loc_og_t2m_mou_7        float64\n",
      " 23  loc_og_t2m_mou_8        float64\n",
      " 24  loc_og_t2f_mou_6        float64\n",
      " 25  loc_og_t2f_mou_7        float64\n",
      " 26  loc_og_t2f_mou_8        float64\n",
      " 27  loc_og_t2c_mou_6        float64\n",
      " 28  loc_og_t2c_mou_7        float64\n",
      " 29  loc_og_t2c_mou_8        float64\n",
      " 30  loc_og_mou_6            float64\n",
      " 31  loc_og_mou_7            float64\n",
      " 32  loc_og_mou_8            float64\n",
      " 33  std_og_t2t_mou_6        float64\n",
      " 34  std_og_t2t_mou_7        float64\n",
      " 35  std_og_t2t_mou_8        float64\n",
      " 36  std_og_t2m_mou_6        float64\n",
      " 37  std_og_t2m_mou_7        float64\n",
      " 38  std_og_t2m_mou_8        float64\n",
      " 39  std_og_t2f_mou_6        float64\n",
      " 40  std_og_t2f_mou_7        float64\n",
      " 41  std_og_t2f_mou_8        float64\n",
      " 42  std_og_t2c_mou_6        float64\n",
      " 43  std_og_t2c_mou_7        float64\n",
      " 44  std_og_t2c_mou_8        float64\n",
      " 45  std_og_mou_6            float64\n",
      " 46  std_og_mou_7            float64\n",
      " 47  std_og_mou_8            float64\n",
      " 48  isd_og_mou_6            float64\n",
      " 49  isd_og_mou_7            float64\n",
      " 50  isd_og_mou_8            float64\n",
      " 51  spl_og_mou_6            float64\n",
      " 52  spl_og_mou_7            float64\n",
      " 53  spl_og_mou_8            float64\n",
      " 54  og_others_6             float64\n",
      " 55  og_others_7             float64\n",
      " 56  og_others_8             float64\n",
      " 57  total_og_mou_6          float64\n",
      " 58  total_og_mou_7          float64\n",
      " 59  total_og_mou_8          float64\n",
      " 60  loc_ic_t2t_mou_6        float64\n",
      " 61  loc_ic_t2t_mou_7        float64\n",
      " 62  loc_ic_t2t_mou_8        float64\n",
      " 63  loc_ic_t2m_mou_6        float64\n",
      " 64  loc_ic_t2m_mou_7        float64\n",
      " 65  loc_ic_t2m_mou_8        float64\n",
      " 66  loc_ic_t2f_mou_6        float64\n",
      " 67  loc_ic_t2f_mou_7        float64\n",
      " 68  loc_ic_t2f_mou_8        float64\n",
      " 69  loc_ic_mou_6            float64\n",
      " 70  loc_ic_mou_7            float64\n",
      " 71  loc_ic_mou_8            float64\n",
      " 72  std_ic_t2t_mou_6        float64\n",
      " 73  std_ic_t2t_mou_7        float64\n",
      " 74  std_ic_t2t_mou_8        float64\n",
      " 75  std_ic_t2m_mou_6        float64\n",
      " 76  std_ic_t2m_mou_7        float64\n",
      " 77  std_ic_t2m_mou_8        float64\n",
      " 78  std_ic_t2f_mou_6        float64\n",
      " 79  std_ic_t2f_mou_7        float64\n",
      " 80  std_ic_t2f_mou_8        float64\n",
      " 81  std_ic_t2o_mou_6        float64\n",
      " 82  std_ic_t2o_mou_7        float64\n",
      " 83  std_ic_t2o_mou_8        float64\n",
      " 84  std_ic_mou_6            float64\n",
      " 85  std_ic_mou_7            float64\n",
      " 86  std_ic_mou_8            float64\n",
      " 87  total_ic_mou_6          float64\n",
      " 88  total_ic_mou_7          float64\n",
      " 89  total_ic_mou_8          float64\n",
      " 90  spl_ic_mou_6            float64\n",
      " 91  spl_ic_mou_7            float64\n",
      " 92  spl_ic_mou_8            float64\n",
      " 93  isd_ic_mou_6            float64\n",
      " 94  isd_ic_mou_7            float64\n",
      " 95  isd_ic_mou_8            float64\n",
      " 96  ic_others_6             float64\n",
      " 97  ic_others_7             float64\n",
      " 98  ic_others_8             float64\n",
      " 99  total_rech_num_6        float64\n",
      " 100 total_rech_num_7        float64\n",
      " 101 total_rech_num_8        float64\n",
      " 102 total_rech_amt_6        float64\n",
      " 103 total_rech_amt_7        float64\n",
      " 104 total_rech_amt_8        float64\n",
      " 105 max_rech_amt_6          float64\n",
      " 106 max_rech_amt_7          float64\n",
      " 107 max_rech_amt_8          float64\n",
      " 108 last_day_rch_amt_6      float64\n",
      " 109 last_day_rch_amt_7      float64\n",
      " 110 last_day_rch_amt_8      float64\n",
      " 111 total_rech_data_6       float64\n",
      " 112 total_rech_data_7       float64\n",
      " 113 total_rech_data_8       float64\n",
      " 114 max_rech_data_6         float64\n",
      " 115 max_rech_data_7         float64\n",
      " 116 max_rech_data_8         float64\n",
      " 117 count_rech_2g_6         float64\n",
      " 118 count_rech_2g_7         float64\n",
      " 119 count_rech_2g_8         float64\n",
      " 120 count_rech_3g_6         float64\n",
      " 121 count_rech_3g_7         float64\n",
      " 122 count_rech_3g_8         float64\n",
      " 123 av_rech_amt_data_6      float64\n",
      " 124 av_rech_amt_data_7      float64\n",
      " 125 av_rech_amt_data_8      float64\n",
      " 126 vol_2g_mb_6             float64\n",
      " 127 vol_2g_mb_7             float64\n",
      " 128 vol_2g_mb_8             float64\n",
      " 129 vol_3g_mb_6             float64\n",
      " 130 vol_3g_mb_7             float64\n",
      " 131 vol_3g_mb_8             float64\n",
      " 132 night_pck_user_6        float64\n",
      " 133 night_pck_user_7        float64\n",
      " 134 night_pck_user_8        float64\n",
      " 135 monthly_2g_6            float64\n",
      " 136 monthly_2g_7            float64\n",
      " 137 monthly_2g_8            float64\n",
      " 138 sachet_2g_6             float64\n",
      " 139 sachet_2g_7             float64\n",
      " 140 sachet_2g_8             float64\n",
      " 141 monthly_3g_6            float64\n",
      " 142 monthly_3g_7            float64\n",
      " 143 monthly_3g_8            float64\n",
      " 144 sachet_3g_6             float64\n",
      " 145 sachet_3g_7             float64\n",
      " 146 sachet_3g_8             float64\n",
      " 147 fb_user_6               float64\n",
      " 148 fb_user_7               float64\n",
      " 149 fb_user_8               float64\n",
      " 150 aon                     float64\n",
      " 151 aug_vbc_3g              float64\n",
      " 152 jul_vbc_3g              float64\n",
      " 153 jun_vbc_3g              float64\n",
      " 154 tot_monthly_recharge_6  float64\n",
      " 155 tot_monthly_recharge_7  float64\n",
      " 156 average_recharge_6_7    float64\n",
      " 157 churn                   int64  \n",
      "dtypes: float64(157), int64(1)\n",
      "memory usage: 36.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_log.info(verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30019 entries, 0 to 30018\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   fb_user_6         30019 non-null  object\n",
      " 1   fb_user_7         30019 non-null  object\n",
      " 2   fb_user_8         30019 non-null  object\n",
      " 3   night_pck_user_6  30019 non-null  object\n",
      " 4   night_pck_user_7  30019 non-null  object\n",
      " 5   night_pck_user_8  30019 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "obj_cols = ['fb_user_6', 'fb_user_7', 'fb_user_8',\n",
    "                            'night_pck_user_6', 'night_pck_user_7', 'night_pck_user_8'\n",
    "                           ]\n",
    "df_log[obj_cols] = df_log[obj_cols].astype('object')\n",
    "df_log[obj_cols].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log = df_log.drop('churn', axis = 1)\n",
    "y_log = df_log['churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of numerical columns: 151\n"
     ]
    }
   ],
   "source": [
    "num_cols = X_log.select_dtypes(include = ['int64','float64']).columns\n",
    "print(\"Total count of numerical columns: {}\".format(len(num_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_log[num_cols] = scaler.fit_transform(X_log[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>tot_monthly_recharge_6</th>\n",
       "      <th>tot_monthly_recharge_7</th>\n",
       "      <th>average_recharge_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.636538</td>\n",
       "      <td>2.510202</td>\n",
       "      <td>2.917916</td>\n",
       "      <td>-0.632765</td>\n",
       "      <td>-0.638199</td>\n",
       "      <td>-0.582044</td>\n",
       "      <td>0.183719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.474119</td>\n",
       "      <td>-0.182020</td>\n",
       "      <td>-0.345100</td>\n",
       "      <td>-0.325309</td>\n",
       "      <td>2.459186</td>\n",
       "      <td>0.303607</td>\n",
       "      <td>1.619414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621115</td>\n",
       "      <td>-0.254252</td>\n",
       "      <td>-1.102039</td>\n",
       "      <td>0.447605</td>\n",
       "      <td>0.226780</td>\n",
       "      <td>-0.636276</td>\n",
       "      <td>-0.848816</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.990277</td>\n",
       "      <td>-0.336839</td>\n",
       "      <td>3.261082</td>\n",
       "      <td>0.130323</td>\n",
       "      <td>-0.647940</td>\n",
       "      <td>-0.188103</td>\n",
       "      <td>-0.502097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.247950</td>\n",
       "      <td>-1.177916</td>\n",
       "      <td>0.224218</td>\n",
       "      <td>0.714988</td>\n",
       "      <td>-0.481432</td>\n",
       "      <td>0.936688</td>\n",
       "      <td>0.068254</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.438951</td>\n",
       "      <td>-0.425530</td>\n",
       "      <td>-0.423514</td>\n",
       "      <td>-0.407870</td>\n",
       "      <td>-0.457652</td>\n",
       "      <td>-1.108415</td>\n",
       "      <td>-0.948731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.450255</td>\n",
       "      <td>-0.874281</td>\n",
       "      <td>-0.955036</td>\n",
       "      <td>-0.655019</td>\n",
       "      <td>-0.581779</td>\n",
       "      <td>-0.524313</td>\n",
       "      <td>-0.268528</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.782542</td>\n",
       "      <td>-0.425530</td>\n",
       "      <td>-0.413601</td>\n",
       "      <td>-0.311431</td>\n",
       "      <td>-0.286393</td>\n",
       "      <td>-0.858616</td>\n",
       "      <td>-0.696702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396727</td>\n",
       "      <td>-1.779691</td>\n",
       "      <td>-1.427460</td>\n",
       "      <td>2.792086</td>\n",
       "      <td>-0.770712</td>\n",
       "      <td>-0.722273</td>\n",
       "      <td>-0.943847</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.617202</td>\n",
       "      <td>-0.425530</td>\n",
       "      <td>-0.423514</td>\n",
       "      <td>-0.407870</td>\n",
       "      <td>0.382332</td>\n",
       "      <td>-1.773670</td>\n",
       "      <td>-0.859404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou    arpu_6    arpu_7  \\\n",
       "0             0.0             0.0             0.0  1.636538  2.510202   \n",
       "1             0.0             0.0             0.0 -0.621115 -0.254252   \n",
       "2             0.0             0.0             0.0 -0.247950 -1.177916   \n",
       "3             0.0             0.0             0.0 -0.450255 -0.874281   \n",
       "4             0.0             0.0             0.0  0.396727 -1.779691   \n",
       "\n",
       "     arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  ...  \\\n",
       "0  2.917916    -0.632765    -0.638199    -0.582044      0.183719  ...   \n",
       "1 -1.102039     0.447605     0.226780    -0.636276     -0.848816  ...   \n",
       "2  0.224218     0.714988    -0.481432     0.936688      0.068254  ...   \n",
       "3 -0.955036    -0.655019    -0.581779    -0.524313     -0.268528  ...   \n",
       "4 -1.427460     2.792086    -0.770712    -0.722273     -0.943847  ...   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8       aon  aug_vbc_3g  jul_vbc_3g  \\\n",
       "0         -1         -1         -1 -0.474119   -0.182020   -0.345100   \n",
       "1         -1          1          1 -0.990277   -0.336839    3.261082   \n",
       "2         -1         -1          1  1.438951   -0.425530   -0.423514   \n",
       "3         -1         -1         -1 -0.782542   -0.425530   -0.413601   \n",
       "4         -1         -1         -1 -0.617202   -0.425530   -0.423514   \n",
       "\n",
       "   jun_vbc_3g  tot_monthly_recharge_6  tot_monthly_recharge_7  \\\n",
       "0   -0.325309                2.459186                0.303607   \n",
       "1    0.130323               -0.647940               -0.188103   \n",
       "2   -0.407870               -0.457652               -1.108415   \n",
       "3   -0.311431               -0.286393               -0.858616   \n",
       "4   -0.407870                0.382332               -1.773670   \n",
       "\n",
       "   average_recharge_6_7  \n",
       "0              1.619414  \n",
       "1             -0.502097  \n",
       "2             -0.948731  \n",
       "3             -0.696702  \n",
       "4             -0.859404  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state = 100)\n",
    "pca_data = pca.fit(X_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17da8ef0400>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(var_cumu)+1), var_cumu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(0.90)\n",
    "pca2_data = pca2.fit_transform(X_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30019, 52)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3 = PCA(0.95)\n",
    "pca3_data = pca3.fit_transform(X_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30019, 70)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca3_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning X_log with pca data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30019, 70)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_log = pd.DataFrame(pca3_data)\n",
    "X_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.848884</td>\n",
       "      <td>7.708640</td>\n",
       "      <td>-1.538871</td>\n",
       "      <td>-6.138307</td>\n",
       "      <td>6.707642</td>\n",
       "      <td>-1.895321</td>\n",
       "      <td>-0.071635</td>\n",
       "      <td>3.484130</td>\n",
       "      <td>5.652522</td>\n",
       "      <td>1.378470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658475</td>\n",
       "      <td>0.114465</td>\n",
       "      <td>-1.261185</td>\n",
       "      <td>1.489114</td>\n",
       "      <td>-2.227306</td>\n",
       "      <td>-0.524190</td>\n",
       "      <td>-0.609610</td>\n",
       "      <td>-1.789933</td>\n",
       "      <td>0.039509</td>\n",
       "      <td>-0.953834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.868207</td>\n",
       "      <td>-4.029816</td>\n",
       "      <td>-0.130091</td>\n",
       "      <td>2.924715</td>\n",
       "      <td>-0.761529</td>\n",
       "      <td>0.643027</td>\n",
       "      <td>-0.488949</td>\n",
       "      <td>0.806977</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>-0.423299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>1.076416</td>\n",
       "      <td>-0.405117</td>\n",
       "      <td>-0.108846</td>\n",
       "      <td>-0.012564</td>\n",
       "      <td>-0.158647</td>\n",
       "      <td>0.761103</td>\n",
       "      <td>0.661591</td>\n",
       "      <td>-0.888201</td>\n",
       "      <td>0.177578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.570567</td>\n",
       "      <td>2.941774</td>\n",
       "      <td>0.835671</td>\n",
       "      <td>-1.163843</td>\n",
       "      <td>10.624948</td>\n",
       "      <td>2.129281</td>\n",
       "      <td>1.349088</td>\n",
       "      <td>0.884376</td>\n",
       "      <td>0.572773</td>\n",
       "      <td>5.167166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682076</td>\n",
       "      <td>0.240198</td>\n",
       "      <td>-2.027697</td>\n",
       "      <td>-0.859467</td>\n",
       "      <td>-0.838989</td>\n",
       "      <td>-0.378317</td>\n",
       "      <td>-0.929591</td>\n",
       "      <td>0.974327</td>\n",
       "      <td>-0.073767</td>\n",
       "      <td>0.610870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.879399</td>\n",
       "      <td>0.264488</td>\n",
       "      <td>-3.440286</td>\n",
       "      <td>-1.124842</td>\n",
       "      <td>2.480123</td>\n",
       "      <td>0.628095</td>\n",
       "      <td>0.785440</td>\n",
       "      <td>-0.915207</td>\n",
       "      <td>-1.127319</td>\n",
       "      <td>-0.134863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336662</td>\n",
       "      <td>-0.065181</td>\n",
       "      <td>0.532011</td>\n",
       "      <td>0.042286</td>\n",
       "      <td>-0.234792</td>\n",
       "      <td>0.531532</td>\n",
       "      <td>0.917273</td>\n",
       "      <td>-0.934947</td>\n",
       "      <td>1.114756</td>\n",
       "      <td>0.856654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.538939</td>\n",
       "      <td>-3.094460</td>\n",
       "      <td>-2.044200</td>\n",
       "      <td>-0.396908</td>\n",
       "      <td>-1.086869</td>\n",
       "      <td>1.447875</td>\n",
       "      <td>3.892854</td>\n",
       "      <td>0.096753</td>\n",
       "      <td>0.682211</td>\n",
       "      <td>-0.711671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268118</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>0.201801</td>\n",
       "      <td>0.282398</td>\n",
       "      <td>0.234505</td>\n",
       "      <td>-0.324621</td>\n",
       "      <td>-0.294928</td>\n",
       "      <td>-0.013934</td>\n",
       "      <td>0.098471</td>\n",
       "      <td>0.034367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3          4         5         6   \\\n",
       "0  4.848884  7.708640 -1.538871 -6.138307   6.707642 -1.895321 -0.071635   \n",
       "1 -0.868207 -4.029816 -0.130091  2.924715  -0.761529  0.643027 -0.488949   \n",
       "2 -0.570567  2.941774  0.835671 -1.163843  10.624948  2.129281  1.349088   \n",
       "3 -1.879399  0.264488 -3.440286 -1.124842   2.480123  0.628095  0.785440   \n",
       "4 -5.538939 -3.094460 -2.044200 -0.396908  -1.086869  1.447875  3.892854   \n",
       "\n",
       "         7         8         9   ...        60        61        62        63  \\\n",
       "0  3.484130  5.652522  1.378470  ...  0.658475  0.114465 -1.261185  1.489114   \n",
       "1  0.806977  0.020100 -0.423299  ...  0.002142  1.076416 -0.405117 -0.108846   \n",
       "2  0.884376  0.572773  5.167166  ...  0.682076  0.240198 -2.027697 -0.859467   \n",
       "3 -0.915207 -1.127319 -0.134863  ... -0.336662 -0.065181  0.532011  0.042286   \n",
       "4  0.096753  0.682211 -0.711671  ...  0.268118 -0.072747  0.201801  0.282398   \n",
       "\n",
       "         64        65        66        67        68        69  \n",
       "0 -2.227306 -0.524190 -0.609610 -1.789933  0.039509 -0.953834  \n",
       "1 -0.012564 -0.158647  0.761103  0.661591 -0.888201  0.177578  \n",
       "2 -0.838989 -0.378317 -0.929591  0.974327 -0.073767  0.610870  \n",
       "3 -0.234792  0.531532  0.917273 -0.934947  1.114756  0.856654  \n",
       "4  0.234505 -0.324621 -0.294928 -0.013934  0.098471  0.034367  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21013, 70)\n",
      "(21013,)\n",
      "(9006, 70)\n",
      "(9006,)\n"
     ]
    }
   ],
   "source": [
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_log, y_log, train_size=0.7, random_state=100)\n",
    "print(X_train_log.shape)\n",
    "print(y_train_log.shape)\n",
    "print(X_test_log.shape)\n",
    "print(y_test_log.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>churn</td>      <th>  No. Observations:  </th>  <td> 21013</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 20942</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    70</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -3975.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 30 Aug 2020</td> <th>  Deviance:          </th> <td>  7950.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:38:44</td>     <th>  Pearson chi2:      </th> <td>1.90e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>12</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -4.0909</td> <td>    0.140</td> <td>  -29.282</td> <td> 0.000</td> <td>   -4.365</td> <td>   -3.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>     <td>   -0.3148</td> <td>    0.018</td> <td>  -17.850</td> <td> 0.000</td> <td>   -0.349</td> <td>   -0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>   -0.2165</td> <td>    0.017</td> <td>  -12.579</td> <td> 0.000</td> <td>   -0.250</td> <td>   -0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>     <td>   -0.0288</td> <td>    0.013</td> <td>   -2.234</td> <td> 0.025</td> <td>   -0.054</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>     <td>   -0.1236</td> <td>    0.022</td> <td>   -5.547</td> <td> 0.000</td> <td>   -0.167</td> <td>   -0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>     <td>   -0.1000</td> <td>    0.025</td> <td>   -3.988</td> <td> 0.000</td> <td>   -0.149</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>     <td>   -0.0824</td> <td>    0.019</td> <td>   -4.333</td> <td> 0.000</td> <td>   -0.120</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>     <td>    0.5470</td> <td>    0.017</td> <td>   31.324</td> <td> 0.000</td> <td>    0.513</td> <td>    0.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>     <td>    0.0813</td> <td>    0.018</td> <td>    4.450</td> <td> 0.000</td> <td>    0.046</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>     <td>   -0.1254</td> <td>    0.037</td> <td>   -3.364</td> <td> 0.001</td> <td>   -0.198</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>     <td>   -0.0334</td> <td>    0.052</td> <td>   -0.647</td> <td> 0.518</td> <td>   -0.135</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th>    <td>   -0.0125</td> <td>    0.029</td> <td>   -0.433</td> <td> 0.665</td> <td>   -0.069</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th>    <td>   -0.0493</td> <td>    0.036</td> <td>   -1.385</td> <td> 0.166</td> <td>   -0.119</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th>    <td>   -0.1690</td> <td>    0.071</td> <td>   -2.393</td> <td> 0.017</td> <td>   -0.307</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13</th>    <td>   -0.1992</td> <td>    0.082</td> <td>   -2.425</td> <td> 0.015</td> <td>   -0.360</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th>    <td>   -0.4675</td> <td>    0.039</td> <td>  -11.879</td> <td> 0.000</td> <td>   -0.545</td> <td>   -0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15</th>    <td>   -0.2121</td> <td>    0.037</td> <td>   -5.753</td> <td> 0.000</td> <td>   -0.284</td> <td>   -0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16</th>    <td>   -0.1020</td> <td>    0.073</td> <td>   -1.389</td> <td> 0.165</td> <td>   -0.246</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17</th>    <td>   -0.1875</td> <td>    0.037</td> <td>   -5.022</td> <td> 0.000</td> <td>   -0.261</td> <td>   -0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>18</th>    <td>   -0.1836</td> <td>    0.078</td> <td>   -2.347</td> <td> 0.019</td> <td>   -0.337</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>19</th>    <td>   -0.0132</td> <td>    0.033</td> <td>   -0.402</td> <td> 0.688</td> <td>   -0.078</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>20</th>    <td>   -1.0164</td> <td>    0.410</td> <td>   -2.480</td> <td> 0.013</td> <td>   -1.819</td> <td>   -0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21</th>    <td>   -2.9055</td> <td>    1.294</td> <td>   -2.245</td> <td> 0.025</td> <td>   -5.442</td> <td>   -0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22</th>    <td>   -1.1376</td> <td>    0.609</td> <td>   -1.867</td> <td> 0.062</td> <td>   -2.332</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>23</th>    <td>    0.1879</td> <td>    0.101</td> <td>    1.856</td> <td> 0.063</td> <td>   -0.011</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>24</th>    <td>   -0.8281</td> <td>    0.429</td> <td>   -1.930</td> <td> 0.054</td> <td>   -1.669</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25</th>    <td>    0.3085</td> <td>    0.065</td> <td>    4.773</td> <td> 0.000</td> <td>    0.182</td> <td>    0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>26</th>    <td>   -0.0711</td> <td>    0.070</td> <td>   -1.010</td> <td> 0.313</td> <td>   -0.209</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>27</th>    <td>   -0.3118</td> <td>    0.174</td> <td>   -1.796</td> <td> 0.072</td> <td>   -0.652</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28</th>    <td>    0.6020</td> <td>    0.243</td> <td>    2.479</td> <td> 0.013</td> <td>    0.126</td> <td>    1.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>29</th>    <td>    0.1453</td> <td>    0.087</td> <td>    1.662</td> <td> 0.097</td> <td>   -0.026</td> <td>    0.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>30</th>    <td>    0.0302</td> <td>    0.075</td> <td>    0.403</td> <td> 0.687</td> <td>   -0.117</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>31</th>    <td>    0.0708</td> <td>    0.044</td> <td>    1.613</td> <td> 0.107</td> <td>   -0.015</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>32</th>    <td>    0.0241</td> <td>    0.058</td> <td>    0.416</td> <td> 0.678</td> <td>   -0.090</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>33</th>    <td>   -0.0004</td> <td>    0.042</td> <td>   -0.011</td> <td> 0.992</td> <td>   -0.083</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>34</th>    <td>    0.0455</td> <td>    0.090</td> <td>    0.503</td> <td> 0.615</td> <td>   -0.132</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>35</th>    <td>   -0.3763</td> <td>    0.129</td> <td>   -2.928</td> <td> 0.003</td> <td>   -0.628</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>36</th>    <td>   -0.1998</td> <td>    0.044</td> <td>   -4.549</td> <td> 0.000</td> <td>   -0.286</td> <td>   -0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>37</th>    <td>   -0.1751</td> <td>    0.044</td> <td>   -3.943</td> <td> 0.000</td> <td>   -0.262</td> <td>   -0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>38</th>    <td>   -0.1958</td> <td>    0.043</td> <td>   -4.540</td> <td> 0.000</td> <td>   -0.280</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>39</th>    <td>   -0.0242</td> <td>    0.045</td> <td>   -0.534</td> <td> 0.593</td> <td>   -0.113</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>40</th>    <td>    0.1639</td> <td>    0.040</td> <td>    4.063</td> <td> 0.000</td> <td>    0.085</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>41</th>    <td>    0.1554</td> <td>    0.123</td> <td>    1.260</td> <td> 0.208</td> <td>   -0.086</td> <td>    0.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>42</th>    <td>    0.0141</td> <td>    0.042</td> <td>    0.340</td> <td> 0.734</td> <td>   -0.067</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>43</th>    <td>    0.1424</td> <td>    0.051</td> <td>    2.791</td> <td> 0.005</td> <td>    0.042</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>44</th>    <td>    0.0305</td> <td>    0.048</td> <td>    0.641</td> <td> 0.521</td> <td>   -0.063</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>45</th>    <td>    0.1317</td> <td>    0.069</td> <td>    1.920</td> <td> 0.055</td> <td>   -0.003</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>46</th>    <td>    0.4639</td> <td>    0.281</td> <td>    1.649</td> <td> 0.099</td> <td>   -0.087</td> <td>    1.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>47</th>    <td>   -2.1499</td> <td>    0.977</td> <td>   -2.200</td> <td> 0.028</td> <td>   -4.066</td> <td>   -0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>48</th>    <td>    2.3717</td> <td>    1.107</td> <td>    2.142</td> <td> 0.032</td> <td>    0.202</td> <td>    4.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>49</th>    <td>    0.1181</td> <td>    0.039</td> <td>    3.018</td> <td> 0.003</td> <td>    0.041</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>50</th>    <td>   -0.5376</td> <td>    0.128</td> <td>   -4.208</td> <td> 0.000</td> <td>   -0.788</td> <td>   -0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>51</th>    <td>   -0.2792</td> <td>    0.238</td> <td>   -1.174</td> <td> 0.240</td> <td>   -0.745</td> <td>    0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>52</th>    <td>    1.0703</td> <td>    0.451</td> <td>    2.375</td> <td> 0.018</td> <td>    0.187</td> <td>    1.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>53</th>    <td>    0.1171</td> <td>    0.071</td> <td>    1.648</td> <td> 0.099</td> <td>   -0.022</td> <td>    0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>54</th>    <td>   -0.0525</td> <td>    0.081</td> <td>   -0.648</td> <td> 0.517</td> <td>   -0.212</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>55</th>    <td>    0.0052</td> <td>    0.058</td> <td>    0.089</td> <td> 0.929</td> <td>   -0.109</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>56</th>    <td>   -0.3219</td> <td>    0.109</td> <td>   -2.963</td> <td> 0.003</td> <td>   -0.535</td> <td>   -0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>57</th>    <td>    0.2077</td> <td>    0.067</td> <td>    3.096</td> <td> 0.002</td> <td>    0.076</td> <td>    0.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>58</th>    <td>   -0.1041</td> <td>    0.056</td> <td>   -1.857</td> <td> 0.063</td> <td>   -0.214</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>59</th>    <td>    0.0649</td> <td>    0.055</td> <td>    1.170</td> <td> 0.242</td> <td>   -0.044</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>60</th>    <td>   -0.0297</td> <td>    0.063</td> <td>   -0.469</td> <td> 0.639</td> <td>   -0.154</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>61</th>    <td>    0.0934</td> <td>    0.057</td> <td>    1.631</td> <td> 0.103</td> <td>   -0.019</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>62</th>    <td>    0.0789</td> <td>    0.063</td> <td>    1.256</td> <td> 0.209</td> <td>   -0.044</td> <td>    0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>63</th>    <td>    0.0536</td> <td>    0.072</td> <td>    0.742</td> <td> 0.458</td> <td>   -0.088</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>64</th>    <td>   -0.0284</td> <td>    0.054</td> <td>   -0.524</td> <td> 0.600</td> <td>   -0.134</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>65</th>    <td>   -0.0455</td> <td>    0.070</td> <td>   -0.655</td> <td> 0.512</td> <td>   -0.182</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>66</th>    <td>   -0.2018</td> <td>    0.058</td> <td>   -3.465</td> <td> 0.001</td> <td>   -0.316</td> <td>   -0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>67</th>    <td>   -0.1265</td> <td>    0.064</td> <td>   -1.969</td> <td> 0.049</td> <td>   -0.252</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>68</th>    <td>   -0.1442</td> <td>    0.061</td> <td>   -2.368</td> <td> 0.018</td> <td>   -0.264</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>69</th>    <td>    0.0543</td> <td>    0.069</td> <td>    0.788</td> <td> 0.431</td> <td>   -0.081</td> <td>    0.189</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  churn   No. Observations:                21013\n",
       "Model:                            GLM   Df Residuals:                    20942\n",
       "Model Family:                Binomial   Df Model:                           70\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -3975.3\n",
       "Date:                Sun, 30 Aug 2020   Deviance:                       7950.7\n",
       "Time:                        12:38:44   Pearson chi2:                 1.90e+05\n",
       "No. Iterations:                    12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -4.0909      0.140    -29.282      0.000      -4.365      -3.817\n",
       "0             -0.3148      0.018    -17.850      0.000      -0.349      -0.280\n",
       "1             -0.2165      0.017    -12.579      0.000      -0.250      -0.183\n",
       "2             -0.0288      0.013     -2.234      0.025      -0.054      -0.004\n",
       "3             -0.1236      0.022     -5.547      0.000      -0.167      -0.080\n",
       "4             -0.1000      0.025     -3.988      0.000      -0.149      -0.051\n",
       "5             -0.0824      0.019     -4.333      0.000      -0.120      -0.045\n",
       "6              0.5470      0.017     31.324      0.000       0.513       0.581\n",
       "7              0.0813      0.018      4.450      0.000       0.046       0.117\n",
       "8             -0.1254      0.037     -3.364      0.001      -0.198      -0.052\n",
       "9             -0.0334      0.052     -0.647      0.518      -0.135       0.068\n",
       "10            -0.0125      0.029     -0.433      0.665      -0.069       0.044\n",
       "11            -0.0493      0.036     -1.385      0.166      -0.119       0.020\n",
       "12            -0.1690      0.071     -2.393      0.017      -0.307      -0.031\n",
       "13            -0.1992      0.082     -2.425      0.015      -0.360      -0.038\n",
       "14            -0.4675      0.039    -11.879      0.000      -0.545      -0.390\n",
       "15            -0.2121      0.037     -5.753      0.000      -0.284      -0.140\n",
       "16            -0.1020      0.073     -1.389      0.165      -0.246       0.042\n",
       "17            -0.1875      0.037     -5.022      0.000      -0.261      -0.114\n",
       "18            -0.1836      0.078     -2.347      0.019      -0.337      -0.030\n",
       "19            -0.0132      0.033     -0.402      0.688      -0.078       0.051\n",
       "20            -1.0164      0.410     -2.480      0.013      -1.819      -0.213\n",
       "21            -2.9055      1.294     -2.245      0.025      -5.442      -0.369\n",
       "22            -1.1376      0.609     -1.867      0.062      -2.332       0.057\n",
       "23             0.1879      0.101      1.856      0.063      -0.011       0.386\n",
       "24            -0.8281      0.429     -1.930      0.054      -1.669       0.013\n",
       "25             0.3085      0.065      4.773      0.000       0.182       0.435\n",
       "26            -0.0711      0.070     -1.010      0.313      -0.209       0.067\n",
       "27            -0.3118      0.174     -1.796      0.072      -0.652       0.028\n",
       "28             0.6020      0.243      2.479      0.013       0.126       1.078\n",
       "29             0.1453      0.087      1.662      0.097      -0.026       0.317\n",
       "30             0.0302      0.075      0.403      0.687      -0.117       0.177\n",
       "31             0.0708      0.044      1.613      0.107      -0.015       0.157\n",
       "32             0.0241      0.058      0.416      0.678      -0.090       0.138\n",
       "33            -0.0004      0.042     -0.011      0.992      -0.083       0.082\n",
       "34             0.0455      0.090      0.503      0.615      -0.132       0.223\n",
       "35            -0.3763      0.129     -2.928      0.003      -0.628      -0.124\n",
       "36            -0.1998      0.044     -4.549      0.000      -0.286      -0.114\n",
       "37            -0.1751      0.044     -3.943      0.000      -0.262      -0.088\n",
       "38            -0.1958      0.043     -4.540      0.000      -0.280      -0.111\n",
       "39            -0.0242      0.045     -0.534      0.593      -0.113       0.065\n",
       "40             0.1639      0.040      4.063      0.000       0.085       0.243\n",
       "41             0.1554      0.123      1.260      0.208      -0.086       0.397\n",
       "42             0.0141      0.042      0.340      0.734      -0.067       0.096\n",
       "43             0.1424      0.051      2.791      0.005       0.042       0.242\n",
       "44             0.0305      0.048      0.641      0.521      -0.063       0.124\n",
       "45             0.1317      0.069      1.920      0.055      -0.003       0.266\n",
       "46             0.4639      0.281      1.649      0.099      -0.087       1.015\n",
       "47            -2.1499      0.977     -2.200      0.028      -4.066      -0.234\n",
       "48             2.3717      1.107      2.142      0.032       0.202       4.542\n",
       "49             0.1181      0.039      3.018      0.003       0.041       0.195\n",
       "50            -0.5376      0.128     -4.208      0.000      -0.788      -0.287\n",
       "51            -0.2792      0.238     -1.174      0.240      -0.745       0.187\n",
       "52             1.0703      0.451      2.375      0.018       0.187       1.954\n",
       "53             0.1171      0.071      1.648      0.099      -0.022       0.256\n",
       "54            -0.0525      0.081     -0.648      0.517      -0.212       0.106\n",
       "55             0.0052      0.058      0.089      0.929      -0.109       0.119\n",
       "56            -0.3219      0.109     -2.963      0.003      -0.535      -0.109\n",
       "57             0.2077      0.067      3.096      0.002       0.076       0.339\n",
       "58            -0.1041      0.056     -1.857      0.063      -0.214       0.006\n",
       "59             0.0649      0.055      1.170      0.242      -0.044       0.173\n",
       "60            -0.0297      0.063     -0.469      0.639      -0.154       0.094\n",
       "61             0.0934      0.057      1.631      0.103      -0.019       0.206\n",
       "62             0.0789      0.063      1.256      0.209      -0.044       0.202\n",
       "63             0.0536      0.072      0.742      0.458      -0.088       0.195\n",
       "64            -0.0284      0.054     -0.524      0.600      -0.134       0.078\n",
       "65            -0.0455      0.070     -0.655      0.512      -0.182       0.091\n",
       "66            -0.2018      0.058     -3.465      0.001      -0.316      -0.088\n",
       "67            -0.1265      0.064     -1.969      0.049      -0.252      -0.001\n",
       "68            -0.1442      0.061     -2.368      0.018      -0.264      -0.025\n",
       "69             0.0543      0.069      0.788      0.431      -0.081       0.189\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "logm1 = sm.GLM(y_train_log,(sm.add_constant(X_train_log)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naga Satya\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass n_features_to_select=25 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "rfe = RFE(log, 25)\n",
    "rfe = rfe.fit(X_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 0,  1,  6, 14, 15, 16, 17, 20, 21, 25, 28, 34, 37, 38, 43, 47, 48,\n",
      "            50, 51, 52, 54, 56, 57, 58, 66],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "cols = X_train_log.columns[rfe.support_]\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>churn</td>      <th>  No. Observations:  </th>  <td> 21013</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 20987</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    25</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -4118.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 30 Aug 2020</td> <th>  Deviance:          </th> <td>  8237.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:46:28</td>     <th>  Pearson chi2:      </th> <td>6.73e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>8</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.7330</td> <td>    0.057</td> <td>  -65.591</td> <td> 0.000</td> <td>   -3.845</td> <td>   -3.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>     <td>   -0.2893</td> <td>    0.011</td> <td>  -26.444</td> <td> 0.000</td> <td>   -0.311</td> <td>   -0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>   -0.2043</td> <td>    0.012</td> <td>  -17.689</td> <td> 0.000</td> <td>   -0.227</td> <td>   -0.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>     <td>    0.5315</td> <td>    0.014</td> <td>   38.490</td> <td> 0.000</td> <td>    0.504</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th>    <td>   -0.4265</td> <td>    0.023</td> <td>  -18.897</td> <td> 0.000</td> <td>   -0.471</td> <td>   -0.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15</th>    <td>   -0.1289</td> <td>    0.025</td> <td>   -5.187</td> <td> 0.000</td> <td>   -0.178</td> <td>   -0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16</th>    <td>   -0.1880</td> <td>    0.024</td> <td>   -7.981</td> <td> 0.000</td> <td>   -0.234</td> <td>   -0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17</th>    <td>   -0.1435</td> <td>    0.022</td> <td>   -6.550</td> <td> 0.000</td> <td>   -0.186</td> <td>   -0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>20</th>    <td>   -0.2249</td> <td>    0.033</td> <td>   -6.770</td> <td> 0.000</td> <td>   -0.290</td> <td>   -0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21</th>    <td>   -0.3959</td> <td>    0.056</td> <td>   -7.083</td> <td> 0.000</td> <td>   -0.505</td> <td>   -0.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25</th>    <td>    0.2298</td> <td>    0.025</td> <td>    9.024</td> <td> 0.000</td> <td>    0.180</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28</th>    <td>    0.1442</td> <td>    0.034</td> <td>    4.272</td> <td> 0.000</td> <td>    0.078</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>34</th>    <td>    0.1534</td> <td>    0.033</td> <td>    4.677</td> <td> 0.000</td> <td>    0.089</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>37</th>    <td>   -0.2252</td> <td>    0.033</td> <td>   -6.910</td> <td> 0.000</td> <td>   -0.289</td> <td>   -0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>38</th>    <td>   -0.2209</td> <td>    0.037</td> <td>   -5.973</td> <td> 0.000</td> <td>   -0.293</td> <td>   -0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>43</th>    <td>    0.1488</td> <td>    0.046</td> <td>    3.238</td> <td> 0.001</td> <td>    0.059</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>47</th>    <td>   -0.3106</td> <td>    0.055</td> <td>   -5.635</td> <td> 0.000</td> <td>   -0.419</td> <td>   -0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>48</th>    <td>    0.2717</td> <td>    0.060</td> <td>    4.500</td> <td> 0.000</td> <td>    0.153</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>50</th>    <td>   -0.3485</td> <td>    0.044</td> <td>   -7.924</td> <td> 0.000</td> <td>   -0.435</td> <td>   -0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>51</th>    <td>    0.1697</td> <td>    0.045</td> <td>    3.771</td> <td> 0.000</td> <td>    0.082</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>52</th>    <td>    0.2225</td> <td>    0.043</td> <td>    5.234</td> <td> 0.000</td> <td>    0.139</td> <td>    0.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>54</th>    <td>   -0.2369</td> <td>    0.047</td> <td>   -5.018</td> <td> 0.000</td> <td>   -0.329</td> <td>   -0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>56</th>    <td>   -0.1708</td> <td>    0.045</td> <td>   -3.790</td> <td> 0.000</td> <td>   -0.259</td> <td>   -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>57</th>    <td>    0.1477</td> <td>    0.050</td> <td>    2.974</td> <td> 0.003</td> <td>    0.050</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>58</th>    <td>   -0.1339</td> <td>    0.052</td> <td>   -2.592</td> <td> 0.010</td> <td>   -0.235</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>66</th>    <td>   -0.1710</td> <td>    0.054</td> <td>   -3.168</td> <td> 0.002</td> <td>   -0.277</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  churn   No. Observations:                21013\n",
       "Model:                            GLM   Df Residuals:                    20987\n",
       "Model Family:                Binomial   Df Model:                           25\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -4118.9\n",
       "Date:                Sun, 30 Aug 2020   Deviance:                       8237.8\n",
       "Time:                        12:46:28   Pearson chi2:                 6.73e+04\n",
       "No. Iterations:                     8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.7330      0.057    -65.591      0.000      -3.845      -3.621\n",
       "0             -0.2893      0.011    -26.444      0.000      -0.311      -0.268\n",
       "1             -0.2043      0.012    -17.689      0.000      -0.227      -0.182\n",
       "6              0.5315      0.014     38.490      0.000       0.504       0.559\n",
       "14            -0.4265      0.023    -18.897      0.000      -0.471      -0.382\n",
       "15            -0.1289      0.025     -5.187      0.000      -0.178      -0.080\n",
       "16            -0.1880      0.024     -7.981      0.000      -0.234      -0.142\n",
       "17            -0.1435      0.022     -6.550      0.000      -0.186      -0.101\n",
       "20            -0.2249      0.033     -6.770      0.000      -0.290      -0.160\n",
       "21            -0.3959      0.056     -7.083      0.000      -0.505      -0.286\n",
       "25             0.2298      0.025      9.024      0.000       0.180       0.280\n",
       "28             0.1442      0.034      4.272      0.000       0.078       0.210\n",
       "34             0.1534      0.033      4.677      0.000       0.089       0.218\n",
       "37            -0.2252      0.033     -6.910      0.000      -0.289      -0.161\n",
       "38            -0.2209      0.037     -5.973      0.000      -0.293      -0.148\n",
       "43             0.1488      0.046      3.238      0.001       0.059       0.239\n",
       "47            -0.3106      0.055     -5.635      0.000      -0.419      -0.203\n",
       "48             0.2717      0.060      4.500      0.000       0.153       0.390\n",
       "50            -0.3485      0.044     -7.924      0.000      -0.435      -0.262\n",
       "51             0.1697      0.045      3.771      0.000       0.082       0.258\n",
       "52             0.2225      0.043      5.234      0.000       0.139       0.306\n",
       "54            -0.2369      0.047     -5.018      0.000      -0.329      -0.144\n",
       "56            -0.1708      0.045     -3.790      0.000      -0.259      -0.082\n",
       "57             0.1477      0.050      2.974      0.003       0.050       0.245\n",
       "58            -0.1339      0.052     -2.592      0.010      -0.235      -0.033\n",
       "66            -0.1710      0.054     -3.168      0.002      -0.277      -0.065\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_log_sm = sm.add_constant(X_train_log[cols])\n",
    "log2 = sm.GLM(y_train_log, X_train_log_sm, family = sm.families.Binomial())\n",
    "model2 = log2.fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12122    0.011996\n",
       "18659    0.058432\n",
       "5658     0.167903\n",
       "1434     0.420265\n",
       "4636     0.549646\n",
       "16841    0.008602\n",
       "29995    0.012482\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the predicted probabilities\n",
    "y_train_log_pred = model2.predict(X_train_log_sm)\n",
    "y_train_log_pred[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0119962 , 0.05843186, 0.16790275, 0.42026527, 0.54964605,\n",
       "       0.00860176, 0.01248236])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log_pred = y_train_log_pred.values.reshape(-1)\n",
    "y_train_log_pred[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.167903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.420265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.549646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_probability\n",
       "0      0           0.011996\n",
       "1      0           0.058432\n",
       "2      0           0.167903\n",
       "3      1           0.420265\n",
       "4      1           0.549646"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log_df = pd.DataFrame({'Churn': y_train_log.values, 'Churn_probability':y_train_log_pred})\n",
    "y_train_log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating the new churn column based on threshold limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_probability</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.167903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.420265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.549646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_probability  Predicted\n",
       "0      0           0.011996          0\n",
       "1      0           0.058432          0\n",
       "2      0           0.167903          0\n",
       "3      1           0.420265          0\n",
       "4      1           0.549646          1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log_df['Predicted'] = y_train_log_df['Churn_probability'].map(lambda x: 1 if x > 0.5 else 0)\n",
    "y_train_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18937,   285],\n",
       "       [ 1320,   471]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_train_log_df['Churn'], y_train_log_df['Predicted'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.923618712225765\n"
     ]
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "print(metrics.accuracy_score(y_train_log_df['Churn'], y_train_log_df['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>54</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features  VIF\n",
       "0          0  1.0\n",
       "13        38  1.0\n",
       "23        58  1.0\n",
       "22        57  1.0\n",
       "21        56  1.0\n",
       "20        54  1.0\n",
       "19        52  1.0\n",
       "18        51  1.0\n",
       "17        50  1.0\n",
       "16        48  1.0\n",
       "15        47  1.0\n",
       "14        43  1.0\n",
       "12        37  1.0\n",
       "1          1  1.0\n",
       "11        34  1.0\n",
       "10        28  1.0\n",
       "9         25  1.0\n",
       "8         21  1.0\n",
       "7         20  1.0\n",
       "6         17  1.0\n",
       "5         16  1.0\n",
       "4         15  1.0\n",
       "3         14  1.0\n",
       "2          6  1.0\n",
       "24        66  1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train_log[cols].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train_log[cols].values, i) for i in range(X_train_log[cols].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VIF values are good to go along with the p values in the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics beyond accuracy\n",
    "TP = confusion_matrix[1,1] # true positive \n",
    "TN = confusion_matrix[0,0] # true negatives\n",
    "FP = confusion_matrix[0,1] # false positives\n",
    "FN = confusion_matrix[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2629815745393635"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851732389969826"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014826761003017375\n"
     ]
    }
   ],
   "source": [
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(FP/ float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.623015873015873\n"
     ]
    }
   ],
   "source": [
    "# positive predictive value \n",
    "print (TP / float(TP+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the optimal cut-off point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the tradeoff between the sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_probability</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058432</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.167903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.420265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.549646</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_probability  Predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  \\\n",
       "0      0           0.011996          0    1    0    0    0    0    0    0   \n",
       "1      0           0.058432          0    1    0    0    0    0    0    0   \n",
       "2      0           0.167903          0    1    1    0    0    0    0    0   \n",
       "3      1           0.420265          0    1    1    1    1    1    0    0   \n",
       "4      1           0.549646          1    1    1    1    1    1    1    0   \n",
       "\n",
       "   0.7  0.8  0.9  \n",
       "0    0    0    0  \n",
       "1    0    0    0  \n",
       "2    0    0    0  \n",
       "3    0    0    0  \n",
       "4    0    0    0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create columns with different probability cutoffs \n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_log_df[i]= y_train_log_df['Churn_probability'].map(lambda x: 1 if x > i else 0)\n",
    "y_train_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prob  accuracy     sensi     speci\n",
      "0.0   0.0  0.085233  1.000000  0.000000\n",
      "0.1   0.1  0.833056  0.797320  0.836385\n",
      "0.2   0.2  0.904630  0.686767  0.924930\n",
      "0.3   0.3  0.921905  0.568398  0.954843\n",
      "0.4   0.4  0.926522  0.427694  0.973000\n",
      "0.5   0.5  0.923619  0.262982  0.985173\n",
      "0.6   0.6  0.920716  0.144612  0.993029\n",
      "0.7   0.7  0.918193  0.074819  0.996775\n",
      "0.8   0.8  0.916385  0.030709  0.998908\n",
      "0.9   0.9  0.915100  0.005025  0.999896\n"
     ]
    }
   ],
   "source": [
    "# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\n",
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_log_df.Churn, y_train_log_df[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot accuracy sensitivity and specificity for various probabilities.\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_probability</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>final_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058432</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.167903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.420265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.549646</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_probability  Predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  \\\n",
       "0      0           0.011996          0    1    0    0    0    0    0    0   \n",
       "1      0           0.058432          0    1    0    0    0    0    0    0   \n",
       "2      0           0.167903          0    1    1    0    0    0    0    0   \n",
       "3      1           0.420265          0    1    1    1    1    1    0    0   \n",
       "4      1           0.549646          1    1    1    1    1    1    1    0   \n",
       "\n",
       "   0.7  0.8  0.9  final_predicted  \n",
       "0    0    0    0                0  \n",
       "1    0    0    0                0  \n",
       "2    0    0    0                1  \n",
       "3    0    0    0                1  \n",
       "4    0    0    0                1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log_df['final_predicted'] = y_train_log_df.Churn_probability.map( lambda x: 1 if x > 0.1 else 0)\n",
    "\n",
    "y_train_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8330557274068434"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the overall accuracy.\n",
    "metrics.accuracy_score(y_train_log_df.Churn, y_train_log_df.final_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16077,  3145],\n",
       "       [  363,  1428]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_2 = metrics.confusion_matrix(y_train_log_df.Churn, y_train_log_df.final_predicted )\n",
    "confusion_matrix_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion_matrix_2[1,1] # true positive \n",
    "TN = confusion_matrix_2[0,0] # true negatives\n",
    "FP = confusion_matrix_2[0,1] # false positives\n",
    "FN = confusion_matrix_2[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7973199329983249"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the sensitivity of our logistic regression model\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8363853917386328"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us calculate specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and recall for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18937,   285],\n",
       "       [ 1320,   471]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_train_log_df.Churn, y_train_log_df.Predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.623015873015873"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion[1,1]/(confusion[0,1]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2629815745393635"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion[1,1]/(confusion[1,0]+confusion[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & recall tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        0\n",
       " 1        0\n",
       " 2        0\n",
       " 3        1\n",
       " 4        1\n",
       "         ..\n",
       " 21008    0\n",
       " 21009    0\n",
       " 21010    1\n",
       " 21011    0\n",
       " 21012    0\n",
       " Name: Churn, Length: 21013, dtype: int64,\n",
       " 0        0\n",
       " 1        0\n",
       " 2        0\n",
       " 3        0\n",
       " 4        1\n",
       "         ..\n",
       " 21008    0\n",
       " 21009    0\n",
       " 21010    0\n",
       " 21011    0\n",
       " 21012    0\n",
       " Name: Predicted, Length: 21013, dtype: int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log_df.Churn, y_train_log_df.Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_log_df.Churn, y_train_log_df.Churn_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_log_sm = sm.add_constant(X_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
