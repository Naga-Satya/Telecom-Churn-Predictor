{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data for high performance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>tot_monthly_recharge_6</th>\n",
       "      <th>tot_monthly_recharge_7</th>\n",
       "      <th>average_recharge_6_7</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1069.180</td>\n",
       "      <td>1349.850</td>\n",
       "      <td>1519.213488</td>\n",
       "      <td>57.84</td>\n",
       "      <td>54.68</td>\n",
       "      <td>52.29</td>\n",
       "      <td>453.43</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>57.74</td>\n",
       "      <td>19.38</td>\n",
       "      <td>18.74</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.721</td>\n",
       "      <td>492.223</td>\n",
       "      <td>137.362000</td>\n",
       "      <td>413.69</td>\n",
       "      <td>351.03</td>\n",
       "      <td>35.08</td>\n",
       "      <td>94.66</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>21.03</td>\n",
       "      <td>910.65</td>\n",
       "      <td>122.16</td>\n",
       "      <td>437.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>492.846</td>\n",
       "      <td>205.671</td>\n",
       "      <td>593.260000</td>\n",
       "      <td>501.76</td>\n",
       "      <td>108.39</td>\n",
       "      <td>534.24</td>\n",
       "      <td>413.31</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>507.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>430.975</td>\n",
       "      <td>299.869</td>\n",
       "      <td>187.894000</td>\n",
       "      <td>50.51</td>\n",
       "      <td>74.01</td>\n",
       "      <td>70.61</td>\n",
       "      <td>296.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>21.89</td>\n",
       "      <td>570.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>690.008</td>\n",
       "      <td>18.980</td>\n",
       "      <td>25.499000</td>\n",
       "      <td>1185.91</td>\n",
       "      <td>9.28</td>\n",
       "      <td>7.79</td>\n",
       "      <td>61.64</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>816.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou    arpu_6    arpu_7  \\\n",
       "0             0.0             0.0             0.0  1069.180  1349.850   \n",
       "1             0.0             0.0             0.0   378.721   492.223   \n",
       "2             0.0             0.0             0.0   492.846   205.671   \n",
       "3             0.0             0.0             0.0   430.975   299.869   \n",
       "4             0.0             0.0             0.0   690.008    18.980   \n",
       "\n",
       "        arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  ...  \\\n",
       "0  1519.213488        57.84        54.68        52.29        453.43  ...   \n",
       "1   137.362000       413.69       351.03        35.08         94.66  ...   \n",
       "2   593.260000       501.76       108.39       534.24        413.31  ...   \n",
       "3   187.894000        50.51        74.01        70.61        296.29  ...   \n",
       "4    25.499000      1185.91         9.28         7.79         61.64  ...   \n",
       "\n",
       "   fb_user_7  fb_user_8     aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \\\n",
       "0       -1.0       -1.0   802.0       57.74       19.38       18.74   \n",
       "1        1.0        1.0   315.0       21.03      910.65      122.16   \n",
       "2       -1.0        1.0  2607.0        0.00        0.00        0.00   \n",
       "3       -1.0       -1.0   511.0        0.00        2.45       21.89   \n",
       "4       -1.0       -1.0   667.0        0.00        0.00        0.00   \n",
       "\n",
       "   tot_monthly_recharge_6  tot_monthly_recharge_7  average_recharge_6_7  churn  \n",
       "0                  1580.0                   790.0                1185.0      1  \n",
       "1                   437.0                   603.0                 520.0      0  \n",
       "2                   507.0                   253.0                 380.0      0  \n",
       "3                   570.0                   348.0                 459.0      0  \n",
       "4                   816.0                     0.0                 408.0      0  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_perf_df = pd.read_csv(\"data_for_high_performance_models.csv\")\n",
    "high_perf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30019, 158)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_perf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Storing the target varible in the target_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = high_perf_df['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30019, 157)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_perf_df.drop('churn', axis = 1, inplace = True)\n",
    "high_perf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling before performing the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>tot_monthly_recharge_6</th>\n",
       "      <th>tot_monthly_recharge_7</th>\n",
       "      <th>average_recharge_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.636538</td>\n",
       "      <td>2.510202</td>\n",
       "      <td>2.917916</td>\n",
       "      <td>-0.632765</td>\n",
       "      <td>-0.638199</td>\n",
       "      <td>-0.582044</td>\n",
       "      <td>0.183719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>-0.782245</td>\n",
       "      <td>-0.778856</td>\n",
       "      <td>-0.474119</td>\n",
       "      <td>-0.182020</td>\n",
       "      <td>-0.345100</td>\n",
       "      <td>-0.325309</td>\n",
       "      <td>2.459186</td>\n",
       "      <td>0.303607</td>\n",
       "      <td>1.619414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621115</td>\n",
       "      <td>-0.254252</td>\n",
       "      <td>-1.102039</td>\n",
       "      <td>0.447605</td>\n",
       "      <td>0.226780</td>\n",
       "      <td>-0.636276</td>\n",
       "      <td>-0.848816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>1.340344</td>\n",
       "      <td>1.379308</td>\n",
       "      <td>-0.990277</td>\n",
       "      <td>-0.336839</td>\n",
       "      <td>3.261082</td>\n",
       "      <td>0.130323</td>\n",
       "      <td>-0.647940</td>\n",
       "      <td>-0.188103</td>\n",
       "      <td>-0.502097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.247950</td>\n",
       "      <td>-1.177916</td>\n",
       "      <td>0.224218</td>\n",
       "      <td>0.714988</td>\n",
       "      <td>-0.481432</td>\n",
       "      <td>0.936688</td>\n",
       "      <td>0.068254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>-0.782245</td>\n",
       "      <td>1.379308</td>\n",
       "      <td>1.438951</td>\n",
       "      <td>-0.425530</td>\n",
       "      <td>-0.423514</td>\n",
       "      <td>-0.407870</td>\n",
       "      <td>-0.457652</td>\n",
       "      <td>-1.108415</td>\n",
       "      <td>-0.948731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.450255</td>\n",
       "      <td>-0.874281</td>\n",
       "      <td>-0.955036</td>\n",
       "      <td>-0.655019</td>\n",
       "      <td>-0.581779</td>\n",
       "      <td>-0.524313</td>\n",
       "      <td>-0.268528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>-0.782245</td>\n",
       "      <td>-0.778856</td>\n",
       "      <td>-0.782542</td>\n",
       "      <td>-0.425530</td>\n",
       "      <td>-0.413601</td>\n",
       "      <td>-0.311431</td>\n",
       "      <td>-0.286393</td>\n",
       "      <td>-0.858616</td>\n",
       "      <td>-0.696702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396727</td>\n",
       "      <td>-1.779691</td>\n",
       "      <td>-1.427460</td>\n",
       "      <td>2.792086</td>\n",
       "      <td>-0.770712</td>\n",
       "      <td>-0.722273</td>\n",
       "      <td>-0.943847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>-0.782245</td>\n",
       "      <td>-0.778856</td>\n",
       "      <td>-0.617202</td>\n",
       "      <td>-0.425530</td>\n",
       "      <td>-0.423514</td>\n",
       "      <td>-0.407870</td>\n",
       "      <td>0.382332</td>\n",
       "      <td>-1.773670</td>\n",
       "      <td>-0.859404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou    arpu_6    arpu_7  \\\n",
       "0             0.0             0.0             0.0  1.636538  2.510202   \n",
       "1             0.0             0.0             0.0 -0.621115 -0.254252   \n",
       "2             0.0             0.0             0.0 -0.247950 -1.177916   \n",
       "3             0.0             0.0             0.0 -0.450255 -0.874281   \n",
       "4             0.0             0.0             0.0  0.396727 -1.779691   \n",
       "\n",
       "     arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  ...  \\\n",
       "0  2.917916    -0.632765    -0.638199    -0.582044      0.183719  ...   \n",
       "1 -1.102039     0.447605     0.226780    -0.636276     -0.848816  ...   \n",
       "2  0.224218     0.714988    -0.481432     0.936688      0.068254  ...   \n",
       "3 -0.955036    -0.655019    -0.581779    -0.524313     -0.268528  ...   \n",
       "4 -1.427460     2.792086    -0.770712    -0.722273     -0.943847  ...   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8       aon  aug_vbc_3g  jul_vbc_3g  \\\n",
       "0  -0.769198  -0.782245  -0.778856 -0.474119   -0.182020   -0.345100   \n",
       "1  -0.769198   1.340344   1.379308 -0.990277   -0.336839    3.261082   \n",
       "2  -0.769198  -0.782245   1.379308  1.438951   -0.425530   -0.423514   \n",
       "3  -0.769198  -0.782245  -0.778856 -0.782542   -0.425530   -0.413601   \n",
       "4  -0.769198  -0.782245  -0.778856 -0.617202   -0.425530   -0.423514   \n",
       "\n",
       "   jun_vbc_3g  tot_monthly_recharge_6  tot_monthly_recharge_7  \\\n",
       "0   -0.325309                2.459186                0.303607   \n",
       "1    0.130323               -0.647940               -0.188103   \n",
       "2   -0.407870               -0.457652               -1.108415   \n",
       "3   -0.311431               -0.286393               -0.858616   \n",
       "4   -0.407870                0.382332               -1.773670   \n",
       "\n",
       "   average_recharge_6_7  \n",
       "0              1.619414  \n",
       "1             -0.502097  \n",
       "2             -0.948731  \n",
       "3             -0.696702  \n",
       "4             -0.859404  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = high_perf_df.select_dtypes(include = ['int64', 'float64']).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "high_perf_df[num_cols] = scaler.fit_transform(high_perf_df[num_cols])\n",
    "high_perf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = high_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = target_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance handling using SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimenstions of churn data before SMOTE\n",
      "Before OverSampling, counts of label '1': 2590\n",
      "Before OverSampling, counts of label '0': 27429\n",
      "After OverSampling, counts of label '1': 27429\n",
      "After OverSampling, counts of label '0': 27429\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Dimenstions of churn data before SMOTE\")\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(y.value_counts()[1]))\n",
    "print(\"Before OverSampling, counts of label '0': {}\".format(y.value_counts()[0]))\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_res = sm.fit_sample(X_train, y.ravel())\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_res==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y is stored in y_res & X in X_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_perf_df = X_train_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA for variables explaining 90% variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54858, 51)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(0.90)\n",
    "pca_data = pca.fit_transform(high_perf_df)\n",
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the cumulative scores of all features\n",
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x212edac9eb8>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, len(var_cumu)+1), var_cumu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA for variables explaining 95% variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54858, 69)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca1 = PCA(0.95)\n",
    "pca_data1 = pca1.fit_transform(high_perf_df)\n",
    "pca_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54858,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the 90% explaining variables into a dataframe named df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.100124</td>\n",
       "      <td>6.940462</td>\n",
       "      <td>-5.042636</td>\n",
       "      <td>5.570421</td>\n",
       "      <td>-0.415971</td>\n",
       "      <td>3.992336</td>\n",
       "      <td>3.533481</td>\n",
       "      <td>3.527090</td>\n",
       "      <td>2.756972</td>\n",
       "      <td>-2.835635</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053495</td>\n",
       "      <td>1.986230</td>\n",
       "      <td>0.141430</td>\n",
       "      <td>-0.845111</td>\n",
       "      <td>-1.572229</td>\n",
       "      <td>-1.591986</td>\n",
       "      <td>-1.886321</td>\n",
       "      <td>-0.435356</td>\n",
       "      <td>2.303196</td>\n",
       "      <td>1.152844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779068</td>\n",
       "      <td>-2.939521</td>\n",
       "      <td>1.333554</td>\n",
       "      <td>-2.846521</td>\n",
       "      <td>-1.393756</td>\n",
       "      <td>-0.315421</td>\n",
       "      <td>-1.386249</td>\n",
       "      <td>-0.474549</td>\n",
       "      <td>0.249651</td>\n",
       "      <td>-0.066193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428911</td>\n",
       "      <td>0.671149</td>\n",
       "      <td>-0.410348</td>\n",
       "      <td>0.132940</td>\n",
       "      <td>-0.100489</td>\n",
       "      <td>-0.678914</td>\n",
       "      <td>-0.307184</td>\n",
       "      <td>1.581666</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>-1.493484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.385466</td>\n",
       "      <td>3.417318</td>\n",
       "      <td>-1.399256</td>\n",
       "      <td>1.038634</td>\n",
       "      <td>-2.511640</td>\n",
       "      <td>7.418871</td>\n",
       "      <td>3.312090</td>\n",
       "      <td>7.673043</td>\n",
       "      <td>1.857023</td>\n",
       "      <td>-2.532117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.851799</td>\n",
       "      <td>-2.071557</td>\n",
       "      <td>-0.760559</td>\n",
       "      <td>0.282627</td>\n",
       "      <td>-1.804087</td>\n",
       "      <td>-0.202911</td>\n",
       "      <td>-1.209008</td>\n",
       "      <td>-1.311449</td>\n",
       "      <td>-1.334448</td>\n",
       "      <td>-0.035679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.842204</td>\n",
       "      <td>-0.244071</td>\n",
       "      <td>-3.673945</td>\n",
       "      <td>0.177725</td>\n",
       "      <td>-0.878501</td>\n",
       "      <td>1.003283</td>\n",
       "      <td>1.665118</td>\n",
       "      <td>1.951179</td>\n",
       "      <td>-0.646478</td>\n",
       "      <td>0.518702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142733</td>\n",
       "      <td>0.842493</td>\n",
       "      <td>-0.468020</td>\n",
       "      <td>-0.107110</td>\n",
       "      <td>-0.313202</td>\n",
       "      <td>-0.364883</td>\n",
       "      <td>-0.107818</td>\n",
       "      <td>-0.191168</td>\n",
       "      <td>-0.163325</td>\n",
       "      <td>-0.540525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.029901</td>\n",
       "      <td>-2.681081</td>\n",
       "      <td>-0.693899</td>\n",
       "      <td>-0.611770</td>\n",
       "      <td>2.240781</td>\n",
       "      <td>-1.313320</td>\n",
       "      <td>-1.158906</td>\n",
       "      <td>2.034719</td>\n",
       "      <td>-0.505274</td>\n",
       "      <td>-1.332094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295636</td>\n",
       "      <td>0.189776</td>\n",
       "      <td>-0.344005</td>\n",
       "      <td>-0.274224</td>\n",
       "      <td>-0.038747</td>\n",
       "      <td>0.070401</td>\n",
       "      <td>0.117535</td>\n",
       "      <td>0.157665</td>\n",
       "      <td>0.379329</td>\n",
       "      <td>0.097534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  6.100124  6.940462 -5.042636  5.570421 -0.415971  3.992336  3.533481   \n",
       "1  0.779068 -2.939521  1.333554 -2.846521 -1.393756 -0.315421 -1.386249   \n",
       "2  1.385466  3.417318 -1.399256  1.038634 -2.511640  7.418871  3.312090   \n",
       "3 -0.842204 -0.244071 -3.673945  0.177725 -0.878501  1.003283  1.665118   \n",
       "4 -5.029901 -2.681081 -0.693899 -0.611770  2.240781 -1.313320 -1.158906   \n",
       "\n",
       "         7         8         9   ...        41        42        43        44  \\\n",
       "0  3.527090  2.756972 -2.835635  ... -1.053495  1.986230  0.141430 -0.845111   \n",
       "1 -0.474549  0.249651 -0.066193  ...  0.428911  0.671149 -0.410348  0.132940   \n",
       "2  7.673043  1.857023 -2.532117  ... -0.851799 -2.071557 -0.760559  0.282627   \n",
       "3  1.951179 -0.646478  0.518702  ...  0.142733  0.842493 -0.468020 -0.107110   \n",
       "4  2.034719 -0.505274 -1.332094  ... -0.295636  0.189776 -0.344005 -0.274224   \n",
       "\n",
       "         45        46        47        48        49        50  \n",
       "0 -1.572229 -1.591986 -1.886321 -0.435356  2.303196  1.152844  \n",
       "1 -0.100489 -0.678914 -0.307184  1.581666  0.702894 -1.493484  \n",
       "2 -1.804087 -0.202911 -1.209008 -1.311449 -1.334448 -0.035679  \n",
       "3 -0.313202 -0.364883 -0.107818 -0.191168 -0.163325 -0.540525  \n",
       "4 -0.038747  0.070401  0.117535  0.157665  0.379329  0.097534  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca = pd.DataFrame(pca_data)\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model ( high performace model 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a copy of dataframe for the random forest model named as df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = df_pca.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54858, 51)\n"
     ]
    }
   ],
   "source": [
    "print(df_rf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54858, 51)\n",
      "(54858,)\n"
     ]
    }
   ],
   "source": [
    "X_rf = df_rf\n",
    "y_rf = y_res\n",
    "# y_rf = np.asarray(y_rf, dtype=\"|S6\")\n",
    "print(X_rf.shape)\n",
    "print(y_rf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38400, 51)\n",
      "(38400,)\n",
      "(16458, 51)\n",
      "(16458,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, train_size=0.7, random_state=100)\n",
    "print(X_train_rf.shape)\n",
    "print(y_train_rf.shape)\n",
    "print(X_test_rf.shape)\n",
    "print(y_test_rf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 100, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a parameters grid for GridSearchCV\n",
    "params = {\n",
    "    'max_depth': [2, 4, 8, 10, 12],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'max_features': [2, 3, 6],\n",
    "    'min_samples_split': range(200, 500, 100),\n",
    "    'n_estimators': [100, 150, 200, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = RandomizedSearchCV(estimator=rf, param_distributions=params, \n",
    "                          cv=4, n_jobs=-1, verbose=1, scoring = \"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                    random_state=100),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [2, 4, 8, 10, 12],\n",
       "                                        'max_features': [2, 3, 6],\n",
       "                                        'min_samples_leaf': range(100, 400, 200),\n",
       "                                        'min_samples_split': range(200, 500, 100),\n",
       "                                        'n_estimators': [100, 150, 200, 30]},\n",
       "                   scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_search.fit(X_train_rf,y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, max_features=2, min_samples_leaf=100,\n",
       "                       min_samples_split=300, n_estimators=150, n_jobs=-1,\n",
       "                       random_state=100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results for the high performance model 1 ( Random Forest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.84296875\n",
      "Train Confusion Matrix:\n",
      "[[16309  2857]\n",
      " [ 3173 16061]]\n",
      "--------------------------------------------------\n",
      "Test Accuracy : 0.8388625592417062\n",
      "Test Confusion Matrix:\n",
      "[[7010 1253]\n",
      " [1399 6796]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Train Accuracy :\", accuracy_score(y_train_rf, rf_best.predict(X_train_rf)))\n",
    "print(\"Train Confusion Matrix:\")\n",
    "print(confusion_matrix(y_train_rf, rf_best.predict(X_train_rf)))\n",
    "print(\"-\"*50)\n",
    "print(\"Test Accuracy :\", accuracy_score(y_test_rf, rf_best.predict(X_test_rf)))\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_rf, rf_best.predict(X_test_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      8263\n",
      "           1       0.84      0.83      0.84      8195\n",
      "\n",
      "    accuracy                           0.84     16458\n",
      "   macro avg       0.84      0.84      0.84     16458\n",
      "weighted avg       0.84      0.84      0.84     16458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_rf, rf_best.predict(X_test_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We attained a recall of 84% i.e we are able to predict 84 out of 100 persons who are going to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_rf = 0.83\n",
    "accuracy_rf = 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Treee Model ( high performance model 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a copy of dataframe for the random forest named as df_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt = df_pca.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54858, 51)\n"
     ]
    }
   ],
   "source": [
    "print(df_dt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54858, 51)\n",
      "(54858,)\n"
     ]
    }
   ],
   "source": [
    "X_dt = df_dt\n",
    "y_dt = y_res\n",
    "# y_dt = np.asarray(y_dt, dtype=\"|S6\")\n",
    "print(X_dt.shape)\n",
    "print(y_dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38400, 51)\n",
      "(38400,)\n",
      "(16458, 51)\n",
      "(16458,)\n"
     ]
    }
   ],
   "source": [
    "X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(X_dt, y_dt, train_size = 0.7, random_state = 100)\n",
    "print(X_train_dt.shape)\n",
    "print(y_train_dt.shape)\n",
    "print(X_test_dt.shape)\n",
    "print(y_test_dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a parameters grid for GridSearchCV\n",
    "params = {\n",
    "    'max_depth': [2, 4, 8, 10, 12],\n",
    "    'min_samples_leaf': range(100, 400, 200),\n",
    "    'max_features': [2, 3, 6],\n",
    "    'min_samples_split': range(200, 500, 100),\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = RandomizedSearchCV(estimator=dt, param_distributions=params, \n",
    "                          cv=5, n_jobs=-1, verbose=1, scoring = \"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.55 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=100),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [2, 4, 8, 10, 12],\n",
       "                                        'max_features': [2, 3, 6],\n",
       "                                        'min_samples_leaf': range(100, 400, 200),\n",
       "                                        'min_samples_split': range(200, 500, 100)},\n",
       "                   scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_search.fit(X_train_dt, y_train_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=3,\n",
       "                       min_samples_leaf=300, min_samples_split=400,\n",
       "                       random_state=100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72      8263\n",
      "           1       0.72      0.72      0.72      8195\n",
      "\n",
      "    accuracy                           0.72     16458\n",
      "   macro avg       0.72      0.72      0.72     16458\n",
      "weighted avg       0.72      0.72      0.72     16458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_dt, dt_best.predict(X_test_dt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We attained a good recall of 88% i.e We are able to predict 88 persons out of 100 who are actually going to predict\n",
    "- The accuracy score seems a little low, but the business solution needs a recall to fulfil our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_dt = 0.87\n",
    "accuracy_dt = 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model ( high performance model 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = df_pca.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.100124</td>\n",
       "      <td>6.940462</td>\n",
       "      <td>-5.042636</td>\n",
       "      <td>5.570421</td>\n",
       "      <td>-0.415971</td>\n",
       "      <td>3.992336</td>\n",
       "      <td>3.533481</td>\n",
       "      <td>3.527090</td>\n",
       "      <td>2.756972</td>\n",
       "      <td>-2.835635</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053495</td>\n",
       "      <td>1.986230</td>\n",
       "      <td>0.141430</td>\n",
       "      <td>-0.845111</td>\n",
       "      <td>-1.572229</td>\n",
       "      <td>-1.591986</td>\n",
       "      <td>-1.886321</td>\n",
       "      <td>-0.435356</td>\n",
       "      <td>2.303196</td>\n",
       "      <td>1.152844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779068</td>\n",
       "      <td>-2.939521</td>\n",
       "      <td>1.333554</td>\n",
       "      <td>-2.846521</td>\n",
       "      <td>-1.393756</td>\n",
       "      <td>-0.315421</td>\n",
       "      <td>-1.386249</td>\n",
       "      <td>-0.474549</td>\n",
       "      <td>0.249651</td>\n",
       "      <td>-0.066193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428911</td>\n",
       "      <td>0.671149</td>\n",
       "      <td>-0.410348</td>\n",
       "      <td>0.132940</td>\n",
       "      <td>-0.100489</td>\n",
       "      <td>-0.678914</td>\n",
       "      <td>-0.307184</td>\n",
       "      <td>1.581666</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>-1.493484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.385466</td>\n",
       "      <td>3.417318</td>\n",
       "      <td>-1.399256</td>\n",
       "      <td>1.038634</td>\n",
       "      <td>-2.511640</td>\n",
       "      <td>7.418871</td>\n",
       "      <td>3.312090</td>\n",
       "      <td>7.673043</td>\n",
       "      <td>1.857023</td>\n",
       "      <td>-2.532117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.851799</td>\n",
       "      <td>-2.071557</td>\n",
       "      <td>-0.760559</td>\n",
       "      <td>0.282627</td>\n",
       "      <td>-1.804087</td>\n",
       "      <td>-0.202911</td>\n",
       "      <td>-1.209008</td>\n",
       "      <td>-1.311449</td>\n",
       "      <td>-1.334448</td>\n",
       "      <td>-0.035679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.842204</td>\n",
       "      <td>-0.244071</td>\n",
       "      <td>-3.673945</td>\n",
       "      <td>0.177725</td>\n",
       "      <td>-0.878501</td>\n",
       "      <td>1.003283</td>\n",
       "      <td>1.665118</td>\n",
       "      <td>1.951179</td>\n",
       "      <td>-0.646478</td>\n",
       "      <td>0.518702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142733</td>\n",
       "      <td>0.842493</td>\n",
       "      <td>-0.468020</td>\n",
       "      <td>-0.107110</td>\n",
       "      <td>-0.313202</td>\n",
       "      <td>-0.364883</td>\n",
       "      <td>-0.107818</td>\n",
       "      <td>-0.191168</td>\n",
       "      <td>-0.163325</td>\n",
       "      <td>-0.540525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.029901</td>\n",
       "      <td>-2.681081</td>\n",
       "      <td>-0.693899</td>\n",
       "      <td>-0.611770</td>\n",
       "      <td>2.240781</td>\n",
       "      <td>-1.313320</td>\n",
       "      <td>-1.158906</td>\n",
       "      <td>2.034719</td>\n",
       "      <td>-0.505274</td>\n",
       "      <td>-1.332094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295636</td>\n",
       "      <td>0.189776</td>\n",
       "      <td>-0.344005</td>\n",
       "      <td>-0.274224</td>\n",
       "      <td>-0.038747</td>\n",
       "      <td>0.070401</td>\n",
       "      <td>0.117535</td>\n",
       "      <td>0.157665</td>\n",
       "      <td>0.379329</td>\n",
       "      <td>0.097534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  6.100124  6.940462 -5.042636  5.570421 -0.415971  3.992336  3.533481   \n",
       "1  0.779068 -2.939521  1.333554 -2.846521 -1.393756 -0.315421 -1.386249   \n",
       "2  1.385466  3.417318 -1.399256  1.038634 -2.511640  7.418871  3.312090   \n",
       "3 -0.842204 -0.244071 -3.673945  0.177725 -0.878501  1.003283  1.665118   \n",
       "4 -5.029901 -2.681081 -0.693899 -0.611770  2.240781 -1.313320 -1.158906   \n",
       "\n",
       "         7         8         9   ...        41        42        43        44  \\\n",
       "0  3.527090  2.756972 -2.835635  ... -1.053495  1.986230  0.141430 -0.845111   \n",
       "1 -0.474549  0.249651 -0.066193  ...  0.428911  0.671149 -0.410348  0.132940   \n",
       "2  7.673043  1.857023 -2.532117  ... -0.851799 -2.071557 -0.760559  0.282627   \n",
       "3  1.951179 -0.646478  0.518702  ...  0.142733  0.842493 -0.468020 -0.107110   \n",
       "4  2.034719 -0.505274 -1.332094  ... -0.295636  0.189776 -0.344005 -0.274224   \n",
       "\n",
       "         45        46        47        48        49        50  \n",
       "0 -1.572229 -1.591986 -1.886321 -0.435356  2.303196  1.152844  \n",
       "1 -0.100489 -0.678914 -0.307184  1.581666  0.702894 -1.493484  \n",
       "2 -1.804087 -0.202911 -1.209008 -1.311449 -1.334448 -0.035679  \n",
       "3 -0.313202 -0.364883 -0.107818 -0.191168 -0.163325 -0.540525  \n",
       "4 -0.038747  0.070401  0.117535  0.157665  0.379329  0.097534  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.100124</td>\n",
       "      <td>6.940462</td>\n",
       "      <td>-5.042636</td>\n",
       "      <td>5.570421</td>\n",
       "      <td>-0.415971</td>\n",
       "      <td>3.992336</td>\n",
       "      <td>3.533481</td>\n",
       "      <td>3.527090</td>\n",
       "      <td>2.756972</td>\n",
       "      <td>-2.835635</td>\n",
       "      <td>...</td>\n",
       "      <td>1.986230</td>\n",
       "      <td>0.141430</td>\n",
       "      <td>-0.845111</td>\n",
       "      <td>-1.572229</td>\n",
       "      <td>-1.591986</td>\n",
       "      <td>-1.886321</td>\n",
       "      <td>-0.435356</td>\n",
       "      <td>2.303196</td>\n",
       "      <td>1.152844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779068</td>\n",
       "      <td>-2.939521</td>\n",
       "      <td>1.333554</td>\n",
       "      <td>-2.846521</td>\n",
       "      <td>-1.393756</td>\n",
       "      <td>-0.315421</td>\n",
       "      <td>-1.386249</td>\n",
       "      <td>-0.474549</td>\n",
       "      <td>0.249651</td>\n",
       "      <td>-0.066193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671149</td>\n",
       "      <td>-0.410348</td>\n",
       "      <td>0.132940</td>\n",
       "      <td>-0.100489</td>\n",
       "      <td>-0.678914</td>\n",
       "      <td>-0.307184</td>\n",
       "      <td>1.581666</td>\n",
       "      <td>0.702894</td>\n",
       "      <td>-1.493484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.385466</td>\n",
       "      <td>3.417318</td>\n",
       "      <td>-1.399256</td>\n",
       "      <td>1.038634</td>\n",
       "      <td>-2.511640</td>\n",
       "      <td>7.418871</td>\n",
       "      <td>3.312090</td>\n",
       "      <td>7.673043</td>\n",
       "      <td>1.857023</td>\n",
       "      <td>-2.532117</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.071557</td>\n",
       "      <td>-0.760559</td>\n",
       "      <td>0.282627</td>\n",
       "      <td>-1.804087</td>\n",
       "      <td>-0.202911</td>\n",
       "      <td>-1.209008</td>\n",
       "      <td>-1.311449</td>\n",
       "      <td>-1.334448</td>\n",
       "      <td>-0.035679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.842204</td>\n",
       "      <td>-0.244071</td>\n",
       "      <td>-3.673945</td>\n",
       "      <td>0.177725</td>\n",
       "      <td>-0.878501</td>\n",
       "      <td>1.003283</td>\n",
       "      <td>1.665118</td>\n",
       "      <td>1.951179</td>\n",
       "      <td>-0.646478</td>\n",
       "      <td>0.518702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842493</td>\n",
       "      <td>-0.468020</td>\n",
       "      <td>-0.107110</td>\n",
       "      <td>-0.313202</td>\n",
       "      <td>-0.364883</td>\n",
       "      <td>-0.107818</td>\n",
       "      <td>-0.191168</td>\n",
       "      <td>-0.163325</td>\n",
       "      <td>-0.540525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.029901</td>\n",
       "      <td>-2.681081</td>\n",
       "      <td>-0.693899</td>\n",
       "      <td>-0.611770</td>\n",
       "      <td>2.240781</td>\n",
       "      <td>-1.313320</td>\n",
       "      <td>-1.158906</td>\n",
       "      <td>2.034719</td>\n",
       "      <td>-0.505274</td>\n",
       "      <td>-1.332094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189776</td>\n",
       "      <td>-0.344005</td>\n",
       "      <td>-0.274224</td>\n",
       "      <td>-0.038747</td>\n",
       "      <td>0.070401</td>\n",
       "      <td>0.117535</td>\n",
       "      <td>0.157665</td>\n",
       "      <td>0.379329</td>\n",
       "      <td>0.097534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  6.100124  6.940462 -5.042636  5.570421 -0.415971  3.992336  3.533481   \n",
       "1  0.779068 -2.939521  1.333554 -2.846521 -1.393756 -0.315421 -1.386249   \n",
       "2  1.385466  3.417318 -1.399256  1.038634 -2.511640  7.418871  3.312090   \n",
       "3 -0.842204 -0.244071 -3.673945  0.177725 -0.878501  1.003283  1.665118   \n",
       "4 -5.029901 -2.681081 -0.693899 -0.611770  2.240781 -1.313320 -1.158906   \n",
       "\n",
       "          7         8         9  ...        42        43        44        45  \\\n",
       "0  3.527090  2.756972 -2.835635  ...  1.986230  0.141430 -0.845111 -1.572229   \n",
       "1 -0.474549  0.249651 -0.066193  ...  0.671149 -0.410348  0.132940 -0.100489   \n",
       "2  7.673043  1.857023 -2.532117  ... -2.071557 -0.760559  0.282627 -1.804087   \n",
       "3  1.951179 -0.646478  0.518702  ...  0.842493 -0.468020 -0.107110 -0.313202   \n",
       "4  2.034719 -0.505274 -1.332094  ...  0.189776 -0.344005 -0.274224 -0.038747   \n",
       "\n",
       "         46        47        48        49        50  churn  \n",
       "0 -1.591986 -1.886321 -0.435356  2.303196  1.152844      1  \n",
       "1 -0.678914 -0.307184  1.581666  0.702894 -1.493484      0  \n",
       "2 -0.202911 -1.209008 -1.311449 -1.334448 -0.035679      0  \n",
       "3 -0.364883 -0.107818 -0.191168 -0.163325 -0.540525      0  \n",
       "4  0.070401  0.117535  0.157665  0.379329  0.097534      0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log['churn'] = y_res\n",
    "df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log = df_log.drop('churn', axis = 1)\n",
    "y_log = df_log['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38400, 51)\n",
      "(38400,)\n",
      "(16458, 51)\n",
      "(16458,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_log, y_log, train_size=0.7, random_state=100)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Checking he type of variable of y_train\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>churn</td>      <th>  No. Observations:  </th>  <td> 38400</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 38348</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    51</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -14582.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Sep 2020</td> <th>  Deviance:          </th> <td>  29163.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:31:20</td>     <th>  Pearson chi2:      </th> <td>7.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.2312</td> <td>    0.017</td> <td>  -13.876</td> <td> 0.000</td> <td>   -0.264</td> <td>   -0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>     <td>   -0.3965</td> <td>    0.005</td> <td>  -79.479</td> <td> 0.000</td> <td>   -0.406</td> <td>   -0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>   -0.2113</td> <td>    0.005</td> <td>  -43.534</td> <td> 0.000</td> <td>   -0.221</td> <td>   -0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>     <td>    0.1285</td> <td>    0.005</td> <td>   23.363</td> <td> 0.000</td> <td>    0.118</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>     <td>    0.1525</td> <td>    0.006</td> <td>   25.425</td> <td> 0.000</td> <td>    0.141</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>     <td>    0.4534</td> <td>    0.007</td> <td>   62.993</td> <td> 0.000</td> <td>    0.439</td> <td>    0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>     <td>    0.0546</td> <td>    0.007</td> <td>    7.922</td> <td> 0.000</td> <td>    0.041</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>6</th>     <td>   -0.0201</td> <td>    0.007</td> <td>   -2.776</td> <td> 0.005</td> <td>   -0.034</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>7</th>     <td>   -0.0014</td> <td>    0.007</td> <td>   -0.195</td> <td> 0.846</td> <td>   -0.016</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>     <td>    0.1410</td> <td>    0.009</td> <td>   15.664</td> <td> 0.000</td> <td>    0.123</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>     <td>    0.5575</td> <td>    0.011</td> <td>   52.779</td> <td> 0.000</td> <td>    0.537</td> <td>    0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th>    <td>   -0.3932</td> <td>    0.011</td> <td>  -36.225</td> <td> 0.000</td> <td>   -0.414</td> <td>   -0.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th>    <td>   -0.0772</td> <td>    0.012</td> <td>   -6.610</td> <td> 0.000</td> <td>   -0.100</td> <td>   -0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th>    <td>   -0.1455</td> <td>    0.011</td> <td>  -12.701</td> <td> 0.000</td> <td>   -0.168</td> <td>   -0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13</th>    <td>   -0.0911</td> <td>    0.011</td> <td>   -8.173</td> <td> 0.000</td> <td>   -0.113</td> <td>   -0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>14</th>    <td>   -0.0131</td> <td>    0.012</td> <td>   -1.063</td> <td> 0.288</td> <td>   -0.037</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>15</th>    <td>    0.0002</td> <td>    0.012</td> <td>    0.017</td> <td> 0.986</td> <td>   -0.024</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>16</th>    <td>   -0.0145</td> <td>    0.014</td> <td>   -1.059</td> <td> 0.290</td> <td>   -0.041</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17</th>    <td>    0.0835</td> <td>    0.013</td> <td>    6.191</td> <td> 0.000</td> <td>    0.057</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>18</th>    <td>    0.0452</td> <td>    0.013</td> <td>    3.422</td> <td> 0.001</td> <td>    0.019</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>19</th>    <td>   -0.1773</td> <td>    0.013</td> <td>  -13.134</td> <td> 0.000</td> <td>   -0.204</td> <td>   -0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>20</th>    <td>   -0.0516</td> <td>    0.014</td> <td>   -3.612</td> <td> 0.000</td> <td>   -0.080</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21</th>    <td>    0.1259</td> <td>    0.016</td> <td>    7.739</td> <td> 0.000</td> <td>    0.094</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22</th>    <td>    0.1158</td> <td>    0.015</td> <td>    7.556</td> <td> 0.000</td> <td>    0.086</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>23</th>    <td>    0.1789</td> <td>    0.016</td> <td>   11.095</td> <td> 0.000</td> <td>    0.147</td> <td>    0.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>24</th>    <td>   -0.1378</td> <td>    0.016</td> <td>   -8.591</td> <td> 0.000</td> <td>   -0.169</td> <td>   -0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25</th>    <td>    0.1136</td> <td>    0.017</td> <td>    6.792</td> <td> 0.000</td> <td>    0.081</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>26</th>    <td>   -0.0380</td> <td>    0.016</td> <td>   -2.387</td> <td> 0.017</td> <td>   -0.069</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>27</th>    <td>   -0.0612</td> <td>    0.017</td> <td>   -3.691</td> <td> 0.000</td> <td>   -0.094</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28</th>    <td>   -0.0488</td> <td>    0.020</td> <td>   -2.470</td> <td> 0.014</td> <td>   -0.088</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>29</th>    <td>    0.1160</td> <td>    0.018</td> <td>    6.416</td> <td> 0.000</td> <td>    0.081</td> <td>    0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>30</th>    <td>    0.0844</td> <td>    0.018</td> <td>    4.620</td> <td> 0.000</td> <td>    0.049</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>31</th>    <td>   -0.0107</td> <td>    0.017</td> <td>   -0.619</td> <td> 0.536</td> <td>   -0.045</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>32</th>    <td>   -0.0692</td> <td>    0.019</td> <td>   -3.601</td> <td> 0.000</td> <td>   -0.107</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>33</th>    <td>   -0.0308</td> <td>    0.018</td> <td>   -1.710</td> <td> 0.087</td> <td>   -0.066</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>34</th>    <td>   -0.0687</td> <td>    0.019</td> <td>   -3.554</td> <td> 0.000</td> <td>   -0.107</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>35</th>    <td>    0.0902</td> <td>    0.018</td> <td>    4.898</td> <td> 0.000</td> <td>    0.054</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>36</th>    <td>    0.1117</td> <td>    0.018</td> <td>    6.069</td> <td> 0.000</td> <td>    0.076</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>37</th>    <td>    0.0614</td> <td>    0.020</td> <td>    3.107</td> <td> 0.002</td> <td>    0.023</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>38</th>    <td>    0.0031</td> <td>    0.020</td> <td>    0.160</td> <td> 0.873</td> <td>   -0.035</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>39</th>    <td>   -0.1015</td> <td>    0.020</td> <td>   -4.964</td> <td> 0.000</td> <td>   -0.142</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>40</th>    <td>   -0.0003</td> <td>    0.021</td> <td>   -0.014</td> <td> 0.989</td> <td>   -0.042</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>41</th>    <td>   -0.2189</td> <td>    0.022</td> <td>  -10.077</td> <td> 0.000</td> <td>   -0.261</td> <td>   -0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>42</th>    <td>    0.2516</td> <td>    0.021</td> <td>   12.237</td> <td> 0.000</td> <td>    0.211</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>43</th>    <td>   -0.1462</td> <td>    0.022</td> <td>   -6.664</td> <td> 0.000</td> <td>   -0.189</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>44</th>    <td>    0.0570</td> <td>    0.022</td> <td>    2.552</td> <td> 0.011</td> <td>    0.013</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>45</th>    <td>   -0.5212</td> <td>    0.026</td> <td>  -19.699</td> <td> 0.000</td> <td>   -0.573</td> <td>   -0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>46</th>    <td>    0.1040</td> <td>    0.023</td> <td>    4.582</td> <td> 0.000</td> <td>    0.060</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>47</th>    <td>   -0.0648</td> <td>    0.024</td> <td>   -2.742</td> <td> 0.006</td> <td>   -0.111</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>48</th>    <td>    0.0694</td> <td>    0.024</td> <td>    2.838</td> <td> 0.005</td> <td>    0.021</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>49</th>    <td>    0.2333</td> <td>    0.024</td> <td>    9.746</td> <td> 0.000</td> <td>    0.186</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>50</th>    <td>    0.2197</td> <td>    0.024</td> <td>    9.093</td> <td> 0.000</td> <td>    0.172</td> <td>    0.267</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  churn   No. Observations:                38400\n",
       "Model:                            GLM   Df Residuals:                    38348\n",
       "Model Family:                Binomial   Df Model:                           51\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -14582.\n",
       "Date:                Tue, 01 Sep 2020   Deviance:                       29163.\n",
       "Time:                        10:31:20   Pearson chi2:                 7.42e+04\n",
       "No. Iterations:                     6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.2312      0.017    -13.876      0.000      -0.264      -0.199\n",
       "0             -0.3965      0.005    -79.479      0.000      -0.406      -0.387\n",
       "1             -0.2113      0.005    -43.534      0.000      -0.221      -0.202\n",
       "2              0.1285      0.005     23.363      0.000       0.118       0.139\n",
       "3              0.1525      0.006     25.425      0.000       0.141       0.164\n",
       "4              0.4534      0.007     62.993      0.000       0.439       0.467\n",
       "5              0.0546      0.007      7.922      0.000       0.041       0.068\n",
       "6             -0.0201      0.007     -2.776      0.005      -0.034      -0.006\n",
       "7             -0.0014      0.007     -0.195      0.846      -0.016       0.013\n",
       "8              0.1410      0.009     15.664      0.000       0.123       0.159\n",
       "9              0.5575      0.011     52.779      0.000       0.537       0.578\n",
       "10            -0.3932      0.011    -36.225      0.000      -0.414      -0.372\n",
       "11            -0.0772      0.012     -6.610      0.000      -0.100      -0.054\n",
       "12            -0.1455      0.011    -12.701      0.000      -0.168      -0.123\n",
       "13            -0.0911      0.011     -8.173      0.000      -0.113      -0.069\n",
       "14            -0.0131      0.012     -1.063      0.288      -0.037       0.011\n",
       "15             0.0002      0.012      0.017      0.986      -0.024       0.025\n",
       "16            -0.0145      0.014     -1.059      0.290      -0.041       0.012\n",
       "17             0.0835      0.013      6.191      0.000       0.057       0.110\n",
       "18             0.0452      0.013      3.422      0.001       0.019       0.071\n",
       "19            -0.1773      0.013    -13.134      0.000      -0.204      -0.151\n",
       "20            -0.0516      0.014     -3.612      0.000      -0.080      -0.024\n",
       "21             0.1259      0.016      7.739      0.000       0.094       0.158\n",
       "22             0.1158      0.015      7.556      0.000       0.086       0.146\n",
       "23             0.1789      0.016     11.095      0.000       0.147       0.211\n",
       "24            -0.1378      0.016     -8.591      0.000      -0.169      -0.106\n",
       "25             0.1136      0.017      6.792      0.000       0.081       0.146\n",
       "26            -0.0380      0.016     -2.387      0.017      -0.069      -0.007\n",
       "27            -0.0612      0.017     -3.691      0.000      -0.094      -0.029\n",
       "28            -0.0488      0.020     -2.470      0.014      -0.088      -0.010\n",
       "29             0.1160      0.018      6.416      0.000       0.081       0.151\n",
       "30             0.0844      0.018      4.620      0.000       0.049       0.120\n",
       "31            -0.0107      0.017     -0.619      0.536      -0.045       0.023\n",
       "32            -0.0692      0.019     -3.601      0.000      -0.107      -0.032\n",
       "33            -0.0308      0.018     -1.710      0.087      -0.066       0.005\n",
       "34            -0.0687      0.019     -3.554      0.000      -0.107      -0.031\n",
       "35             0.0902      0.018      4.898      0.000       0.054       0.126\n",
       "36             0.1117      0.018      6.069      0.000       0.076       0.148\n",
       "37             0.0614      0.020      3.107      0.002       0.023       0.100\n",
       "38             0.0031      0.020      0.160      0.873      -0.035       0.042\n",
       "39            -0.1015      0.020     -4.964      0.000      -0.142      -0.061\n",
       "40            -0.0003      0.021     -0.014      0.989      -0.042       0.041\n",
       "41            -0.2189      0.022    -10.077      0.000      -0.261      -0.176\n",
       "42             0.2516      0.021     12.237      0.000       0.211       0.292\n",
       "43            -0.1462      0.022     -6.664      0.000      -0.189      -0.103\n",
       "44             0.0570      0.022      2.552      0.011       0.013       0.101\n",
       "45            -0.5212      0.026    -19.699      0.000      -0.573      -0.469\n",
       "46             0.1040      0.023      4.582      0.000       0.060       0.149\n",
       "47            -0.0648      0.024     -2.742      0.006      -0.111      -0.018\n",
       "48             0.0694      0.024      2.838      0.005       0.021       0.117\n",
       "49             0.2333      0.024      9.746      0.000       0.186       0.280\n",
       "50             0.2197      0.024      9.093      0.000       0.172       0.267\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1 = LogisticRegression()\n",
    "rfe1 = RFE(log1, 40)\n",
    "rfe1 = rfe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 0,  1,  2,  3,  4,  5,  8,  9, 10, 11, 12, 13, 17, 19, 20, 21, 22, 23,\n",
      "       24, 25, 27, 28, 29, 30, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46,\n",
      "       47, 48, 49, 50],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "col = X_train.columns[rfe1.support_]\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>churn</td>      <th>  No. Observations:  </th>  <td> 38400</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 38359</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -14597.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Sep 2020</td> <th>  Deviance:          </th> <td>  29194.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:31:24</td>     <th>  Pearson chi2:      </th> <td>7.23e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.2344</td> <td>    0.016</td> <td>  -14.251</td> <td> 0.000</td> <td>   -0.267</td> <td>   -0.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>     <td>   -0.3962</td> <td>    0.005</td> <td>  -80.430</td> <td> 0.000</td> <td>   -0.406</td> <td>   -0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>   -0.2129</td> <td>    0.005</td> <td>  -44.041</td> <td> 0.000</td> <td>   -0.222</td> <td>   -0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>     <td>    0.1281</td> <td>    0.005</td> <td>   23.538</td> <td> 0.000</td> <td>    0.117</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>3</th>     <td>    0.1535</td> <td>    0.006</td> <td>   25.731</td> <td> 0.000</td> <td>    0.142</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>4</th>     <td>    0.4530</td> <td>    0.007</td> <td>   63.041</td> <td> 0.000</td> <td>    0.439</td> <td>    0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>5</th>     <td>    0.0545</td> <td>    0.007</td> <td>    7.969</td> <td> 0.000</td> <td>    0.041</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>8</th>     <td>    0.1406</td> <td>    0.009</td> <td>   15.711</td> <td> 0.000</td> <td>    0.123</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>9</th>     <td>    0.5567</td> <td>    0.011</td> <td>   52.909</td> <td> 0.000</td> <td>    0.536</td> <td>    0.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>10</th>    <td>   -0.3955</td> <td>    0.011</td> <td>  -36.835</td> <td> 0.000</td> <td>   -0.417</td> <td>   -0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>11</th>    <td>   -0.0735</td> <td>    0.012</td> <td>   -6.372</td> <td> 0.000</td> <td>   -0.096</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>12</th>    <td>   -0.1417</td> <td>    0.011</td> <td>  -12.474</td> <td> 0.000</td> <td>   -0.164</td> <td>   -0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>13</th>    <td>   -0.0919</td> <td>    0.011</td> <td>   -8.271</td> <td> 0.000</td> <td>   -0.114</td> <td>   -0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>17</th>    <td>    0.0808</td> <td>    0.013</td> <td>    6.025</td> <td> 0.000</td> <td>    0.055</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>19</th>    <td>   -0.1793</td> <td>    0.013</td> <td>  -13.309</td> <td> 0.000</td> <td>   -0.206</td> <td>   -0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>20</th>    <td>   -0.0537</td> <td>    0.014</td> <td>   -3.759</td> <td> 0.000</td> <td>   -0.082</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>21</th>    <td>    0.1300</td> <td>    0.016</td> <td>    8.056</td> <td> 0.000</td> <td>    0.098</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>22</th>    <td>    0.1156</td> <td>    0.015</td> <td>    7.591</td> <td> 0.000</td> <td>    0.086</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>23</th>    <td>    0.1788</td> <td>    0.016</td> <td>   11.139</td> <td> 0.000</td> <td>    0.147</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>24</th>    <td>   -0.1387</td> <td>    0.016</td> <td>   -8.676</td> <td> 0.000</td> <td>   -0.170</td> <td>   -0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>25</th>    <td>    0.1105</td> <td>    0.017</td> <td>    6.653</td> <td> 0.000</td> <td>    0.078</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>27</th>    <td>   -0.0613</td> <td>    0.017</td> <td>   -3.698</td> <td> 0.000</td> <td>   -0.094</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>28</th>    <td>   -0.0484</td> <td>    0.019</td> <td>   -2.494</td> <td> 0.013</td> <td>   -0.086</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>29</th>    <td>    0.1172</td> <td>    0.018</td> <td>    6.514</td> <td> 0.000</td> <td>    0.082</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>30</th>    <td>    0.0870</td> <td>    0.018</td> <td>    4.819</td> <td> 0.000</td> <td>    0.052</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>32</th>    <td>   -0.0738</td> <td>    0.019</td> <td>   -3.875</td> <td> 0.000</td> <td>   -0.111</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>34</th>    <td>   -0.0705</td> <td>    0.019</td> <td>   -3.655</td> <td> 0.000</td> <td>   -0.108</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>35</th>    <td>    0.0932</td> <td>    0.018</td> <td>    5.090</td> <td> 0.000</td> <td>    0.057</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>36</th>    <td>    0.1098</td> <td>    0.018</td> <td>    5.986</td> <td> 0.000</td> <td>    0.074</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>37</th>    <td>    0.0620</td> <td>    0.020</td> <td>    3.148</td> <td> 0.002</td> <td>    0.023</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>39</th>    <td>   -0.1006</td> <td>    0.020</td> <td>   -4.940</td> <td> 0.000</td> <td>   -0.141</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>41</th>    <td>   -0.2169</td> <td>    0.021</td> <td>  -10.103</td> <td> 0.000</td> <td>   -0.259</td> <td>   -0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>42</th>    <td>    0.2542</td> <td>    0.020</td> <td>   12.411</td> <td> 0.000</td> <td>    0.214</td> <td>    0.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>43</th>    <td>   -0.1454</td> <td>    0.022</td> <td>   -6.651</td> <td> 0.000</td> <td>   -0.188</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>44</th>    <td>    0.0567</td> <td>    0.022</td> <td>    2.540</td> <td> 0.011</td> <td>    0.013</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>45</th>    <td>   -0.5165</td> <td>    0.026</td> <td>  -19.881</td> <td> 0.000</td> <td>   -0.567</td> <td>   -0.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>46</th>    <td>    0.1038</td> <td>    0.023</td> <td>    4.582</td> <td> 0.000</td> <td>    0.059</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>47</th>    <td>   -0.0632</td> <td>    0.024</td> <td>   -2.677</td> <td> 0.007</td> <td>   -0.109</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>48</th>    <td>    0.0635</td> <td>    0.024</td> <td>    2.600</td> <td> 0.009</td> <td>    0.016</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>49</th>    <td>    0.2327</td> <td>    0.024</td> <td>    9.734</td> <td> 0.000</td> <td>    0.186</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>50</th>    <td>    0.2220</td> <td>    0.024</td> <td>    9.208</td> <td> 0.000</td> <td>    0.175</td> <td>    0.269</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  churn   No. Observations:                38400\n",
       "Model:                            GLM   Df Residuals:                    38359\n",
       "Model Family:                Binomial   Df Model:                           40\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -14597.\n",
       "Date:                Tue, 01 Sep 2020   Deviance:                       29194.\n",
       "Time:                        10:31:24   Pearson chi2:                 7.23e+04\n",
       "No. Iterations:                     6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.2344      0.016    -14.251      0.000      -0.267      -0.202\n",
       "0             -0.3962      0.005    -80.430      0.000      -0.406      -0.387\n",
       "1             -0.2129      0.005    -44.041      0.000      -0.222      -0.203\n",
       "2              0.1281      0.005     23.538      0.000       0.117       0.139\n",
       "3              0.1535      0.006     25.731      0.000       0.142       0.165\n",
       "4              0.4530      0.007     63.041      0.000       0.439       0.467\n",
       "5              0.0545      0.007      7.969      0.000       0.041       0.068\n",
       "8              0.1406      0.009     15.711      0.000       0.123       0.158\n",
       "9              0.5567      0.011     52.909      0.000       0.536       0.577\n",
       "10            -0.3955      0.011    -36.835      0.000      -0.417      -0.374\n",
       "11            -0.0735      0.012     -6.372      0.000      -0.096      -0.051\n",
       "12            -0.1417      0.011    -12.474      0.000      -0.164      -0.119\n",
       "13            -0.0919      0.011     -8.271      0.000      -0.114      -0.070\n",
       "17             0.0808      0.013      6.025      0.000       0.055       0.107\n",
       "19            -0.1793      0.013    -13.309      0.000      -0.206      -0.153\n",
       "20            -0.0537      0.014     -3.759      0.000      -0.082      -0.026\n",
       "21             0.1300      0.016      8.056      0.000       0.098       0.162\n",
       "22             0.1156      0.015      7.591      0.000       0.086       0.145\n",
       "23             0.1788      0.016     11.139      0.000       0.147       0.210\n",
       "24            -0.1387      0.016     -8.676      0.000      -0.170      -0.107\n",
       "25             0.1105      0.017      6.653      0.000       0.078       0.143\n",
       "27            -0.0613      0.017     -3.698      0.000      -0.094      -0.029\n",
       "28            -0.0484      0.019     -2.494      0.013      -0.086      -0.010\n",
       "29             0.1172      0.018      6.514      0.000       0.082       0.153\n",
       "30             0.0870      0.018      4.819      0.000       0.052       0.122\n",
       "32            -0.0738      0.019     -3.875      0.000      -0.111      -0.036\n",
       "34            -0.0705      0.019     -3.655      0.000      -0.108      -0.033\n",
       "35             0.0932      0.018      5.090      0.000       0.057       0.129\n",
       "36             0.1098      0.018      5.986      0.000       0.074       0.146\n",
       "37             0.0620      0.020      3.148      0.002       0.023       0.101\n",
       "39            -0.1006      0.020     -4.940      0.000      -0.141      -0.061\n",
       "41            -0.2169      0.021    -10.103      0.000      -0.259      -0.175\n",
       "42             0.2542      0.020     12.411      0.000       0.214       0.294\n",
       "43            -0.1454      0.022     -6.651      0.000      -0.188      -0.103\n",
       "44             0.0567      0.022      2.540      0.011       0.013       0.100\n",
       "45            -0.5165      0.026    -19.881      0.000      -0.567      -0.466\n",
       "46             0.1038      0.023      4.582      0.000       0.059       0.148\n",
       "47            -0.0632      0.024     -2.677      0.007      -0.109      -0.017\n",
       "48             0.0635      0.024      2.600      0.009       0.016       0.111\n",
       "49             0.2327      0.024      9.734      0.000       0.186       0.280\n",
       "50             0.2220      0.024      9.208      0.000       0.175       0.269\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "log2 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "model2 = log2.fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29172    0.008065\n",
       "9013     0.177540\n",
       "8741     0.032071\n",
       "30680    0.936593\n",
       "43716    0.694321\n",
       "17901    0.532962\n",
       "52619    0.604667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the predicted probabilities\n",
    "y_train_pred = model2.predict(X_train_sm)\n",
    "y_train_pred[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00806485, 0.1775397 , 0.03207055, 0.93659278, 0.69432059,\n",
       "       0.53296153, 0.6046665 , 0.33509615, 0.06563537, 0.9302197 ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a dataframe with the actual churn flag and the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>29172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.177540</td>\n",
       "      <td>9013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>8741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.936593</td>\n",
       "      <td>30680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.694321</td>\n",
       "      <td>43716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob     ID\n",
       "0      0    0.008065  29172\n",
       "1      0    0.177540   9013\n",
       "2      0    0.032071   8741\n",
       "3      1    0.936593  30680\n",
       "4      1    0.694321  43716"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Churn':y_train.values, 'Churn_Prob':y_train_pred})\n",
    "y_train_pred_final['ID'] = y_train.index\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>29172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.177540</td>\n",
       "      <td>9013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>8741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.936593</td>\n",
       "      <td>30680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.694321</td>\n",
       "      <td>43716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob     ID  predicted\n",
       "0      0    0.008065  29172          0\n",
       "1      0    0.177540   9013          0\n",
       "2      0    0.032071   8741          0\n",
       "3      1    0.936593  30680          1\n",
       "4      1    0.694321  43716          1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15952  3214]\n",
      " [ 2853 16381]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8420052083333334\n"
     ]
    }
   ],
   "source": [
    "# overall accuracy.\n",
    "accuracy_log = metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted)\n",
    "print(\"Accuracy: {}\".format(accuracy_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516689196215036"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8323072106855891"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Churn, y_train_pred_final.Churn_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_roc(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Optimal cutoff point for the churn value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>29172</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.177540</td>\n",
       "      <td>9013</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032071</td>\n",
       "      <td>8741</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.936593</td>\n",
       "      <td>30680</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.694321</td>\n",
       "      <td>43716</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob     ID  predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  \\\n",
       "0      0    0.008065  29172          0    1    0    0    0    0    0    0   \n",
       "1      0    0.177540   9013          0    1    1    0    0    0    0    0   \n",
       "2      0    0.032071   8741          0    1    0    0    0    0    0    0   \n",
       "3      1    0.936593  30680          1    1    1    1    1    1    1    1   \n",
       "4      1    0.694321  43716          1    1    1    1    1    1    1    1   \n",
       "\n",
       "   0.7  0.8  0.9  \n",
       "0    0    0    0  \n",
       "1    0    0    0  \n",
       "2    0    0    0  \n",
       "3    1    1    1  \n",
       "4    0    0    0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prob  accuracy     sensi     speci\n",
      "0.0   0.0  0.500885  1.000000  0.000000\n",
      "0.1   0.1  0.712083  0.977228  0.445998\n",
      "0.2   0.2  0.775625  0.952480  0.598143\n",
      "0.3   0.3  0.812031  0.925237  0.698424\n",
      "0.4   0.4  0.832396  0.892066  0.772514\n",
      "0.5   0.5  0.842005  0.851669  0.832307\n",
      "0.6   0.6  0.842943  0.808412  0.877596\n",
      "0.7   0.7  0.832656  0.752730  0.912867\n",
      "0.8   0.8  0.796823  0.651191  0.942972\n",
      "0.9   0.9  0.653151  0.333316  0.974121\n"
     ]
    }
   ],
   "source": [
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plottign the tradeoff graph between all the metrics\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seems like our threshold of 0.5 is fine for sensitivity and specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15952,  3214],\n",
       "       [ 2853, 16381]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula for Precision: TP/TP+FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8359785659607043\n"
     ]
    }
   ],
   "source": [
    "precision = confusion[1,1]/(confusion[0,1]+confusion[1,1])\n",
    "print(\"Precision: {}\".format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula for recall: TP/TP+FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8516689196215036\n"
     ]
    }
   ],
   "source": [
    "recall_log = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "print(\"Recall: {}\".format(recall_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F score calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (2 × precision × recall)/(precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F Score: 0.8437508048108373\n"
     ]
    }
   ],
   "source": [
    "f_score = (2*precision*recall_log)/(precision+recall_log)\n",
    "print(\"F Score: {}\".format(f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision & Recall tradeoff graph plottin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like all our metrics i.e sensitivity, specificity, precision & recall performs good at 0.5 threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of Logistic Regression Model ( high performance Model 3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and Recall printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8420052083333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {}\".format(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8359785659607043\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall: {}\".format(confusion[1,1]/(confusion[0,1]+confusion[1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall scores of all 3 high performance models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame(columns = ['Model', 'Accuracy', 'Recall'])\n",
    "performance.loc[0] = ['Logistic Regression', accuracy_log, recall_log]\n",
    "performance.loc[1] = ['Decision Tree', accuracy_dt, recall_dt]\n",
    "performance.loc[2] = ['Random Forest', accuracy_rf, recall_rf]\n",
    "performance.index+=1\n",
    "performance.Recall=performance.Recall.round(4)*100\n",
    "performance.Accuracy=performance.Accuracy.round(4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>84.2</td>\n",
       "      <td>85.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>83.0</td>\n",
       "      <td>87.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Recall\n",
       "1  Logistic Regression      84.2   85.17\n",
       "2        Decision Tree      83.0   87.00\n",
       "3        Random Forest      84.0   83.00"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model ( Interpretable Model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of high_perf_df dataframe prepare the logistic regression model\n",
    "df_logistic = X_train_res.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>tot_monthly_recharge_6</th>\n",
       "      <th>tot_monthly_recharge_7</th>\n",
       "      <th>average_recharge_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.636538</td>\n",
       "      <td>2.510202</td>\n",
       "      <td>2.917916</td>\n",
       "      <td>-0.632765</td>\n",
       "      <td>-0.638199</td>\n",
       "      <td>-0.582044</td>\n",
       "      <td>0.183719</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>-0.782245</td>\n",
       "      <td>-0.778856</td>\n",
       "      <td>-0.474119</td>\n",
       "      <td>-0.182020</td>\n",
       "      <td>-0.345100</td>\n",
       "      <td>-0.325309</td>\n",
       "      <td>2.459186</td>\n",
       "      <td>0.303607</td>\n",
       "      <td>1.619414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.621115</td>\n",
       "      <td>-0.254252</td>\n",
       "      <td>-1.102039</td>\n",
       "      <td>0.447605</td>\n",
       "      <td>0.226780</td>\n",
       "      <td>-0.636276</td>\n",
       "      <td>-0.848816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>1.340344</td>\n",
       "      <td>1.379308</td>\n",
       "      <td>-0.990277</td>\n",
       "      <td>-0.336839</td>\n",
       "      <td>3.261082</td>\n",
       "      <td>0.130323</td>\n",
       "      <td>-0.647940</td>\n",
       "      <td>-0.188103</td>\n",
       "      <td>-0.502097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.247950</td>\n",
       "      <td>-1.177916</td>\n",
       "      <td>0.224218</td>\n",
       "      <td>0.714988</td>\n",
       "      <td>-0.481432</td>\n",
       "      <td>0.936688</td>\n",
       "      <td>0.068254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>-0.782245</td>\n",
       "      <td>1.379308</td>\n",
       "      <td>1.438951</td>\n",
       "      <td>-0.425530</td>\n",
       "      <td>-0.423514</td>\n",
       "      <td>-0.407870</td>\n",
       "      <td>-0.457652</td>\n",
       "      <td>-1.108415</td>\n",
       "      <td>-0.948731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.450255</td>\n",
       "      <td>-0.874281</td>\n",
       "      <td>-0.955036</td>\n",
       "      <td>-0.655019</td>\n",
       "      <td>-0.581779</td>\n",
       "      <td>-0.524313</td>\n",
       "      <td>-0.268528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>-0.782245</td>\n",
       "      <td>-0.778856</td>\n",
       "      <td>-0.782542</td>\n",
       "      <td>-0.425530</td>\n",
       "      <td>-0.413601</td>\n",
       "      <td>-0.311431</td>\n",
       "      <td>-0.286393</td>\n",
       "      <td>-0.858616</td>\n",
       "      <td>-0.696702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396727</td>\n",
       "      <td>-1.779691</td>\n",
       "      <td>-1.427460</td>\n",
       "      <td>2.792086</td>\n",
       "      <td>-0.770712</td>\n",
       "      <td>-0.722273</td>\n",
       "      <td>-0.943847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.769198</td>\n",
       "      <td>-0.782245</td>\n",
       "      <td>-0.778856</td>\n",
       "      <td>-0.617202</td>\n",
       "      <td>-0.425530</td>\n",
       "      <td>-0.423514</td>\n",
       "      <td>-0.407870</td>\n",
       "      <td>0.382332</td>\n",
       "      <td>-1.773670</td>\n",
       "      <td>-0.859404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou    arpu_6    arpu_7  \\\n",
       "0             0.0             0.0             0.0  1.636538  2.510202   \n",
       "1             0.0             0.0             0.0 -0.621115 -0.254252   \n",
       "2             0.0             0.0             0.0 -0.247950 -1.177916   \n",
       "3             0.0             0.0             0.0 -0.450255 -0.874281   \n",
       "4             0.0             0.0             0.0  0.396727 -1.779691   \n",
       "\n",
       "     arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  offnet_mou_6  ...  \\\n",
       "0  2.917916    -0.632765    -0.638199    -0.582044      0.183719  ...   \n",
       "1 -1.102039     0.447605     0.226780    -0.636276     -0.848816  ...   \n",
       "2  0.224218     0.714988    -0.481432     0.936688      0.068254  ...   \n",
       "3 -0.955036    -0.655019    -0.581779    -0.524313     -0.268528  ...   \n",
       "4 -1.427460     2.792086    -0.770712    -0.722273     -0.943847  ...   \n",
       "\n",
       "   fb_user_6  fb_user_7  fb_user_8       aon  aug_vbc_3g  jul_vbc_3g  \\\n",
       "0  -0.769198  -0.782245  -0.778856 -0.474119   -0.182020   -0.345100   \n",
       "1  -0.769198   1.340344   1.379308 -0.990277   -0.336839    3.261082   \n",
       "2  -0.769198  -0.782245   1.379308  1.438951   -0.425530   -0.423514   \n",
       "3  -0.769198  -0.782245  -0.778856 -0.782542   -0.425530   -0.413601   \n",
       "4  -0.769198  -0.782245  -0.778856 -0.617202   -0.425530   -0.423514   \n",
       "\n",
       "   jun_vbc_3g  tot_monthly_recharge_6  tot_monthly_recharge_7  \\\n",
       "0   -0.325309                2.459186                0.303607   \n",
       "1    0.130323               -0.647940               -0.188103   \n",
       "2   -0.407870               -0.457652               -1.108415   \n",
       "3   -0.311431               -0.286393               -0.858616   \n",
       "4   -0.407870                0.382332               -1.773670   \n",
       "\n",
       "   average_recharge_6_7  \n",
       "0              1.619414  \n",
       "1             -0.502097  \n",
       "2             -0.948731  \n",
       "3             -0.696702  \n",
       "4             -0.859404  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_logistic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_logistic['churn'] = y_res\n",
    "# df_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_logistic = df_logistic\n",
    "y_logistic = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38400, 157)\n",
      "(38400,)\n",
      "(16458, 157)\n",
      "(16458,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_logistic, y_logistic, train_size=0.7, random_state=100)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Checking he type of variable of y_train\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 38400</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 38251</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>   148</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -13412.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Sep 2020</td> <th>  Deviance:          </th> <td>  26824.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:43:24</td>     <th>  Pearson chi2:      </th> <td>1.57e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>100</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                  <td>   -2.0125</td> <td>    0.029</td> <td>  -68.766</td> <td> 0.000</td> <td>   -2.070</td> <td>   -1.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2o_mou</th>         <td> 3.656e-14</td> <td> 8.15e-15</td> <td>    4.488</td> <td> 0.000</td> <td> 2.06e-14</td> <td> 5.25e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2o_mou</th>         <td> 3.713e-13</td> <td> 9.94e-14</td> <td>    3.733</td> <td> 0.000</td> <td> 1.76e-13</td> <td> 5.66e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2o_mou</th>         <td>-1.705e-13</td> <td> 3.29e-14</td> <td>   -5.175</td> <td> 0.000</td> <td>-2.35e-13</td> <td>-1.06e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_6</th>                 <td>    0.1148</td> <td>    0.056</td> <td>    2.068</td> <td> 0.039</td> <td>    0.006</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_7</th>                 <td>    0.3365</td> <td>    0.061</td> <td>    5.543</td> <td> 0.000</td> <td>    0.218</td> <td>    0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_8</th>                 <td>    0.5755</td> <td>    0.071</td> <td>    8.096</td> <td> 0.000</td> <td>    0.436</td> <td>    0.715</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_6</th>            <td>    0.5111</td> <td>    0.110</td> <td>    4.652</td> <td> 0.000</td> <td>    0.296</td> <td>    0.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_7</th>            <td>    0.1440</td> <td>    0.133</td> <td>    1.085</td> <td> 0.278</td> <td>   -0.116</td> <td>    0.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>            <td>   -0.0802</td> <td>    0.146</td> <td>   -0.551</td> <td> 0.582</td> <td>   -0.366</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_6</th>           <td>    0.1833</td> <td>    0.097</td> <td>    1.886</td> <td> 0.059</td> <td>   -0.007</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_7</th>           <td>    0.1881</td> <td>    0.121</td> <td>    1.559</td> <td> 0.119</td> <td>   -0.048</td> <td>    0.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>           <td>    0.1282</td> <td>    0.117</td> <td>    1.095</td> <td> 0.273</td> <td>   -0.101</td> <td>    0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_6</th>          <td>   -0.0372</td> <td>    0.033</td> <td>   -1.116</td> <td> 0.264</td> <td>   -0.102</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_7</th>          <td>    0.1237</td> <td>    0.033</td> <td>    3.793</td> <td> 0.000</td> <td>    0.060</td> <td>    0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_8</th>          <td>   -0.0435</td> <td>    0.029</td> <td>   -1.474</td> <td> 0.140</td> <td>   -0.101</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_6</th>          <td>   -0.0573</td> <td>    0.035</td> <td>   -1.631</td> <td> 0.103</td> <td>   -0.126</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_7</th>          <td>   -0.0695</td> <td>    0.034</td> <td>   -2.066</td> <td> 0.039</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>          <td>    0.2120</td> <td>    0.032</td> <td>    6.567</td> <td> 0.000</td> <td>    0.149</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_6</th>       <td>   -0.2049</td> <td>    0.089</td> <td>   -2.311</td> <td> 0.021</td> <td>   -0.379</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>       <td>    0.2369</td> <td>    0.103</td> <td>    2.297</td> <td> 0.022</td> <td>    0.035</td> <td>    0.439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_8</th>       <td>   -1.0380</td> <td>    0.115</td> <td>   -8.995</td> <td> 0.000</td> <td>   -1.264</td> <td>   -0.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_6</th>       <td>   -0.1653</td> <td>    0.122</td> <td>   -1.360</td> <td> 0.174</td> <td>   -0.404</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>       <td>    0.1473</td> <td>    0.135</td> <td>    1.095</td> <td> 0.274</td> <td>   -0.116</td> <td>    0.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>       <td>   -1.4197</td> <td>    0.149</td> <td>   -9.553</td> <td> 0.000</td> <td>   -1.711</td> <td>   -1.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_6</th>       <td>   -0.0582</td> <td>    0.038</td> <td>   -1.533</td> <td> 0.125</td> <td>   -0.133</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_7</th>       <td>   -0.0917</td> <td>    0.042</td> <td>   -2.160</td> <td> 0.031</td> <td>   -0.175</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>       <td>   -0.1464</td> <td>    0.042</td> <td>   -3.461</td> <td> 0.001</td> <td>   -0.229</td> <td>   -0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_6</th>       <td>   -0.0100</td> <td>    0.022</td> <td>   -0.445</td> <td> 0.656</td> <td>   -0.054</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_7</th>       <td>   -0.0526</td> <td>    0.024</td> <td>   -2.206</td> <td> 0.027</td> <td>   -0.099</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_8</th>       <td>    0.0459</td> <td>    0.025</td> <td>    1.840</td> <td> 0.066</td> <td>   -0.003</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_6</th>           <td>    0.2893</td> <td>    0.180</td> <td>    1.605</td> <td> 0.109</td> <td>   -0.064</td> <td>    0.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>           <td>   -0.6442</td> <td>    0.201</td> <td>   -3.211</td> <td> 0.001</td> <td>   -1.037</td> <td>   -0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_8</th>           <td>    2.4767</td> <td>    0.231</td> <td>   10.710</td> <td> 0.000</td> <td>    2.023</td> <td>    2.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_6</th>       <td>   -0.2301</td> <td>    0.103</td> <td>   -2.239</td> <td> 0.025</td> <td>   -0.431</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_7</th>       <td>   -0.1012</td> <td>    0.126</td> <td>   -0.802</td> <td> 0.423</td> <td>   -0.349</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_8</th>       <td>   -0.7811</td> <td>    0.137</td> <td>   -5.709</td> <td> 0.000</td> <td>   -1.049</td> <td>   -0.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_6</th>       <td>   -0.0027</td> <td>    0.090</td> <td>   -0.031</td> <td> 0.976</td> <td>   -0.179</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_7</th>       <td>    0.0500</td> <td>    0.113</td> <td>    0.443</td> <td> 0.658</td> <td>   -0.171</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>       <td>   -1.0237</td> <td>    0.111</td> <td>   -9.218</td> <td> 0.000</td> <td>   -1.241</td> <td>   -0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_6</th>       <td>   -0.0778</td> <td>    0.029</td> <td>   -2.674</td> <td> 0.008</td> <td>   -0.135</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_7</th>       <td>    0.0124</td> <td>    0.031</td> <td>    0.394</td> <td> 0.693</td> <td>   -0.049</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_8</th>       <td>   -0.1177</td> <td>    0.036</td> <td>   -3.305</td> <td> 0.001</td> <td>   -0.188</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2c_mou_6</th>       <td> 9.745e-14</td> <td> 2.09e-14</td> <td>    4.654</td> <td> 0.000</td> <td> 5.64e-14</td> <td> 1.38e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2c_mou_7</th>       <td>-1.694e-13</td> <td> 4.63e-14</td> <td>   -3.656</td> <td> 0.000</td> <td> -2.6e-13</td> <td>-7.86e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2c_mou_8</th>       <td> 2.615e-13</td> <td> 5.46e-14</td> <td>    4.793</td> <td> 0.000</td> <td> 1.55e-13</td> <td> 3.68e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>           <td>    0.3390</td> <td>    0.145</td> <td>    2.334</td> <td> 0.020</td> <td>    0.054</td> <td>    0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>           <td>   -0.4584</td> <td>    0.178</td> <td>   -2.572</td> <td> 0.010</td> <td>   -0.808</td> <td>   -0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>           <td>    2.7689</td> <td>    0.230</td> <td>   12.021</td> <td> 0.000</td> <td>    2.317</td> <td>    3.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_og_mou_6</th>           <td>    0.0724</td> <td>    0.025</td> <td>    2.855</td> <td> 0.004</td> <td>    0.023</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_og_mou_7</th>           <td>   -0.0213</td> <td>    0.028</td> <td>   -0.753</td> <td> 0.451</td> <td>   -0.077</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_og_mou_8</th>           <td>   -0.0227</td> <td>    0.029</td> <td>   -0.787</td> <td> 0.432</td> <td>   -0.079</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_6</th>           <td>   -0.0841</td> <td>    0.025</td> <td>   -3.316</td> <td> 0.001</td> <td>   -0.134</td> <td>   -0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_7</th>           <td>    0.0267</td> <td>    0.027</td> <td>    0.977</td> <td> 0.329</td> <td>   -0.027</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_8</th>           <td>   -0.0420</td> <td>    0.030</td> <td>   -1.399</td> <td> 0.162</td> <td>   -0.101</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>og_others_6</th>            <td>   -0.0483</td> <td>    0.019</td> <td>   -2.535</td> <td> 0.011</td> <td>   -0.086</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>og_others_7</th>            <td>   -0.0150</td> <td>    0.026</td> <td>   -0.580</td> <td> 0.562</td> <td>   -0.066</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>og_others_8</th>            <td>   -0.0845</td> <td>    0.037</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.157</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>         <td>   -0.5853</td> <td>    0.129</td> <td>   -4.543</td> <td> 0.000</td> <td>   -0.838</td> <td>   -0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_7</th>         <td>    0.5963</td> <td>    0.156</td> <td>    3.827</td> <td> 0.000</td> <td>    0.291</td> <td>    0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>         <td>   -2.3800</td> <td>    0.201</td> <td>  -11.824</td> <td> 0.000</td> <td>   -2.775</td> <td>   -1.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_6</th>       <td>    0.3233</td> <td>    0.071</td> <td>    4.582</td> <td> 0.000</td> <td>    0.185</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_7</th>       <td>    0.1216</td> <td>    0.081</td> <td>    1.506</td> <td> 0.132</td> <td>   -0.037</td> <td>    0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_8</th>       <td>   -0.8200</td> <td>    0.086</td> <td>   -9.576</td> <td> 0.000</td> <td>   -0.988</td> <td>   -0.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_6</th>       <td>    0.4476</td> <td>    0.111</td> <td>    4.016</td> <td> 0.000</td> <td>    0.229</td> <td>    0.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_7</th>       <td>    0.3598</td> <td>    0.128</td> <td>    2.822</td> <td> 0.005</td> <td>    0.110</td> <td>    0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_8</th>       <td>   -1.6590</td> <td>    0.133</td> <td>  -12.521</td> <td> 0.000</td> <td>   -1.919</td> <td>   -1.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_6</th>       <td>    0.0304</td> <td>    0.043</td> <td>    0.702</td> <td> 0.483</td> <td>   -0.054</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_7</th>       <td>   -0.0217</td> <td>    0.050</td> <td>   -0.437</td> <td> 0.662</td> <td>   -0.119</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>       <td>   -0.3638</td> <td>    0.051</td> <td>   -7.126</td> <td> 0.000</td> <td>   -0.464</td> <td>   -0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_6</th>           <td>   -0.4850</td> <td>    0.183</td> <td>   -2.655</td> <td> 0.008</td> <td>   -0.843</td> <td>   -0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_7</th>           <td>   -0.6299</td> <td>    0.204</td> <td>   -3.094</td> <td> 0.002</td> <td>   -1.029</td> <td>   -0.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>           <td>    4.3976</td> <td>    0.223</td> <td>   19.754</td> <td> 0.000</td> <td>    3.961</td> <td>    4.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_6</th>       <td>   -0.1480</td> <td>    0.052</td> <td>   -2.853</td> <td> 0.004</td> <td>   -0.250</td> <td>   -0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_7</th>       <td>    0.1115</td> <td>    0.059</td> <td>    1.874</td> <td> 0.061</td> <td>   -0.005</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_8</th>       <td>   -0.4651</td> <td>    0.069</td> <td>   -6.727</td> <td> 0.000</td> <td>   -0.601</td> <td>   -0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_6</th>       <td>   -0.2007</td> <td>    0.078</td> <td>   -2.557</td> <td> 0.011</td> <td>   -0.355</td> <td>   -0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_7</th>       <td>   -0.1308</td> <td>    0.086</td> <td>   -1.521</td> <td> 0.128</td> <td>   -0.299</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_8</th>       <td>   -0.3761</td> <td>    0.102</td> <td>   -3.705</td> <td> 0.000</td> <td>   -0.575</td> <td>   -0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_6</th>       <td>   -0.0192</td> <td>    0.032</td> <td>   -0.608</td> <td> 0.543</td> <td>   -0.081</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_7</th>       <td>    0.0714</td> <td>    0.034</td> <td>    2.130</td> <td> 0.033</td> <td>    0.006</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_8</th>       <td>   -0.1921</td> <td>    0.038</td> <td>   -5.067</td> <td> 0.000</td> <td>   -0.266</td> <td>   -0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2o_mou_6</th>       <td> 3.108e-13</td> <td>  1.1e-13</td> <td>    2.817</td> <td> 0.005</td> <td> 9.46e-14</td> <td> 5.27e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2o_mou_7</th>       <td>-1.483e-13</td> <td> 2.98e-14</td> <td>   -4.972</td> <td> 0.000</td> <td>-2.07e-13</td> <td>-8.99e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2o_mou_8</th>       <td> -5.74e-14</td> <td> 6.77e-14</td> <td>   -0.848</td> <td> 0.397</td> <td> -1.9e-13</td> <td> 7.53e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_6</th>           <td>    0.3343</td> <td>    0.111</td> <td>    3.023</td> <td> 0.003</td> <td>    0.118</td> <td>    0.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_7</th>           <td>   -0.1136</td> <td>    0.120</td> <td>   -0.943</td> <td> 0.346</td> <td>   -0.350</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_8</th>           <td>    1.5031</td> <td>    0.143</td> <td>   10.524</td> <td> 0.000</td> <td>    1.223</td> <td>    1.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_6</th>         <td>    0.0614</td> <td>    0.123</td> <td>    0.500</td> <td> 0.617</td> <td>   -0.179</td> <td>    0.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_7</th>         <td>    0.6289</td> <td>    0.142</td> <td>    4.444</td> <td> 0.000</td> <td>    0.352</td> <td>    0.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_8</th>         <td>   -3.7901</td> <td>    0.180</td> <td>  -21.001</td> <td> 0.000</td> <td>   -4.144</td> <td>   -3.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_6</th>           <td>   -0.0296</td> <td>    0.018</td> <td>   -1.633</td> <td> 0.103</td> <td>   -0.065</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_7</th>           <td>   -0.0781</td> <td>    0.018</td> <td>   -4.325</td> <td> 0.000</td> <td>   -0.113</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_8</th>           <td>   -0.5129</td> <td>    0.029</td> <td>  -17.960</td> <td> 0.000</td> <td>   -0.569</td> <td>   -0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_6</th>           <td>    0.0743</td> <td>    0.034</td> <td>    2.198</td> <td> 0.028</td> <td>    0.008</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_7</th>           <td>   -0.0933</td> <td>    0.038</td> <td>   -2.460</td> <td> 0.014</td> <td>   -0.168</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_8</th>           <td>    0.4446</td> <td>    0.038</td> <td>   11.799</td> <td> 0.000</td> <td>    0.371</td> <td>    0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ic_others_6</th>            <td>   -0.0594</td> <td>    0.022</td> <td>   -2.692</td> <td> 0.007</td> <td>   -0.103</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ic_others_7</th>            <td>   -0.0839</td> <td>    0.024</td> <td>   -3.567</td> <td> 0.000</td> <td>   -0.130</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ic_others_8</th>            <td>    0.0886</td> <td>    0.025</td> <td>    3.567</td> <td> 0.000</td> <td>    0.040</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_6</th>       <td>   -0.0376</td> <td>    0.034</td> <td>   -1.104</td> <td> 0.270</td> <td>   -0.104</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_7</th>       <td>    0.1785</td> <td>    0.039</td> <td>    4.580</td> <td> 0.000</td> <td>    0.102</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_8</th>       <td>   -0.6283</td> <td>    0.039</td> <td>  -16.165</td> <td> 0.000</td> <td>   -0.705</td> <td>   -0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_6</th>       <td>  -18.9622</td> <td>    7.153</td> <td>   -2.651</td> <td> 0.008</td> <td>  -32.982</td> <td>   -4.943</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_7</th>       <td>  -10.0925</td> <td>    7.066</td> <td>   -1.428</td> <td> 0.153</td> <td>  -23.941</td> <td>    3.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_8</th>       <td>   -0.4100</td> <td>    0.075</td> <td>   -5.436</td> <td> 0.000</td> <td>   -0.558</td> <td>   -0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_6</th>         <td>   -0.1081</td> <td>    0.033</td> <td>   -3.259</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_7</th>         <td>    0.0403</td> <td>    0.035</td> <td>    1.162</td> <td> 0.245</td> <td>   -0.028</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_8</th>         <td>    0.1890</td> <td>    0.035</td> <td>    5.404</td> <td> 0.000</td> <td>    0.120</td> <td>    0.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_6</th>     <td>   -0.0554</td> <td>    0.024</td> <td>   -2.296</td> <td> 0.022</td> <td>   -0.103</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_7</th>     <td>   -0.1213</td> <td>    0.024</td> <td>   -5.074</td> <td> 0.000</td> <td>   -0.168</td> <td>   -0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th>     <td>   -0.6576</td> <td>    0.026</td> <td>  -25.105</td> <td> 0.000</td> <td>   -0.709</td> <td>   -0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_6</th>      <td>   -0.0681</td> <td>    0.107</td> <td>   -0.635</td> <td> 0.526</td> <td>   -0.278</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_7</th>      <td>   -0.0673</td> <td>    0.121</td> <td>   -0.556</td> <td> 0.578</td> <td>   -0.304</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_8</th>      <td>   -0.3890</td> <td>    0.137</td> <td>   -2.845</td> <td> 0.004</td> <td>   -0.657</td> <td>   -0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_6</th>        <td>    0.1319</td> <td>    0.099</td> <td>    1.326</td> <td> 0.185</td> <td>   -0.063</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_7</th>        <td>   -0.2893</td> <td>    0.100</td> <td>   -2.891</td> <td> 0.004</td> <td>   -0.485</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_8</th>        <td>   -0.1081</td> <td>    0.127</td> <td>   -0.853</td> <td> 0.394</td> <td>   -0.357</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_2g_6</th>        <td>   -0.1683</td> <td>    0.210</td> <td>   -0.803</td> <td> 0.422</td> <td>   -0.579</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_2g_7</th>        <td>   -0.9361</td> <td>    0.252</td> <td>   -3.710</td> <td> 0.000</td> <td>   -1.431</td> <td>   -0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_2g_8</th>        <td>   -0.1107</td> <td>    0.432</td> <td>   -0.256</td> <td> 0.798</td> <td>   -0.957</td> <td>    0.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_3g_6</th>        <td>   -0.0527</td> <td>    0.109</td> <td>   -0.483</td> <td> 0.629</td> <td>   -0.266</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_3g_7</th>        <td>   -0.2834</td> <td>    0.112</td> <td>   -2.528</td> <td> 0.011</td> <td>   -0.503</td> <td>   -0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_3g_8</th>        <td>    0.3977</td> <td>    0.146</td> <td>    2.721</td> <td> 0.007</td> <td>    0.111</td> <td>    0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_6</th>     <td>   -0.0928</td> <td>    0.085</td> <td>   -1.095</td> <td> 0.274</td> <td>   -0.259</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_7</th>     <td>    0.2118</td> <td>    0.090</td> <td>    2.366</td> <td> 0.018</td> <td>    0.036</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_8</th>     <td>   -0.3210</td> <td>    0.104</td> <td>   -3.090</td> <td> 0.002</td> <td>   -0.525</td> <td>   -0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_6</th>            <td>    0.0540</td> <td>    0.032</td> <td>    1.693</td> <td> 0.090</td> <td>   -0.009</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_7</th>            <td>    0.0729</td> <td>    0.034</td> <td>    2.135</td> <td> 0.033</td> <td>    0.006</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_8</th>            <td>   -0.2346</td> <td>    0.038</td> <td>   -6.218</td> <td> 0.000</td> <td>   -0.309</td> <td>   -0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_6</th>            <td>    0.0808</td> <td>    0.048</td> <td>    1.678</td> <td> 0.093</td> <td>   -0.014</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_7</th>            <td>    0.1235</td> <td>    0.051</td> <td>    2.417</td> <td> 0.016</td> <td>    0.023</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_8</th>            <td>   -0.1987</td> <td>    0.056</td> <td>   -3.557</td> <td> 0.000</td> <td>   -0.308</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>night_pck_user_6</th>       <td>    0.0385</td> <td>    0.078</td> <td>    0.491</td> <td> 0.624</td> <td>   -0.115</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>night_pck_user_7</th>       <td>   -0.1078</td> <td>    0.084</td> <td>   -1.288</td> <td> 0.198</td> <td>   -0.272</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>night_pck_user_8</th>       <td>    0.1184</td> <td>    0.080</td> <td>    1.490</td> <td> 0.136</td> <td>   -0.037</td> <td>    0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_6</th>           <td>   -0.0905</td> <td>    0.073</td> <td>   -1.246</td> <td> 0.213</td> <td>   -0.233</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_7</th>           <td>    0.2215</td> <td>    0.078</td> <td>    2.846</td> <td> 0.004</td> <td>    0.069</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_8</th>           <td>   -0.0322</td> <td>    0.121</td> <td>   -0.266</td> <td> 0.790</td> <td>   -0.269</td> <td>    0.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_6</th>            <td>    0.1502</td> <td>    0.184</td> <td>    0.819</td> <td> 0.413</td> <td>   -0.210</td> <td>    0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_7</th>            <td>    0.7645</td> <td>    0.226</td> <td>    3.377</td> <td> 0.001</td> <td>    0.321</td> <td>    1.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_8</th>            <td>    0.4107</td> <td>    0.402</td> <td>    1.022</td> <td> 0.307</td> <td>   -0.377</td> <td>    1.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_6</th>           <td>   -0.0246</td> <td>    0.087</td> <td>   -0.284</td> <td> 0.777</td> <td>   -0.194</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_7</th>           <td>    0.3376</td> <td>    0.087</td> <td>    3.876</td> <td> 0.000</td> <td>    0.167</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_8</th>           <td>   -0.2485</td> <td>    0.125</td> <td>   -1.995</td> <td> 0.046</td> <td>   -0.493</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_6</th>            <td>   -0.0633</td> <td>    0.059</td> <td>   -1.069</td> <td> 0.285</td> <td>   -0.179</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_7</th>            <td>    0.2500</td> <td>    0.061</td> <td>    4.105</td> <td> 0.000</td> <td>    0.131</td> <td>    0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_8</th>            <td>   -0.2232</td> <td>    0.083</td> <td>   -2.679</td> <td> 0.007</td> <td>   -0.386</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fb_user_6</th>              <td>    0.0233</td> <td>    0.090</td> <td>    0.259</td> <td> 0.796</td> <td>   -0.153</td> <td>    0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fb_user_7</th>              <td>    0.1992</td> <td>    0.095</td> <td>    2.097</td> <td> 0.036</td> <td>    0.013</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fb_user_8</th>              <td>   -0.2206</td> <td>    0.095</td> <td>   -2.328</td> <td> 0.020</td> <td>   -0.406</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aon</th>                    <td>   -0.3559</td> <td>    0.021</td> <td>  -16.767</td> <td> 0.000</td> <td>   -0.398</td> <td>   -0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>             <td>   -0.2157</td> <td>    0.042</td> <td>   -5.075</td> <td> 0.000</td> <td>   -0.299</td> <td>   -0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jul_vbc_3g</th>             <td>    0.0331</td> <td>    0.042</td> <td>    0.785</td> <td> 0.433</td> <td>   -0.050</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jun_vbc_3g</th>             <td>    0.0604</td> <td>    0.038</td> <td>    1.588</td> <td> 0.112</td> <td>   -0.014</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tot_monthly_recharge_6</th> <td>   18.9461</td> <td>    7.156</td> <td>    2.647</td> <td> 0.008</td> <td>    4.920</td> <td>   32.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tot_monthly_recharge_7</th> <td>    9.9012</td> <td>    7.068</td> <td>    1.401</td> <td> 0.161</td> <td>   -3.952</td> <td>   23.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>average_recharge_6_7</th>   <td>    0.0930</td> <td>    0.130</td> <td>    0.716</td> <td> 0.474</td> <td>   -0.162</td> <td>    0.348</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                38400\n",
       "Model:                            GLM   Df Residuals:                    38251\n",
       "Model Family:                Binomial   Df Model:                          148\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -13412.\n",
       "Date:                Tue, 01 Sep 2020   Deviance:                       26824.\n",
       "Time:                        10:43:24   Pearson chi2:                 1.57e+05\n",
       "No. Iterations:                   100                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "const                     -2.0125      0.029    -68.766      0.000      -2.070      -1.955\n",
       "loc_og_t2o_mou          3.656e-14   8.15e-15      4.488      0.000    2.06e-14    5.25e-14\n",
       "std_og_t2o_mou          3.713e-13   9.94e-14      3.733      0.000    1.76e-13    5.66e-13\n",
       "loc_ic_t2o_mou         -1.705e-13   3.29e-14     -5.175      0.000   -2.35e-13   -1.06e-13\n",
       "arpu_6                     0.1148      0.056      2.068      0.039       0.006       0.224\n",
       "arpu_7                     0.3365      0.061      5.543      0.000       0.218       0.455\n",
       "arpu_8                     0.5755      0.071      8.096      0.000       0.436       0.715\n",
       "onnet_mou_6                0.5111      0.110      4.652      0.000       0.296       0.726\n",
       "onnet_mou_7                0.1440      0.133      1.085      0.278      -0.116       0.404\n",
       "onnet_mou_8               -0.0802      0.146     -0.551      0.582      -0.366       0.205\n",
       "offnet_mou_6               0.1833      0.097      1.886      0.059      -0.007       0.374\n",
       "offnet_mou_7               0.1881      0.121      1.559      0.119      -0.048       0.425\n",
       "offnet_mou_8               0.1282      0.117      1.095      0.273      -0.101       0.358\n",
       "roam_ic_mou_6             -0.0372      0.033     -1.116      0.264      -0.102       0.028\n",
       "roam_ic_mou_7              0.1237      0.033      3.793      0.000       0.060       0.188\n",
       "roam_ic_mou_8             -0.0435      0.029     -1.474      0.140      -0.101       0.014\n",
       "roam_og_mou_6             -0.0573      0.035     -1.631      0.103      -0.126       0.012\n",
       "roam_og_mou_7             -0.0695      0.034     -2.066      0.039      -0.135      -0.004\n",
       "roam_og_mou_8              0.2120      0.032      6.567      0.000       0.149       0.275\n",
       "loc_og_t2t_mou_6          -0.2049      0.089     -2.311      0.021      -0.379      -0.031\n",
       "loc_og_t2t_mou_7           0.2369      0.103      2.297      0.022       0.035       0.439\n",
       "loc_og_t2t_mou_8          -1.0380      0.115     -8.995      0.000      -1.264      -0.812\n",
       "loc_og_t2m_mou_6          -0.1653      0.122     -1.360      0.174      -0.404       0.073\n",
       "loc_og_t2m_mou_7           0.1473      0.135      1.095      0.274      -0.116       0.411\n",
       "loc_og_t2m_mou_8          -1.4197      0.149     -9.553      0.000      -1.711      -1.128\n",
       "loc_og_t2f_mou_6          -0.0582      0.038     -1.533      0.125      -0.133       0.016\n",
       "loc_og_t2f_mou_7          -0.0917      0.042     -2.160      0.031      -0.175      -0.008\n",
       "loc_og_t2f_mou_8          -0.1464      0.042     -3.461      0.001      -0.229      -0.064\n",
       "loc_og_t2c_mou_6          -0.0100      0.022     -0.445      0.656      -0.054       0.034\n",
       "loc_og_t2c_mou_7          -0.0526      0.024     -2.206      0.027      -0.099      -0.006\n",
       "loc_og_t2c_mou_8           0.0459      0.025      1.840      0.066      -0.003       0.095\n",
       "loc_og_mou_6               0.2893      0.180      1.605      0.109      -0.064       0.643\n",
       "loc_og_mou_7              -0.6442      0.201     -3.211      0.001      -1.037      -0.251\n",
       "loc_og_mou_8               2.4767      0.231     10.710      0.000       2.023       2.930\n",
       "std_og_t2t_mou_6          -0.2301      0.103     -2.239      0.025      -0.431      -0.029\n",
       "std_og_t2t_mou_7          -0.1012      0.126     -0.802      0.423      -0.349       0.146\n",
       "std_og_t2t_mou_8          -0.7811      0.137     -5.709      0.000      -1.049      -0.513\n",
       "std_og_t2m_mou_6          -0.0027      0.090     -0.031      0.976      -0.179       0.173\n",
       "std_og_t2m_mou_7           0.0500      0.113      0.443      0.658      -0.171       0.271\n",
       "std_og_t2m_mou_8          -1.0237      0.111     -9.218      0.000      -1.241      -0.806\n",
       "std_og_t2f_mou_6          -0.0778      0.029     -2.674      0.008      -0.135      -0.021\n",
       "std_og_t2f_mou_7           0.0124      0.031      0.394      0.693      -0.049       0.074\n",
       "std_og_t2f_mou_8          -0.1177      0.036     -3.305      0.001      -0.188      -0.048\n",
       "std_og_t2c_mou_6        9.745e-14   2.09e-14      4.654      0.000    5.64e-14    1.38e-13\n",
       "std_og_t2c_mou_7       -1.694e-13   4.63e-14     -3.656      0.000    -2.6e-13   -7.86e-14\n",
       "std_og_t2c_mou_8        2.615e-13   5.46e-14      4.793      0.000    1.55e-13    3.68e-13\n",
       "std_og_mou_6               0.3390      0.145      2.334      0.020       0.054       0.624\n",
       "std_og_mou_7              -0.4584      0.178     -2.572      0.010      -0.808      -0.109\n",
       "std_og_mou_8               2.7689      0.230     12.021      0.000       2.317       3.220\n",
       "isd_og_mou_6               0.0724      0.025      2.855      0.004       0.023       0.122\n",
       "isd_og_mou_7              -0.0213      0.028     -0.753      0.451      -0.077       0.034\n",
       "isd_og_mou_8              -0.0227      0.029     -0.787      0.432      -0.079       0.034\n",
       "spl_og_mou_6              -0.0841      0.025     -3.316      0.001      -0.134      -0.034\n",
       "spl_og_mou_7               0.0267      0.027      0.977      0.329      -0.027       0.080\n",
       "spl_og_mou_8              -0.0420      0.030     -1.399      0.162      -0.101       0.017\n",
       "og_others_6               -0.0483      0.019     -2.535      0.011      -0.086      -0.011\n",
       "og_others_7               -0.0150      0.026     -0.580      0.562      -0.066       0.036\n",
       "og_others_8               -0.0845      0.037     -2.277      0.023      -0.157      -0.012\n",
       "total_og_mou_6            -0.5853      0.129     -4.543      0.000      -0.838      -0.333\n",
       "total_og_mou_7             0.5963      0.156      3.827      0.000       0.291       0.902\n",
       "total_og_mou_8            -2.3800      0.201    -11.824      0.000      -2.775      -1.986\n",
       "loc_ic_t2t_mou_6           0.3233      0.071      4.582      0.000       0.185       0.462\n",
       "loc_ic_t2t_mou_7           0.1216      0.081      1.506      0.132      -0.037       0.280\n",
       "loc_ic_t2t_mou_8          -0.8200      0.086     -9.576      0.000      -0.988      -0.652\n",
       "loc_ic_t2m_mou_6           0.4476      0.111      4.016      0.000       0.229       0.666\n",
       "loc_ic_t2m_mou_7           0.3598      0.128      2.822      0.005       0.110       0.610\n",
       "loc_ic_t2m_mou_8          -1.6590      0.133    -12.521      0.000      -1.919      -1.399\n",
       "loc_ic_t2f_mou_6           0.0304      0.043      0.702      0.483      -0.054       0.115\n",
       "loc_ic_t2f_mou_7          -0.0217      0.050     -0.437      0.662      -0.119       0.076\n",
       "loc_ic_t2f_mou_8          -0.3638      0.051     -7.126      0.000      -0.464      -0.264\n",
       "loc_ic_mou_6              -0.4850      0.183     -2.655      0.008      -0.843      -0.127\n",
       "loc_ic_mou_7              -0.6299      0.204     -3.094      0.002      -1.029      -0.231\n",
       "loc_ic_mou_8               4.3976      0.223     19.754      0.000       3.961       4.834\n",
       "std_ic_t2t_mou_6          -0.1480      0.052     -2.853      0.004      -0.250      -0.046\n",
       "std_ic_t2t_mou_7           0.1115      0.059      1.874      0.061      -0.005       0.228\n",
       "std_ic_t2t_mou_8          -0.4651      0.069     -6.727      0.000      -0.601      -0.330\n",
       "std_ic_t2m_mou_6          -0.2007      0.078     -2.557      0.011      -0.355      -0.047\n",
       "std_ic_t2m_mou_7          -0.1308      0.086     -1.521      0.128      -0.299       0.038\n",
       "std_ic_t2m_mou_8          -0.3761      0.102     -3.705      0.000      -0.575      -0.177\n",
       "std_ic_t2f_mou_6          -0.0192      0.032     -0.608      0.543      -0.081       0.043\n",
       "std_ic_t2f_mou_7           0.0714      0.034      2.130      0.033       0.006       0.137\n",
       "std_ic_t2f_mou_8          -0.1921      0.038     -5.067      0.000      -0.266      -0.118\n",
       "std_ic_t2o_mou_6        3.108e-13    1.1e-13      2.817      0.005    9.46e-14    5.27e-13\n",
       "std_ic_t2o_mou_7       -1.483e-13   2.98e-14     -4.972      0.000   -2.07e-13   -8.99e-14\n",
       "std_ic_t2o_mou_8        -5.74e-14   6.77e-14     -0.848      0.397    -1.9e-13    7.53e-14\n",
       "std_ic_mou_6               0.3343      0.111      3.023      0.003       0.118       0.551\n",
       "std_ic_mou_7              -0.1136      0.120     -0.943      0.346      -0.350       0.123\n",
       "std_ic_mou_8               1.5031      0.143     10.524      0.000       1.223       1.783\n",
       "total_ic_mou_6             0.0614      0.123      0.500      0.617      -0.179       0.302\n",
       "total_ic_mou_7             0.6289      0.142      4.444      0.000       0.352       0.906\n",
       "total_ic_mou_8            -3.7901      0.180    -21.001      0.000      -4.144      -3.436\n",
       "spl_ic_mou_6              -0.0296      0.018     -1.633      0.103      -0.065       0.006\n",
       "spl_ic_mou_7              -0.0781      0.018     -4.325      0.000      -0.113      -0.043\n",
       "spl_ic_mou_8              -0.5129      0.029    -17.960      0.000      -0.569      -0.457\n",
       "isd_ic_mou_6               0.0743      0.034      2.198      0.028       0.008       0.141\n",
       "isd_ic_mou_7              -0.0933      0.038     -2.460      0.014      -0.168      -0.019\n",
       "isd_ic_mou_8               0.4446      0.038     11.799      0.000       0.371       0.519\n",
       "ic_others_6               -0.0594      0.022     -2.692      0.007      -0.103      -0.016\n",
       "ic_others_7               -0.0839      0.024     -3.567      0.000      -0.130      -0.038\n",
       "ic_others_8                0.0886      0.025      3.567      0.000       0.040       0.137\n",
       "total_rech_num_6          -0.0376      0.034     -1.104      0.270      -0.104       0.029\n",
       "total_rech_num_7           0.1785      0.039      4.580      0.000       0.102       0.255\n",
       "total_rech_num_8          -0.6283      0.039    -16.165      0.000      -0.705      -0.552\n",
       "total_rech_amt_6         -18.9622      7.153     -2.651      0.008     -32.982      -4.943\n",
       "total_rech_amt_7         -10.0925      7.066     -1.428      0.153     -23.941       3.756\n",
       "total_rech_amt_8          -0.4100      0.075     -5.436      0.000      -0.558      -0.262\n",
       "max_rech_amt_6            -0.1081      0.033     -3.259      0.001      -0.173      -0.043\n",
       "max_rech_amt_7             0.0403      0.035      1.162      0.245      -0.028       0.108\n",
       "max_rech_amt_8             0.1890      0.035      5.404      0.000       0.120       0.257\n",
       "last_day_rch_amt_6        -0.0554      0.024     -2.296      0.022      -0.103      -0.008\n",
       "last_day_rch_amt_7        -0.1213      0.024     -5.074      0.000      -0.168      -0.074\n",
       "last_day_rch_amt_8        -0.6576      0.026    -25.105      0.000      -0.709      -0.606\n",
       "total_rech_data_6         -0.0681      0.107     -0.635      0.526      -0.278       0.142\n",
       "total_rech_data_7         -0.0673      0.121     -0.556      0.578      -0.304       0.170\n",
       "total_rech_data_8         -0.3890      0.137     -2.845      0.004      -0.657      -0.121\n",
       "max_rech_data_6            0.1319      0.099      1.326      0.185      -0.063       0.327\n",
       "max_rech_data_7           -0.2893      0.100     -2.891      0.004      -0.485      -0.093\n",
       "max_rech_data_8           -0.1081      0.127     -0.853      0.394      -0.357       0.140\n",
       "count_rech_2g_6           -0.1683      0.210     -0.803      0.422      -0.579       0.242\n",
       "count_rech_2g_7           -0.9361      0.252     -3.710      0.000      -1.431      -0.442\n",
       "count_rech_2g_8           -0.1107      0.432     -0.256      0.798      -0.957       0.736\n",
       "count_rech_3g_6           -0.0527      0.109     -0.483      0.629      -0.266       0.161\n",
       "count_rech_3g_7           -0.2834      0.112     -2.528      0.011      -0.503      -0.064\n",
       "count_rech_3g_8            0.3977      0.146      2.721      0.007       0.111       0.684\n",
       "av_rech_amt_data_6        -0.0928      0.085     -1.095      0.274      -0.259       0.073\n",
       "av_rech_amt_data_7         0.2118      0.090      2.366      0.018       0.036       0.387\n",
       "av_rech_amt_data_8        -0.3210      0.104     -3.090      0.002      -0.525      -0.117\n",
       "vol_2g_mb_6                0.0540      0.032      1.693      0.090      -0.009       0.116\n",
       "vol_2g_mb_7                0.0729      0.034      2.135      0.033       0.006       0.140\n",
       "vol_2g_mb_8               -0.2346      0.038     -6.218      0.000      -0.309      -0.161\n",
       "vol_3g_mb_6                0.0808      0.048      1.678      0.093      -0.014       0.175\n",
       "vol_3g_mb_7                0.1235      0.051      2.417      0.016       0.023       0.224\n",
       "vol_3g_mb_8               -0.1987      0.056     -3.557      0.000      -0.308      -0.089\n",
       "night_pck_user_6           0.0385      0.078      0.491      0.624      -0.115       0.192\n",
       "night_pck_user_7          -0.1078      0.084     -1.288      0.198      -0.272       0.056\n",
       "night_pck_user_8           0.1184      0.080      1.490      0.136      -0.037       0.274\n",
       "monthly_2g_6              -0.0905      0.073     -1.246      0.213      -0.233       0.052\n",
       "monthly_2g_7               0.2215      0.078      2.846      0.004       0.069       0.374\n",
       "monthly_2g_8              -0.0322      0.121     -0.266      0.790      -0.269       0.205\n",
       "sachet_2g_6                0.1502      0.184      0.819      0.413      -0.210       0.510\n",
       "sachet_2g_7                0.7645      0.226      3.377      0.001       0.321       1.208\n",
       "sachet_2g_8                0.4107      0.402      1.022      0.307      -0.377       1.198\n",
       "monthly_3g_6              -0.0246      0.087     -0.284      0.777      -0.194       0.145\n",
       "monthly_3g_7               0.3376      0.087      3.876      0.000       0.167       0.508\n",
       "monthly_3g_8              -0.2485      0.125     -1.995      0.046      -0.493      -0.004\n",
       "sachet_3g_6               -0.0633      0.059     -1.069      0.285      -0.179       0.053\n",
       "sachet_3g_7                0.2500      0.061      4.105      0.000       0.131       0.369\n",
       "sachet_3g_8               -0.2232      0.083     -2.679      0.007      -0.386      -0.060\n",
       "fb_user_6                  0.0233      0.090      0.259      0.796      -0.153       0.200\n",
       "fb_user_7                  0.1992      0.095      2.097      0.036       0.013       0.386\n",
       "fb_user_8                 -0.2206      0.095     -2.328      0.020      -0.406      -0.035\n",
       "aon                       -0.3559      0.021    -16.767      0.000      -0.398      -0.314\n",
       "aug_vbc_3g                -0.2157      0.042     -5.075      0.000      -0.299      -0.132\n",
       "jul_vbc_3g                 0.0331      0.042      0.785      0.433      -0.050       0.116\n",
       "jun_vbc_3g                 0.0604      0.038      1.588      0.112      -0.014       0.135\n",
       "tot_monthly_recharge_6    18.9461      7.156      2.647      0.008       4.920      32.972\n",
       "tot_monthly_recharge_7     9.9012      7.068      1.401      0.161      -3.952      23.754\n",
       "average_recharge_6_7       0.0930      0.130      0.716      0.474      -0.162       0.348\n",
       "==========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression model\n",
    "logm1 = sm.GLM(y_train,(sm.add_constant(X_train)), family = sm.families.Binomial())\n",
    "logm1.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic1 = LogisticRegression()\n",
    "rfe_logistic = RFE(logistic1, 70)\n",
    "rfe_logistic = rfe_logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['arpu_6', 'arpu_7', 'arpu_8', 'onnet_mou_6', 'offnet_mou_7',\n",
      "       'roam_og_mou_8', 'loc_og_t2t_mou_7', 'loc_og_t2t_mou_8',\n",
      "       'loc_og_t2m_mou_8', 'loc_og_t2f_mou_7', 'loc_og_t2f_mou_8',\n",
      "       'loc_og_mou_7', 'loc_og_mou_8', 'std_og_t2t_mou_6', 'std_og_t2t_mou_8',\n",
      "       'std_og_t2m_mou_8', 'std_og_mou_6', 'std_og_mou_7', 'std_og_mou_8',\n",
      "       'total_og_mou_6', 'total_og_mou_7', 'total_og_mou_8',\n",
      "       'loc_ic_t2t_mou_6', 'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_6',\n",
      "       'loc_ic_t2m_mou_7', 'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_8',\n",
      "       'loc_ic_mou_6', 'loc_ic_mou_7', 'loc_ic_mou_8', 'std_ic_t2t_mou_8',\n",
      "       'std_ic_t2m_mou_7', 'std_ic_t2m_mou_8', 'std_ic_t2f_mou_8',\n",
      "       'std_ic_mou_8', 'total_ic_mou_7', 'total_ic_mou_8', 'spl_ic_mou_8',\n",
      "       'isd_ic_mou_8', 'total_rech_num_7', 'total_rech_num_8',\n",
      "       'total_rech_amt_6', 'total_rech_amt_7', 'total_rech_amt_8',\n",
      "       'last_day_rch_amt_8', 'total_rech_data_8', 'max_rech_data_7',\n",
      "       'max_rech_data_8', 'count_rech_2g_6', 'count_rech_2g_7',\n",
      "       'count_rech_3g_7', 'count_rech_3g_8', 'av_rech_amt_data_7',\n",
      "       'av_rech_amt_data_8', 'vol_2g_mb_8', 'vol_3g_mb_8', 'night_pck_user_7',\n",
      "       'night_pck_user_8', 'sachet_2g_6', 'sachet_2g_7', 'sachet_2g_8',\n",
      "       'monthly_3g_7', 'monthly_3g_8', 'sachet_3g_7', 'sachet_3g_8',\n",
      "       'fb_user_7', 'fb_user_8', 'aon', 'average_recharge_6_7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "col = X_train.columns[rfe_logistic.support_]\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 38400</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 38329</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    70</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -13628.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Sep 2020</td> <th>  Deviance:          </th> <td>  27255.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:49:10</td>     <th>  Pearson chi2:      </th> <td>1.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>7</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>   -1.9382</td> <td>    0.028</td> <td>  -70.127</td> <td> 0.000</td> <td>   -1.992</td> <td>   -1.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_6</th>               <td>    0.1787</td> <td>    0.051</td> <td>    3.504</td> <td> 0.000</td> <td>    0.079</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_7</th>               <td>    0.3623</td> <td>    0.055</td> <td>    6.643</td> <td> 0.000</td> <td>    0.255</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_8</th>               <td>    0.4212</td> <td>    0.065</td> <td>    6.453</td> <td> 0.000</td> <td>    0.293</td> <td>    0.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_6</th>          <td>    0.3200</td> <td>    0.062</td> <td>    5.194</td> <td> 0.000</td> <td>    0.199</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_7</th>         <td>    0.2494</td> <td>    0.041</td> <td>    6.106</td> <td> 0.000</td> <td>    0.169</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>        <td>    0.1954</td> <td>    0.016</td> <td>   11.880</td> <td> 0.000</td> <td>    0.163</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>     <td>    0.2119</td> <td>    0.056</td> <td>    3.762</td> <td> 0.000</td> <td>    0.101</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_8</th>     <td>   -1.1417</td> <td>    0.099</td> <td>  -11.536</td> <td> 0.000</td> <td>   -1.336</td> <td>   -0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>     <td>   -1.4383</td> <td>    0.117</td> <td>  -12.275</td> <td> 0.000</td> <td>   -1.668</td> <td>   -1.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_7</th>     <td>   -0.1539</td> <td>    0.036</td> <td>   -4.276</td> <td> 0.000</td> <td>   -0.224</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>     <td>   -0.1555</td> <td>    0.040</td> <td>   -3.933</td> <td> 0.000</td> <td>   -0.233</td> <td>   -0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>         <td>   -0.4765</td> <td>    0.089</td> <td>   -5.382</td> <td> 0.000</td> <td>   -0.650</td> <td>   -0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_8</th>         <td>    2.6326</td> <td>    0.196</td> <td>   13.464</td> <td> 0.000</td> <td>    2.249</td> <td>    3.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_6</th>     <td>   -0.1837</td> <td>    0.063</td> <td>   -2.915</td> <td> 0.004</td> <td>   -0.307</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_8</th>     <td>   -0.7812</td> <td>    0.066</td> <td>  -11.868</td> <td> 0.000</td> <td>   -0.910</td> <td>   -0.652</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>     <td>   -0.8522</td> <td>    0.067</td> <td>  -12.640</td> <td> 0.000</td> <td>   -0.984</td> <td>   -0.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>         <td>    0.3395</td> <td>    0.067</td> <td>    5.080</td> <td> 0.000</td> <td>    0.209</td> <td>    0.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>         <td>   -0.4079</td> <td>    0.127</td> <td>   -3.223</td> <td> 0.001</td> <td>   -0.656</td> <td>   -0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>         <td>    2.7126</td> <td>    0.215</td> <td>   12.629</td> <td> 0.000</td> <td>    2.292</td> <td>    3.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>       <td>   -0.3718</td> <td>    0.066</td> <td>   -5.674</td> <td> 0.000</td> <td>   -0.500</td> <td>   -0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_7</th>       <td>    0.5261</td> <td>    0.131</td> <td>    4.012</td> <td> 0.000</td> <td>    0.269</td> <td>    0.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>       <td>   -2.4117</td> <td>    0.191</td> <td>  -12.626</td> <td> 0.000</td> <td>   -2.786</td> <td>   -2.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_6</th>     <td>    0.3315</td> <td>    0.056</td> <td>    5.923</td> <td> 0.000</td> <td>    0.222</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_8</th>     <td>   -0.7413</td> <td>    0.077</td> <td>   -9.635</td> <td> 0.000</td> <td>   -0.892</td> <td>   -0.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_6</th>     <td>    0.4764</td> <td>    0.095</td> <td>    5.034</td> <td> 0.000</td> <td>    0.291</td> <td>    0.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_7</th>     <td>    0.2511</td> <td>    0.084</td> <td>    3.003</td> <td> 0.003</td> <td>    0.087</td> <td>    0.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_8</th>     <td>   -1.5505</td> <td>    0.125</td> <td>  -12.379</td> <td> 0.000</td> <td>   -1.796</td> <td>   -1.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>     <td>   -0.3492</td> <td>    0.040</td> <td>   -8.821</td> <td> 0.000</td> <td>   -0.427</td> <td>   -0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_6</th>         <td>   -0.4372</td> <td>    0.121</td> <td>   -3.614</td> <td> 0.000</td> <td>   -0.674</td> <td>   -0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_7</th>         <td>   -0.4819</td> <td>    0.112</td> <td>   -4.300</td> <td> 0.000</td> <td>   -0.702</td> <td>   -0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>         <td>    4.1706</td> <td>    0.202</td> <td>   20.600</td> <td> 0.000</td> <td>    3.774</td> <td>    4.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_8</th>     <td>   -0.4544</td> <td>    0.059</td> <td>   -7.710</td> <td> 0.000</td> <td>   -0.570</td> <td>   -0.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_7</th>     <td>   -0.1740</td> <td>    0.034</td> <td>   -5.180</td> <td> 0.000</td> <td>   -0.240</td> <td>   -0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_8</th>     <td>   -0.4535</td> <td>    0.092</td> <td>   -4.953</td> <td> 0.000</td> <td>   -0.633</td> <td>   -0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_8</th>     <td>   -0.2043</td> <td>    0.031</td> <td>   -6.526</td> <td> 0.000</td> <td>   -0.266</td> <td>   -0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_8</th>         <td>    1.5651</td> <td>    0.128</td> <td>   12.249</td> <td> 0.000</td> <td>    1.315</td> <td>    1.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_7</th>       <td>    0.6408</td> <td>    0.083</td> <td>    7.737</td> <td> 0.000</td> <td>    0.478</td> <td>    0.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_8</th>       <td>   -3.7062</td> <td>    0.160</td> <td>  -23.111</td> <td> 0.000</td> <td>   -4.020</td> <td>   -3.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_8</th>         <td>   -0.5284</td> <td>    0.028</td> <td>  -18.764</td> <td> 0.000</td> <td>   -0.584</td> <td>   -0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_8</th>         <td>    0.4207</td> <td>    0.028</td> <td>   14.912</td> <td> 0.000</td> <td>    0.365</td> <td>    0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_7</th>     <td>    0.1822</td> <td>    0.030</td> <td>    6.106</td> <td> 0.000</td> <td>    0.124</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_8</th>     <td>   -0.6658</td> <td>    0.036</td> <td>  -18.336</td> <td> 0.000</td> <td>   -0.737</td> <td>   -0.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_6</th>     <td>   -0.1766</td> <td>    0.089</td> <td>   -1.974</td> <td> 0.048</td> <td>   -0.352</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_7</th>     <td>   -0.2420</td> <td>    0.087</td> <td>   -2.784</td> <td> 0.005</td> <td>   -0.412</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_8</th>     <td>   -0.1678</td> <td>    0.063</td> <td>   -2.650</td> <td> 0.008</td> <td>   -0.292</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th>   <td>   -0.6386</td> <td>    0.025</td> <td>  -25.759</td> <td> 0.000</td> <td>   -0.687</td> <td>   -0.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_8</th>    <td>   -0.4505</td> <td>    0.104</td> <td>   -4.322</td> <td> 0.000</td> <td>   -0.655</td> <td>   -0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_7</th>      <td>   -0.1709</td> <td>    0.084</td> <td>   -2.032</td> <td> 0.042</td> <td>   -0.336</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_8</th>      <td>   -0.1593</td> <td>    0.103</td> <td>   -1.549</td> <td> 0.121</td> <td>   -0.361</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_2g_6</th>      <td>   -0.1714</td> <td>    0.072</td> <td>   -2.369</td> <td> 0.018</td> <td>   -0.313</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_2g_7</th>      <td>   -0.4745</td> <td>    0.119</td> <td>   -3.976</td> <td> 0.000</td> <td>   -0.708</td> <td>   -0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_3g_7</th>      <td>   -0.2660</td> <td>    0.095</td> <td>   -2.811</td> <td> 0.005</td> <td>   -0.451</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_3g_8</th>      <td>    0.3712</td> <td>    0.134</td> <td>    2.766</td> <td> 0.006</td> <td>    0.108</td> <td>    0.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_7</th>   <td>    0.3245</td> <td>    0.075</td> <td>    4.330</td> <td> 0.000</td> <td>    0.178</td> <td>    0.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_8</th>   <td>   -0.2843</td> <td>    0.098</td> <td>   -2.909</td> <td> 0.004</td> <td>   -0.476</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_8</th>          <td>   -0.1901</td> <td>    0.032</td> <td>   -5.987</td> <td> 0.000</td> <td>   -0.252</td> <td>   -0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_8</th>          <td>   -0.2114</td> <td>    0.047</td> <td>   -4.538</td> <td> 0.000</td> <td>   -0.303</td> <td>   -0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>night_pck_user_7</th>     <td>   -0.1356</td> <td>    0.076</td> <td>   -1.778</td> <td> 0.075</td> <td>   -0.285</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>night_pck_user_8</th>     <td>    0.1785</td> <td>    0.076</td> <td>    2.349</td> <td> 0.019</td> <td>    0.030</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_6</th>          <td>    0.1941</td> <td>    0.071</td> <td>    2.732</td> <td> 0.006</td> <td>    0.055</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_7</th>          <td>    0.3116</td> <td>    0.109</td> <td>    2.847</td> <td> 0.004</td> <td>    0.097</td> <td>    0.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_8</th>          <td>    0.3598</td> <td>    0.086</td> <td>    4.203</td> <td> 0.000</td> <td>    0.192</td> <td>    0.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_7</th>         <td>    0.2354</td> <td>    0.078</td> <td>    3.016</td> <td> 0.003</td> <td>    0.082</td> <td>    0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_8</th>         <td>   -0.1775</td> <td>    0.102</td> <td>   -1.744</td> <td> 0.081</td> <td>   -0.377</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_7</th>          <td>    0.1990</td> <td>    0.056</td> <td>    3.570</td> <td> 0.000</td> <td>    0.090</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_8</th>          <td>   -0.1848</td> <td>    0.077</td> <td>   -2.411</td> <td> 0.016</td> <td>   -0.335</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fb_user_7</th>            <td>    0.2166</td> <td>    0.087</td> <td>    2.503</td> <td> 0.012</td> <td>    0.047</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fb_user_8</th>            <td>   -0.2845</td> <td>    0.091</td> <td>   -3.127</td> <td> 0.002</td> <td>   -0.463</td> <td>   -0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aon</th>                  <td>   -0.3533</td> <td>    0.020</td> <td>  -17.343</td> <td> 0.000</td> <td>   -0.393</td> <td>   -0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>average_recharge_6_7</th> <td>    0.1682</td> <td>    0.124</td> <td>    1.354</td> <td> 0.176</td> <td>   -0.075</td> <td>    0.412</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                38400\n",
       "Model:                            GLM   Df Residuals:                    38329\n",
       "Model Family:                Binomial   Df Model:                           70\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -13628.\n",
       "Date:                Tue, 01 Sep 2020   Deviance:                       27255.\n",
       "Time:                        10:49:10   Pearson chi2:                 1.87e+05\n",
       "No. Iterations:                     7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                   -1.9382      0.028    -70.127      0.000      -1.992      -1.884\n",
       "arpu_6                   0.1787      0.051      3.504      0.000       0.079       0.279\n",
       "arpu_7                   0.3623      0.055      6.643      0.000       0.255       0.469\n",
       "arpu_8                   0.4212      0.065      6.453      0.000       0.293       0.549\n",
       "onnet_mou_6              0.3200      0.062      5.194      0.000       0.199       0.441\n",
       "offnet_mou_7             0.2494      0.041      6.106      0.000       0.169       0.329\n",
       "roam_og_mou_8            0.1954      0.016     11.880      0.000       0.163       0.228\n",
       "loc_og_t2t_mou_7         0.2119      0.056      3.762      0.000       0.101       0.322\n",
       "loc_og_t2t_mou_8        -1.1417      0.099    -11.536      0.000      -1.336      -0.948\n",
       "loc_og_t2m_mou_8        -1.4383      0.117    -12.275      0.000      -1.668      -1.209\n",
       "loc_og_t2f_mou_7        -0.1539      0.036     -4.276      0.000      -0.224      -0.083\n",
       "loc_og_t2f_mou_8        -0.1555      0.040     -3.933      0.000      -0.233      -0.078\n",
       "loc_og_mou_7            -0.4765      0.089     -5.382      0.000      -0.650      -0.303\n",
       "loc_og_mou_8             2.6326      0.196     13.464      0.000       2.249       3.016\n",
       "std_og_t2t_mou_6        -0.1837      0.063     -2.915      0.004      -0.307      -0.060\n",
       "std_og_t2t_mou_8        -0.7812      0.066    -11.868      0.000      -0.910      -0.652\n",
       "std_og_t2m_mou_8        -0.8522      0.067    -12.640      0.000      -0.984      -0.720\n",
       "std_og_mou_6             0.3395      0.067      5.080      0.000       0.209       0.471\n",
       "std_og_mou_7            -0.4079      0.127     -3.223      0.001      -0.656      -0.160\n",
       "std_og_mou_8             2.7126      0.215     12.629      0.000       2.292       3.134\n",
       "total_og_mou_6          -0.3718      0.066     -5.674      0.000      -0.500      -0.243\n",
       "total_og_mou_7           0.5261      0.131      4.012      0.000       0.269       0.783\n",
       "total_og_mou_8          -2.4117      0.191    -12.626      0.000      -2.786      -2.037\n",
       "loc_ic_t2t_mou_6         0.3315      0.056      5.923      0.000       0.222       0.441\n",
       "loc_ic_t2t_mou_8        -0.7413      0.077     -9.635      0.000      -0.892      -0.590\n",
       "loc_ic_t2m_mou_6         0.4764      0.095      5.034      0.000       0.291       0.662\n",
       "loc_ic_t2m_mou_7         0.2511      0.084      3.003      0.003       0.087       0.415\n",
       "loc_ic_t2m_mou_8        -1.5505      0.125    -12.379      0.000      -1.796      -1.305\n",
       "loc_ic_t2f_mou_8        -0.3492      0.040     -8.821      0.000      -0.427      -0.272\n",
       "loc_ic_mou_6            -0.4372      0.121     -3.614      0.000      -0.674      -0.200\n",
       "loc_ic_mou_7            -0.4819      0.112     -4.300      0.000      -0.702      -0.262\n",
       "loc_ic_mou_8             4.1706      0.202     20.600      0.000       3.774       4.567\n",
       "std_ic_t2t_mou_8        -0.4544      0.059     -7.710      0.000      -0.570      -0.339\n",
       "std_ic_t2m_mou_7        -0.1740      0.034     -5.180      0.000      -0.240      -0.108\n",
       "std_ic_t2m_mou_8        -0.4535      0.092     -4.953      0.000      -0.633      -0.274\n",
       "std_ic_t2f_mou_8        -0.2043      0.031     -6.526      0.000      -0.266      -0.143\n",
       "std_ic_mou_8             1.5651      0.128     12.249      0.000       1.315       1.816\n",
       "total_ic_mou_7           0.6408      0.083      7.737      0.000       0.478       0.803\n",
       "total_ic_mou_8          -3.7062      0.160    -23.111      0.000      -4.020      -3.392\n",
       "spl_ic_mou_8            -0.5284      0.028    -18.764      0.000      -0.584      -0.473\n",
       "isd_ic_mou_8             0.4207      0.028     14.912      0.000       0.365       0.476\n",
       "total_rech_num_7         0.1822      0.030      6.106      0.000       0.124       0.241\n",
       "total_rech_num_8        -0.6658      0.036    -18.336      0.000      -0.737      -0.595\n",
       "total_rech_amt_6        -0.1766      0.089     -1.974      0.048      -0.352      -0.001\n",
       "total_rech_amt_7        -0.2420      0.087     -2.784      0.005      -0.412      -0.072\n",
       "total_rech_amt_8        -0.1678      0.063     -2.650      0.008      -0.292      -0.044\n",
       "last_day_rch_amt_8      -0.6386      0.025    -25.759      0.000      -0.687      -0.590\n",
       "total_rech_data_8       -0.4505      0.104     -4.322      0.000      -0.655      -0.246\n",
       "max_rech_data_7         -0.1709      0.084     -2.032      0.042      -0.336      -0.006\n",
       "max_rech_data_8         -0.1593      0.103     -1.549      0.121      -0.361       0.042\n",
       "count_rech_2g_6         -0.1714      0.072     -2.369      0.018      -0.313      -0.030\n",
       "count_rech_2g_7         -0.4745      0.119     -3.976      0.000      -0.708      -0.241\n",
       "count_rech_3g_7         -0.2660      0.095     -2.811      0.005      -0.451      -0.081\n",
       "count_rech_3g_8          0.3712      0.134      2.766      0.006       0.108       0.634\n",
       "av_rech_amt_data_7       0.3245      0.075      4.330      0.000       0.178       0.471\n",
       "av_rech_amt_data_8      -0.2843      0.098     -2.909      0.004      -0.476      -0.093\n",
       "vol_2g_mb_8             -0.1901      0.032     -5.987      0.000      -0.252      -0.128\n",
       "vol_3g_mb_8             -0.2114      0.047     -4.538      0.000      -0.303      -0.120\n",
       "night_pck_user_7        -0.1356      0.076     -1.778      0.075      -0.285       0.014\n",
       "night_pck_user_8         0.1785      0.076      2.349      0.019       0.030       0.327\n",
       "sachet_2g_6              0.1941      0.071      2.732      0.006       0.055       0.333\n",
       "sachet_2g_7              0.3116      0.109      2.847      0.004       0.097       0.526\n",
       "sachet_2g_8              0.3598      0.086      4.203      0.000       0.192       0.528\n",
       "monthly_3g_7             0.2354      0.078      3.016      0.003       0.082       0.388\n",
       "monthly_3g_8            -0.1775      0.102     -1.744      0.081      -0.377       0.022\n",
       "sachet_3g_7              0.1990      0.056      3.570      0.000       0.090       0.308\n",
       "sachet_3g_8             -0.1848      0.077     -2.411      0.016      -0.335      -0.035\n",
       "fb_user_7                0.2166      0.087      2.503      0.012       0.047       0.386\n",
       "fb_user_8               -0.2845      0.091     -3.127      0.002      -0.463      -0.106\n",
       "aon                     -0.3533      0.020    -17.343      0.000      -0.393      -0.313\n",
       "average_recharge_6_7     0.1682      0.124      1.354      0.176      -0.075       0.412\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logistic2 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "model2 = logistic2.fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic2 = LogisticRegression()\n",
    "rfe_logistic2 = RFE(logistic2, 50)\n",
    "rfe_logistic2 = rfe_logistic2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['arpu_7', 'arpu_8', 'onnet_mou_6', 'offnet_mou_7', 'roam_og_mou_8',\n",
      "       'loc_og_t2t_mou_7', 'loc_og_t2t_mou_8', 'loc_og_t2m_mou_8',\n",
      "       'loc_og_t2f_mou_8', 'loc_og_mou_7', 'loc_og_mou_8', 'std_og_t2t_mou_6',\n",
      "       'std_og_t2t_mou_8', 'std_og_t2m_mou_8', 'std_og_mou_6', 'std_og_mou_7',\n",
      "       'std_og_mou_8', 'total_og_mou_6', 'total_og_mou_7', 'total_og_mou_8',\n",
      "       'loc_ic_t2t_mou_6', 'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_6',\n",
      "       'loc_ic_t2m_mou_7', 'loc_ic_t2m_mou_8', 'loc_ic_t2f_mou_8',\n",
      "       'loc_ic_mou_6', 'loc_ic_mou_7', 'loc_ic_mou_8', 'std_ic_t2t_mou_8',\n",
      "       'std_ic_t2m_mou_7', 'std_ic_t2m_mou_8', 'std_ic_t2f_mou_8',\n",
      "       'std_ic_mou_8', 'total_ic_mou_7', 'total_ic_mou_8', 'spl_ic_mou_8',\n",
      "       'isd_ic_mou_8', 'total_rech_num_7', 'total_rech_num_8',\n",
      "       'last_day_rch_amt_8', 'total_rech_data_8', 'max_rech_data_8',\n",
      "       'count_rech_2g_7', 'av_rech_amt_data_7', 'vol_2g_mb_8', 'vol_3g_mb_8',\n",
      "       'sachet_2g_7', 'sachet_2g_8', 'aon'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "col = X_train.columns[rfe_logistic2.support_]\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 38400</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 38349</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    50</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -13677.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Sep 2020</td> <th>  Deviance:          </th> <td>  27354.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:51:18</td>     <th>  Pearson chi2:      </th> <td>1.91e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>7</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -1.9297</td> <td>    0.027</td> <td>  -70.562</td> <td> 0.000</td> <td>   -1.983</td> <td>   -1.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_7</th>             <td>    0.2507</td> <td>    0.032</td> <td>    7.760</td> <td> 0.000</td> <td>    0.187</td> <td>    0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_8</th>             <td>    0.3243</td> <td>    0.041</td> <td>    7.837</td> <td> 0.000</td> <td>    0.243</td> <td>    0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_6</th>        <td>    0.3573</td> <td>    0.060</td> <td>    5.923</td> <td> 0.000</td> <td>    0.239</td> <td>    0.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_7</th>       <td>    0.2575</td> <td>    0.041</td> <td>    6.309</td> <td> 0.000</td> <td>    0.178</td> <td>    0.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>    0.1885</td> <td>    0.016</td> <td>   11.626</td> <td> 0.000</td> <td>    0.157</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>   <td>    0.2127</td> <td>    0.056</td> <td>    3.808</td> <td> 0.000</td> <td>    0.103</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_8</th>   <td>   -1.1443</td> <td>    0.099</td> <td>  -11.595</td> <td> 0.000</td> <td>   -1.338</td> <td>   -0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>   <td>   -1.4283</td> <td>    0.117</td> <td>  -12.224</td> <td> 0.000</td> <td>   -1.657</td> <td>   -1.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td>   -0.2623</td> <td>    0.031</td> <td>   -8.385</td> <td> 0.000</td> <td>   -0.324</td> <td>   -0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>       <td>   -0.5203</td> <td>    0.088</td> <td>   -5.908</td> <td> 0.000</td> <td>   -0.693</td> <td>   -0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_8</th>       <td>    2.6632</td> <td>    0.195</td> <td>   13.652</td> <td> 0.000</td> <td>    2.281</td> <td>    3.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_6</th>   <td>   -0.2162</td> <td>    0.062</td> <td>   -3.487</td> <td> 0.000</td> <td>   -0.338</td> <td>   -0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_8</th>   <td>   -0.7816</td> <td>    0.066</td> <td>  -11.880</td> <td> 0.000</td> <td>   -0.911</td> <td>   -0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>   -0.8567</td> <td>    0.067</td> <td>  -12.717</td> <td> 0.000</td> <td>   -0.989</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>       <td>    0.3269</td> <td>    0.066</td> <td>    4.920</td> <td> 0.000</td> <td>    0.197</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>   -0.4262</td> <td>    0.126</td> <td>   -3.371</td> <td> 0.001</td> <td>   -0.674</td> <td>   -0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>       <td>    2.7685</td> <td>    0.216</td> <td>   12.846</td> <td> 0.000</td> <td>    2.346</td> <td>    3.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>     <td>   -0.2772</td> <td>    0.062</td> <td>   -4.479</td> <td> 0.000</td> <td>   -0.398</td> <td>   -0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_7</th>     <td>    0.5022</td> <td>    0.131</td> <td>    3.841</td> <td> 0.000</td> <td>    0.246</td> <td>    0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>     <td>   -2.4955</td> <td>    0.191</td> <td>  -13.048</td> <td> 0.000</td> <td>   -2.870</td> <td>   -2.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_6</th>   <td>    0.3392</td> <td>    0.056</td> <td>    6.059</td> <td> 0.000</td> <td>    0.229</td> <td>    0.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_8</th>   <td>   -0.7582</td> <td>    0.077</td> <td>   -9.866</td> <td> 0.000</td> <td>   -0.909</td> <td>   -0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_6</th>   <td>    0.5045</td> <td>    0.095</td> <td>    5.322</td> <td> 0.000</td> <td>    0.319</td> <td>    0.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_7</th>   <td>    0.2490</td> <td>    0.083</td> <td>    2.991</td> <td> 0.003</td> <td>    0.086</td> <td>    0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_8</th>   <td>   -1.5827</td> <td>    0.125</td> <td>  -12.673</td> <td> 0.000</td> <td>   -1.827</td> <td>   -1.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.3581</td> <td>    0.039</td> <td>   -9.104</td> <td> 0.000</td> <td>   -0.435</td> <td>   -0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_6</th>       <td>   -0.4617</td> <td>    0.121</td> <td>   -3.803</td> <td> 0.000</td> <td>   -0.700</td> <td>   -0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_7</th>       <td>   -0.4646</td> <td>    0.112</td> <td>   -4.156</td> <td> 0.000</td> <td>   -0.684</td> <td>   -0.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>    4.2623</td> <td>    0.201</td> <td>   21.194</td> <td> 0.000</td> <td>    3.868</td> <td>    4.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_8</th>   <td>   -0.4597</td> <td>    0.059</td> <td>   -7.855</td> <td> 0.000</td> <td>   -0.574</td> <td>   -0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_7</th>   <td>   -0.1690</td> <td>    0.034</td> <td>   -5.040</td> <td> 0.000</td> <td>   -0.235</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_8</th>   <td>   -0.4680</td> <td>    0.091</td> <td>   -5.141</td> <td> 0.000</td> <td>   -0.646</td> <td>   -0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_8</th>   <td>   -0.2057</td> <td>    0.031</td> <td>   -6.616</td> <td> 0.000</td> <td>   -0.267</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_8</th>       <td>    1.6092</td> <td>    0.126</td> <td>   12.743</td> <td> 0.000</td> <td>    1.362</td> <td>    1.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_7</th>     <td>    0.6140</td> <td>    0.082</td> <td>    7.443</td> <td> 0.000</td> <td>    0.452</td> <td>    0.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_8</th>     <td>   -3.7681</td> <td>    0.158</td> <td>  -23.844</td> <td> 0.000</td> <td>   -4.078</td> <td>   -3.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_8</th>       <td>   -0.5285</td> <td>    0.028</td> <td>  -18.758</td> <td> 0.000</td> <td>   -0.584</td> <td>   -0.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_8</th>       <td>    0.4240</td> <td>    0.028</td> <td>   15.147</td> <td> 0.000</td> <td>    0.369</td> <td>    0.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_7</th>   <td>    0.2038</td> <td>    0.029</td> <td>    7.029</td> <td> 0.000</td> <td>    0.147</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_8</th>   <td>   -0.6965</td> <td>    0.034</td> <td>  -20.195</td> <td> 0.000</td> <td>   -0.764</td> <td>   -0.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.6637</td> <td>    0.023</td> <td>  -28.390</td> <td> 0.000</td> <td>   -0.710</td> <td>   -0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_8</th>  <td>   -0.3710</td> <td>    0.069</td> <td>   -5.398</td> <td> 0.000</td> <td>   -0.506</td> <td>   -0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_8</th>    <td>   -0.4412</td> <td>    0.041</td> <td>  -10.717</td> <td> 0.000</td> <td>   -0.522</td> <td>   -0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_2g_7</th>    <td>   -0.6783</td> <td>    0.078</td> <td>   -8.685</td> <td> 0.000</td> <td>   -0.831</td> <td>   -0.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_7</th> <td>    0.2832</td> <td>    0.031</td> <td>    9.237</td> <td> 0.000</td> <td>    0.223</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_8</th>        <td>   -0.2228</td> <td>    0.030</td> <td>   -7.403</td> <td> 0.000</td> <td>   -0.282</td> <td>   -0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_8</th>        <td>   -0.2362</td> <td>    0.043</td> <td>   -5.534</td> <td> 0.000</td> <td>   -0.320</td> <td>   -0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_7</th>        <td>    0.5504</td> <td>    0.075</td> <td>    7.323</td> <td> 0.000</td> <td>    0.403</td> <td>    0.698</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_8</th>        <td>    0.2398</td> <td>    0.060</td> <td>    4.013</td> <td> 0.000</td> <td>    0.123</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aon</th>                <td>   -0.3585</td> <td>    0.020</td> <td>  -17.696</td> <td> 0.000</td> <td>   -0.398</td> <td>   -0.319</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                38400\n",
       "Model:                            GLM   Df Residuals:                    38349\n",
       "Model Family:                Binomial   Df Model:                           50\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -13677.\n",
       "Date:                Tue, 01 Sep 2020   Deviance:                       27354.\n",
       "Time:                        10:51:18   Pearson chi2:                 1.91e+05\n",
       "No. Iterations:                     7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -1.9297      0.027    -70.562      0.000      -1.983      -1.876\n",
       "arpu_7                 0.2507      0.032      7.760      0.000       0.187       0.314\n",
       "arpu_8                 0.3243      0.041      7.837      0.000       0.243       0.405\n",
       "onnet_mou_6            0.3573      0.060      5.923      0.000       0.239       0.476\n",
       "offnet_mou_7           0.2575      0.041      6.309      0.000       0.178       0.338\n",
       "roam_og_mou_8          0.1885      0.016     11.626      0.000       0.157       0.220\n",
       "loc_og_t2t_mou_7       0.2127      0.056      3.808      0.000       0.103       0.322\n",
       "loc_og_t2t_mou_8      -1.1443      0.099    -11.595      0.000      -1.338      -0.951\n",
       "loc_og_t2m_mou_8      -1.4283      0.117    -12.224      0.000      -1.657      -1.199\n",
       "loc_og_t2f_mou_8      -0.2623      0.031     -8.385      0.000      -0.324      -0.201\n",
       "loc_og_mou_7          -0.5203      0.088     -5.908      0.000      -0.693      -0.348\n",
       "loc_og_mou_8           2.6632      0.195     13.652      0.000       2.281       3.045\n",
       "std_og_t2t_mou_6      -0.2162      0.062     -3.487      0.000      -0.338      -0.095\n",
       "std_og_t2t_mou_8      -0.7816      0.066    -11.880      0.000      -0.911      -0.653\n",
       "std_og_t2m_mou_8      -0.8567      0.067    -12.717      0.000      -0.989      -0.725\n",
       "std_og_mou_6           0.3269      0.066      4.920      0.000       0.197       0.457\n",
       "std_og_mou_7          -0.4262      0.126     -3.371      0.001      -0.674      -0.178\n",
       "std_og_mou_8           2.7685      0.216     12.846      0.000       2.346       3.191\n",
       "total_og_mou_6        -0.2772      0.062     -4.479      0.000      -0.398      -0.156\n",
       "total_og_mou_7         0.5022      0.131      3.841      0.000       0.246       0.758\n",
       "total_og_mou_8        -2.4955      0.191    -13.048      0.000      -2.870      -2.121\n",
       "loc_ic_t2t_mou_6       0.3392      0.056      6.059      0.000       0.229       0.449\n",
       "loc_ic_t2t_mou_8      -0.7582      0.077     -9.866      0.000      -0.909      -0.608\n",
       "loc_ic_t2m_mou_6       0.5045      0.095      5.322      0.000       0.319       0.690\n",
       "loc_ic_t2m_mou_7       0.2490      0.083      2.991      0.003       0.086       0.412\n",
       "loc_ic_t2m_mou_8      -1.5827      0.125    -12.673      0.000      -1.827      -1.338\n",
       "loc_ic_t2f_mou_8      -0.3581      0.039     -9.104      0.000      -0.435      -0.281\n",
       "loc_ic_mou_6          -0.4617      0.121     -3.803      0.000      -0.700      -0.224\n",
       "loc_ic_mou_7          -0.4646      0.112     -4.156      0.000      -0.684      -0.246\n",
       "loc_ic_mou_8           4.2623      0.201     21.194      0.000       3.868       4.656\n",
       "std_ic_t2t_mou_8      -0.4597      0.059     -7.855      0.000      -0.574      -0.345\n",
       "std_ic_t2m_mou_7      -0.1690      0.034     -5.040      0.000      -0.235      -0.103\n",
       "std_ic_t2m_mou_8      -0.4680      0.091     -5.141      0.000      -0.646      -0.290\n",
       "std_ic_t2f_mou_8      -0.2057      0.031     -6.616      0.000      -0.267      -0.145\n",
       "std_ic_mou_8           1.6092      0.126     12.743      0.000       1.362       1.857\n",
       "total_ic_mou_7         0.6140      0.082      7.443      0.000       0.452       0.776\n",
       "total_ic_mou_8        -3.7681      0.158    -23.844      0.000      -4.078      -3.458\n",
       "spl_ic_mou_8          -0.5285      0.028    -18.758      0.000      -0.584      -0.473\n",
       "isd_ic_mou_8           0.4240      0.028     15.147      0.000       0.369       0.479\n",
       "total_rech_num_7       0.2038      0.029      7.029      0.000       0.147       0.261\n",
       "total_rech_num_8      -0.6965      0.034    -20.195      0.000      -0.764      -0.629\n",
       "last_day_rch_amt_8    -0.6637      0.023    -28.390      0.000      -0.710      -0.618\n",
       "total_rech_data_8     -0.3710      0.069     -5.398      0.000      -0.506      -0.236\n",
       "max_rech_data_8       -0.4412      0.041    -10.717      0.000      -0.522      -0.360\n",
       "count_rech_2g_7       -0.6783      0.078     -8.685      0.000      -0.831      -0.525\n",
       "av_rech_amt_data_7     0.2832      0.031      9.237      0.000       0.223       0.343\n",
       "vol_2g_mb_8           -0.2228      0.030     -7.403      0.000      -0.282      -0.164\n",
       "vol_3g_mb_8           -0.2362      0.043     -5.534      0.000      -0.320      -0.153\n",
       "sachet_2g_7            0.5504      0.075      7.323      0.000       0.403       0.698\n",
       "sachet_2g_8            0.2398      0.060      4.013      0.000       0.123       0.357\n",
       "aon                   -0.3585      0.020    -17.696      0.000      -0.398      -0.319\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logistic3 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "model3 = logistic3.fit()\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIF calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF values of the feature variables. \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>std_og_mou_8</td>\n",
       "      <td>76.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>72.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>loc_og_mou_8</td>\n",
       "      <td>66.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>total_og_mou_8</td>\n",
       "      <td>61.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>total_og_mou_7</td>\n",
       "      <td>56.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>std_og_mou_7</td>\n",
       "      <td>52.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>loc_ic_mou_6</td>\n",
       "      <td>38.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>loc_ic_mou_7</td>\n",
       "      <td>36.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>total_ic_mou_8</td>\n",
       "      <td>33.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>loc_ic_t2m_mou_8</td>\n",
       "      <td>32.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>std_ic_mou_8</td>\n",
       "      <td>29.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>loc_ic_t2m_mou_6</td>\n",
       "      <td>24.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loc_og_mou_7</td>\n",
       "      <td>20.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>std_og_mou_6</td>\n",
       "      <td>20.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>loc_ic_t2m_mou_7</td>\n",
       "      <td>19.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>total_ic_mou_7</td>\n",
       "      <td>19.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>std_og_t2t_mou_6</td>\n",
       "      <td>17.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>std_ic_t2m_mou_8</td>\n",
       "      <td>16.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>total_og_mou_6</td>\n",
       "      <td>16.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>count_rech_2g_7</td>\n",
       "      <td>15.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>sachet_2g_7</td>\n",
       "      <td>14.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>onnet_mou_6</td>\n",
       "      <td>14.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>14.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>std_og_t2t_mou_8</td>\n",
       "      <td>14.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loc_og_t2t_mou_8</td>\n",
       "      <td>13.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>total_rech_data_8</td>\n",
       "      <td>11.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>loc_ic_t2t_mou_8</td>\n",
       "      <td>9.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>sachet_2g_8</td>\n",
       "      <td>8.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arpu_8</td>\n",
       "      <td>7.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>loc_og_t2t_mou_7</td>\n",
       "      <td>7.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>loc_ic_t2t_mou_6</td>\n",
       "      <td>7.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offnet_mou_7</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>std_ic_t2t_mou_8</td>\n",
       "      <td>6.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>max_rech_data_8</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>total_rech_num_8</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arpu_7</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>vol_3g_mb_8</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>std_ic_t2m_mou_7</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>total_rech_num_7</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>av_rech_amt_data_7</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>vol_2g_mb_8</td>\n",
       "      <td>1.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>loc_og_t2f_mou_8</td>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>isd_ic_mou_8</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>std_ic_t2f_mou_8</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roam_og_mou_8</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>aon</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>spl_ic_mou_8</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features    VIF\n",
       "16        std_og_mou_8  76.61\n",
       "28        loc_ic_mou_8  72.22\n",
       "10        loc_og_mou_8  66.02\n",
       "19      total_og_mou_8  61.42\n",
       "18      total_og_mou_7  56.90\n",
       "15        std_og_mou_7  52.98\n",
       "26        loc_ic_mou_6  38.99\n",
       "27        loc_ic_mou_7  36.85\n",
       "35      total_ic_mou_8  33.66\n",
       "24    loc_ic_t2m_mou_8  32.74\n",
       "33        std_ic_mou_8  29.72\n",
       "7     loc_og_t2m_mou_8  24.79\n",
       "22    loc_ic_t2m_mou_6  24.31\n",
       "9         loc_og_mou_7  20.93\n",
       "14        std_og_mou_6  20.68\n",
       "23    loc_ic_t2m_mou_7  19.95\n",
       "34      total_ic_mou_7  19.94\n",
       "11    std_og_t2t_mou_6  17.32\n",
       "31    std_ic_t2m_mou_8  16.48\n",
       "17      total_og_mou_6  16.09\n",
       "43     count_rech_2g_7  15.68\n",
       "47         sachet_2g_7  14.91\n",
       "2          onnet_mou_6  14.82\n",
       "13    std_og_t2m_mou_8  14.13\n",
       "12    std_og_t2t_mou_8  14.07\n",
       "6     loc_og_t2t_mou_8  13.66\n",
       "41   total_rech_data_8  11.22\n",
       "21    loc_ic_t2t_mou_8   9.60\n",
       "48         sachet_2g_8   8.30\n",
       "1               arpu_8   7.92\n",
       "5     loc_og_t2t_mou_7   7.89\n",
       "20    loc_ic_t2t_mou_6   7.19\n",
       "3         offnet_mou_7   6.26\n",
       "29    std_ic_t2t_mou_8   6.06\n",
       "42     max_rech_data_8   4.33\n",
       "39    total_rech_num_8   4.28\n",
       "0               arpu_7   3.97\n",
       "46         vol_3g_mb_8   3.80\n",
       "30    std_ic_t2m_mou_7   3.42\n",
       "38    total_rech_num_7   3.04\n",
       "44  av_rech_amt_data_7   2.81\n",
       "25    loc_ic_t2f_mou_8   2.28\n",
       "40  last_day_rch_amt_8   1.83\n",
       "45         vol_2g_mb_8   1.74\n",
       "8     loc_og_t2f_mou_8   1.69\n",
       "37        isd_ic_mou_8   1.55\n",
       "32    std_ic_t2f_mou_8   1.55\n",
       "4        roam_og_mou_8   1.51\n",
       "49                 aon   1.31\n",
       "36        spl_ic_mou_8   1.09"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic3 = LogisticRegression()\n",
    "rfe_logistic3 = RFE(logistic3, 20)\n",
    "rfe_logistic3 = rfe_logistic3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['arpu_7', 'loc_og_t2t_mou_8', 'loc_og_t2m_mou_8', 'loc_og_mou_8',\n",
      "       'std_og_t2t_mou_8', 'std_og_t2m_mou_8', 'std_og_mou_8',\n",
      "       'total_og_mou_8', 'loc_ic_t2t_mou_8', 'loc_ic_t2m_mou_8',\n",
      "       'loc_ic_t2f_mou_8', 'loc_ic_mou_8', 'std_ic_mou_8', 'total_ic_mou_8',\n",
      "       'spl_ic_mou_8', 'total_rech_num_8', 'last_day_rch_amt_8',\n",
      "       'max_rech_data_8', 'count_rech_2g_7', 'sachet_2g_7'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "col = X_train.columns[rfe_logistic3.support_]\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td> 38400</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 38379</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>    20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -14608.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 01 Sep 2020</td> <th>  Deviance:          </th> <td>  29216.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>10:53:48</td>     <th>  Pearson chi2:      </th> <td>9.55e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>7</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -1.8261</td> <td>    0.026</td> <td>  -70.828</td> <td> 0.000</td> <td>   -1.877</td> <td>   -1.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_7</th>             <td>    0.7016</td> <td>    0.019</td> <td>   36.285</td> <td> 0.000</td> <td>    0.664</td> <td>    0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_8</th>   <td>   -0.9387</td> <td>    0.089</td> <td>  -10.536</td> <td> 0.000</td> <td>   -1.113</td> <td>   -0.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>   <td>   -1.5612</td> <td>    0.115</td> <td>  -13.569</td> <td> 0.000</td> <td>   -1.787</td> <td>   -1.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_8</th>       <td>    2.4905</td> <td>    0.190</td> <td>   13.097</td> <td> 0.000</td> <td>    2.118</td> <td>    2.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_8</th>   <td>   -0.8408</td> <td>    0.063</td> <td>  -13.262</td> <td> 0.000</td> <td>   -0.965</td> <td>   -0.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>   -0.7708</td> <td>    0.063</td> <td>  -12.262</td> <td> 0.000</td> <td>   -0.894</td> <td>   -0.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>       <td>    3.0553</td> <td>    0.212</td> <td>   14.427</td> <td> 0.000</td> <td>    2.640</td> <td>    3.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>     <td>   -2.6445</td> <td>    0.180</td> <td>  -14.697</td> <td> 0.000</td> <td>   -2.997</td> <td>   -2.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_8</th>   <td>   -0.7827</td> <td>    0.068</td> <td>  -11.480</td> <td> 0.000</td> <td>   -0.916</td> <td>   -0.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_8</th>   <td>   -1.4589</td> <td>    0.103</td> <td>  -14.172</td> <td> 0.000</td> <td>   -1.661</td> <td>   -1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>   -0.6476</td> <td>    0.037</td> <td>  -17.552</td> <td> 0.000</td> <td>   -0.720</td> <td>   -0.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td>    3.1435</td> <td>    0.170</td> <td>   18.507</td> <td> 0.000</td> <td>    2.811</td> <td>    3.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_8</th>       <td>    0.4519</td> <td>    0.042</td> <td>   10.803</td> <td> 0.000</td> <td>    0.370</td> <td>    0.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_8</th>     <td>   -2.1213</td> <td>    0.118</td> <td>  -17.930</td> <td> 0.000</td> <td>   -2.353</td> <td>   -1.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_8</th>       <td>   -0.5329</td> <td>    0.028</td> <td>  -19.272</td> <td> 0.000</td> <td>   -0.587</td> <td>   -0.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_8</th>   <td>   -0.5690</td> <td>    0.021</td> <td>  -26.684</td> <td> 0.000</td> <td>   -0.611</td> <td>   -0.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>   -0.6977</td> <td>    0.021</td> <td>  -33.518</td> <td> 0.000</td> <td>   -0.738</td> <td>   -0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_8</th>    <td>   -0.7230</td> <td>    0.023</td> <td>  -31.665</td> <td> 0.000</td> <td>   -0.768</td> <td>   -0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>count_rech_2g_7</th>    <td>   -0.6861</td> <td>    0.069</td> <td>   -9.934</td> <td> 0.000</td> <td>   -0.821</td> <td>   -0.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_7</th>        <td>    0.5563</td> <td>    0.068</td> <td>    8.175</td> <td> 0.000</td> <td>    0.423</td> <td>    0.690</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                38400\n",
       "Model:                            GLM   Df Residuals:                    38379\n",
       "Model Family:                Binomial   Df Model:                           20\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -14608.\n",
       "Date:                Tue, 01 Sep 2020   Deviance:                       29216.\n",
       "Time:                        10:53:48   Pearson chi2:                 9.55e+04\n",
       "No. Iterations:                     7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -1.8261      0.026    -70.828      0.000      -1.877      -1.776\n",
       "arpu_7                 0.7016      0.019     36.285      0.000       0.664       0.739\n",
       "loc_og_t2t_mou_8      -0.9387      0.089    -10.536      0.000      -1.113      -0.764\n",
       "loc_og_t2m_mou_8      -1.5612      0.115    -13.569      0.000      -1.787      -1.336\n",
       "loc_og_mou_8           2.4905      0.190     13.097      0.000       2.118       2.863\n",
       "std_og_t2t_mou_8      -0.8408      0.063    -13.262      0.000      -0.965      -0.717\n",
       "std_og_t2m_mou_8      -0.7708      0.063    -12.262      0.000      -0.894      -0.648\n",
       "std_og_mou_8           3.0553      0.212     14.427      0.000       2.640       3.470\n",
       "total_og_mou_8        -2.6445      0.180    -14.697      0.000      -2.997      -2.292\n",
       "loc_ic_t2t_mou_8      -0.7827      0.068    -11.480      0.000      -0.916      -0.649\n",
       "loc_ic_t2m_mou_8      -1.4589      0.103    -14.172      0.000      -1.661      -1.257\n",
       "loc_ic_t2f_mou_8      -0.6476      0.037    -17.552      0.000      -0.720      -0.575\n",
       "loc_ic_mou_8           3.1435      0.170     18.507      0.000       2.811       3.476\n",
       "std_ic_mou_8           0.4519      0.042     10.803      0.000       0.370       0.534\n",
       "total_ic_mou_8        -2.1213      0.118    -17.930      0.000      -2.353      -1.889\n",
       "spl_ic_mou_8          -0.5329      0.028    -19.272      0.000      -0.587      -0.479\n",
       "total_rech_num_8      -0.5690      0.021    -26.684      0.000      -0.611      -0.527\n",
       "last_day_rch_amt_8    -0.6977      0.021    -33.518      0.000      -0.738      -0.657\n",
       "max_rech_data_8       -0.7230      0.023    -31.665      0.000      -0.768      -0.678\n",
       "count_rech_2g_7       -0.6861      0.069     -9.934      0.000      -0.821      -0.551\n",
       "sachet_2g_7            0.5563      0.068      8.175      0.000       0.423       0.690\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train[col])\n",
    "logistic4 = sm.GLM(y_train, X_train_sm, family = sm.families.Binomial())\n",
    "model4 = logistic4.fit()\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>std_og_mou_8</td>\n",
       "      <td>64.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loc_og_mou_8</td>\n",
       "      <td>57.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>loc_ic_mou_8</td>\n",
       "      <td>54.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_og_mou_8</td>\n",
       "      <td>42.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loc_ic_t2m_mou_8</td>\n",
       "      <td>23.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loc_og_t2m_mou_8</td>\n",
       "      <td>22.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_ic_mou_8</td>\n",
       "      <td>19.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>count_rech_2g_7</td>\n",
       "      <td>13.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sachet_2g_7</td>\n",
       "      <td>13.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>std_og_t2t_mou_8</td>\n",
       "      <td>13.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std_og_t2m_mou_8</td>\n",
       "      <td>12.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loc_og_t2t_mou_8</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>loc_ic_t2t_mou_8</td>\n",
       "      <td>7.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>std_ic_mou_8</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>loc_ic_t2f_mou_8</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_rech_num_8</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>last_day_rch_amt_8</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max_rech_data_8</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arpu_7</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spl_ic_mou_8</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features    VIF\n",
       "6         std_og_mou_8  64.21\n",
       "3         loc_og_mou_8  57.84\n",
       "11        loc_ic_mou_8  54.43\n",
       "7       total_og_mou_8  42.13\n",
       "9     loc_ic_t2m_mou_8  23.76\n",
       "2     loc_og_t2m_mou_8  22.72\n",
       "13      total_ic_mou_8  19.19\n",
       "18     count_rech_2g_7  13.97\n",
       "19         sachet_2g_7  13.62\n",
       "4     std_og_t2t_mou_8  13.19\n",
       "5     std_og_t2m_mou_8  12.61\n",
       "1     loc_og_t2t_mou_8  10.25\n",
       "8     loc_ic_t2t_mou_8   7.99\n",
       "12        std_ic_mou_8   3.01\n",
       "10    loc_ic_t2f_mou_8   1.94\n",
       "15    total_rech_num_8   1.84\n",
       "16  last_day_rch_amt_8   1.53\n",
       "17     max_rech_data_8   1.42\n",
       "0               arpu_7   1.32\n",
       "14        spl_ic_mou_8   1.07"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = X_train[col].columns\n",
    "vif['VIF'] = [variance_inflation_factor(X_train[col].values, i) for i in range(X_train[col].shape[1])]\n",
    "vif['VIF'] = round(vif['VIF'], 2)\n",
    "vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29172    0.094557\n",
       "9013     0.063160\n",
       "8741     0.081252\n",
       "30680    0.948372\n",
       "43716    0.734511\n",
       "17901    0.698748\n",
       "52619    0.541255\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the predicted probabilities\n",
    "y_train_pred = model4.predict(X_train_sm)\n",
    "y_train_pred[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09455664, 0.06315962, 0.08125246, 0.94837161, 0.73451085,\n",
       "       0.69874803, 0.54125487, 0.22597399, 0.01605662, 0.90588884])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = y_train_pred.values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a dataframe with the actual churn flag and the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.094557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.063160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.948372</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.734511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  ID\n",
       "0      0    0.094557   0\n",
       "1      0    0.063160   0\n",
       "2      0    0.081252   0\n",
       "3      1    0.948372   1\n",
       "4      1    0.734511   1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final = pd.DataFrame({'Churn':y_train, 'Churn_Prob':y_train_pred})\n",
    "y_train_pred_final['ID'] = y_train\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating new column 'predicted' with 1 if Churn_Prob > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.094557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.063160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.948372</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.734511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  ID  predicted\n",
       "0      0    0.094557   0          0\n",
       "1      0    0.063160   0          0\n",
       "2      0    0.081252   0          0\n",
       "3      1    0.948372   1          1\n",
       "4      1    0.734511   1          1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_final['predicted'] = y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Let's see the head\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15952  3214]\n",
      " [ 2865 16369]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix \n",
    "confusion = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.predicted )\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8416927083333333\n"
     ]
    }
   ],
   "source": [
    "# overall accuracy.\n",
    "accuracy_log = metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted)\n",
    "print(\"Accuracy: {}\".format(accuracy_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8510450244358948"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sensitivity\n",
    "TP / float(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8323072106855891"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specificity\n",
    "TN / float(TN+FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve( y_train_pred_final.Churn, y_train_pred_final.Churn_Prob, drop_intermediate = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_roc(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Optimal cutoff point for the churn value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Churn</th>\n",
       "      <th>Churn_Prob</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.094557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.063160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.081252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.948372</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.734511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Churn  Churn_Prob  ID  predicted  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  \\\n",
       "0      0    0.094557   0          0    1    0    0    0    0    0    0    0   \n",
       "1      0    0.063160   0          0    1    0    0    0    0    0    0    0   \n",
       "2      0    0.081252   0          0    1    0    0    0    0    0    0    0   \n",
       "3      1    0.948372   1          1    1    1    1    1    1    1    1    1   \n",
       "4      1    0.734511   1          1    1    1    1    1    1    1    1    1   \n",
       "\n",
       "   0.8  0.9  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "2    0    0  \n",
       "3    1    1  \n",
       "4    0    0  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final.Churn_Prob.map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     prob  accuracy     sensi     speci\n",
      "0.0   0.0  0.500885  1.000000  0.000000\n",
      "0.1   0.1  0.703255  0.974680  0.430867\n",
      "0.2   0.2  0.766927  0.948061  0.585151\n",
      "0.3   0.3  0.805130  0.919154  0.690702\n",
      "0.4   0.4  0.829271  0.888323  0.770009\n",
      "0.5   0.5  0.841693  0.851045  0.832307\n",
      "0.6   0.6  0.843516  0.806229  0.880935\n",
      "0.7   0.7  0.832109  0.744255  0.920275\n",
      "0.8   0.8  0.797682  0.643340  0.952572\n",
      "0.9   0.9  0.681797  0.382500  0.982156\n"
     ]
    }
   ],
   "source": [
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plottign the tradeoff graph between all the metrics\n",
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seems like our threshold of 0.5 is fine for sensitivity and specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15952,  3214],\n",
       "       [ 2865, 16369]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion = metrics.confusion_matrix(y_train_pred_final.Churn, y_train_pred_final.predicted )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula for Precision: TP/TP+FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.835878057498851\n"
     ]
    }
   ],
   "source": [
    "precision = confusion[1,1]/(confusion[0,1]+confusion[1,1])\n",
    "print(\"Precision: {}\".format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula for recall: TP/TP+FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8510450244358948\n"
     ]
    }
   ],
   "source": [
    "recall_log = confusion[1,1]/(confusion[1,0]+confusion[1,1])\n",
    "print(\"Recall: {}\".format(recall_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F score calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (2 × precision × recall)/(precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F Score: 0.8433933585800036\n"
     ]
    }
   ],
   "source": [
    "f_score = (2*precision*recall_log)/(precision+recall_log)\n",
    "print(\"F Score: {}\".format(f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision & Recall tradeoff graph plottin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, thresholds = precision_recall_curve(y_train_pred_final.Churn, y_train_pred_final.Churn_Prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, p[:-1], \"g-\")\n",
    "plt.plot(thresholds, r[:-1], \"r-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like all our metrics i.e sensitivity, specificity, precision & recall performs good at 0.5 threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and Recall printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8416927083333333\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted) \n",
    "print(\"Accuracy: {}\".format(metrics.accuracy_score(y_train_pred_final.Churn, y_train_pred_final.predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.835878057498851\n"
     ]
    }
   ],
   "source": [
    "recall = confusion[1,1]/(confusion[0,1]+confusion[1,1]) \n",
    "print(\"Recall: {}\".format(confusion[1,1]/(confusion[0,1]+confusion[1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>84.200000</td>\n",
       "      <td>85.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Intrepretable</td>\n",
       "      <td>0.841693</td>\n",
       "      <td>0.835878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model   Accuracy     Recall\n",
       "1                Logistic Regression  84.200000  85.170000\n",
       "2                      Decision Tree  83.000000  87.000000\n",
       "3                      Random Forest  84.000000  83.000000\n",
       "4  Logistic Regression Intrepretable   0.841693   0.835878"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.loc[4] = ['Logistic Regression Intrepretable', accuracy, recall]\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
